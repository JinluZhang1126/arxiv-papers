## Updated on 2025.10.08
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#interaction>Interaction</a></li>
    <li><a href=#world-model>World Model</a></li>
    <li><a href=#vlm>VLM</a></li>
    <li><a href=#vla>VLA</a></li>
    <li><a href=#humanoid>Humanoid</a></li>
    <li><a href=#3dgs/nerf>3DGS/NeRF</a></li>
  </ol>
</details>

## Interaction

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-10-03**|**Mask2IV: Interaction-Centric Video Generation via Mask Trajectories**|Gen Li,...Laura Sevilla-Lara|[2510.03135](http://arxiv.org/abs/2510.03135)|**[link](https://reagan1311.github.io/mask2iv)**|
|**2025-10-02**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Shu Zou,...Jing Zhang|[2510.02155](http://arxiv.org/abs/2510.02155)|null|
|**2025-09-30**|**HART: Human Aligned Reconstruction Transformer**|Xiyi Chen,...Ming Lin|[2509.26621](http://arxiv.org/abs/2509.26621)|**[link](https://xiyichen.github.io/hart)**|
|**2025-09-30**|**Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations**|Nicola Messina,...Antonino Furnari|[2509.26004](http://arxiv.org/abs/2509.26004)|null|
|**2025-09-28**|**InteractMove: Text-Controlled Human-Object Interaction Generation in 3D Scenes with Movable Objects**|Xinhao Cai,...Yang Liu|[2509.23612](http://arxiv.org/abs/2509.23612)|null|
|**2025-09-23**|**Lang2Morph: Language-Driven Morphological Design of Robotic Hands**|Yanyuan Qiao,...Josie Hughes|[2509.18937](http://arxiv.org/abs/2509.18937)|null|
|**2025-09-23**|**Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought**|Yuhan Wang,...Weichao Wu|[2509.18571](http://arxiv.org/abs/2509.18571)|null|
|**2025-09-22**|**Trainee Action Recognition through Interaction Analysis in CCATT Mixed-Reality Training**|Divya Mereddy,...Benjamin Goldberg|[2509.17888](http://arxiv.org/abs/2509.17888)|null|
|**2025-09-20**|**Person Identification from Egocentric Human-Object Interactions using 3D Hand Pose**|Muhammad Hamza,...Muhammad Tahir Akram|[2509.16557](http://arxiv.org/abs/2509.16557)|null|
|**2025-09-19**|**Dynamic Objects Relocalization in Changing Environments with Flow Matching**|Francesco Argenziano,...Liam Paull|[2509.16398](http://arxiv.org/abs/2509.16398)|null|
|**2025-10-03**|**Contextualized Representation Learning for Effective Human-Object Interaction Detection**|Zhehao Li,...Jiafei Wu|[2509.12784](http://arxiv.org/abs/2509.12784)|null|
|**2025-09-16**|**Explicit Multimodal Graph Modeling for Human-Object Interaction Detection**|Wenxuan Ji,...Xiao-Yu zhang|[2509.12554](http://arxiv.org/abs/2509.12554)|null|
|**2025-09-12**|**OnlineHOI: Towards Online Human-Object Interaction Generation and Perception**|Yihong Ji,...Fei Yu|[2509.12250](http://arxiv.org/abs/2509.12250)|null|
|**2025-09-11**|**InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation**|Sirui Xu,...Liang-Yan Gui|[2509.09555](http://arxiv.org/abs/2509.09555)|null|
|**2025-09-16**|**Improvement of Human-Object Interaction Action Recognition Using Scene Information and Multi-Task Learning Approach**|Hesham M. Shehata,...Mohammad Abdolrahmani|[2509.09067](http://arxiv.org/abs/2509.09067)|null|
|**2025-09-09**|**ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion**|Ao Li,...Yansong Tang|[2509.07920](http://arxiv.org/abs/2509.07920)|null|
|**2025-09-01**|**FantasyHSI: Video-Generation-Centric 4D Human Synthesis In Any Scene through A Graph-based Multi-Agent Framework**|Lingzhou Mu,...Kai Zhang|[2509.01232](http://arxiv.org/abs/2509.01232)|**[link](https://fantasy-amap.github.io/fantasy-hsi/)**|
|**2025-08-31**|**InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos**|Yangsong Zhang,...Ivan Laptev|[2509.00767](http://arxiv.org/abs/2509.00767)|**[link](https://mael-zys.github.io/InterPose/)**|
|**2025-08-31**|**No More Sibling Rivalry: Debiasing Human-Object Interaction Detection**|Bin Yang,...Sibei Yang|[2509.00760](http://arxiv.org/abs/2509.00760)|null|
|**2025-08-29**|**ECHO: Ego-Centric modeling of Human-Object interactions**|Ilya A. Petrov,...Gerard Pons-Moll|[2508.21556](http://arxiv.org/abs/2508.21556)|null|
|**2025-08-28**|**Ego-centric Predictive Model Conditioned on Hand Trajectories**|Binjie Zhang,...Mike Zheng Shou|[2508.19852](http://arxiv.org/abs/2508.19852)|null|
|**2025-08-28**|**Interact-Custom: Customized Human Object Interaction Image Generation**|Zhu Xu,...Yang Liu|[2508.19575](http://arxiv.org/abs/2508.19575)|null|
|**2025-08-26**|**DQEN: Dual Query Enhancement Network for DETR-based HOI Detection**|Zhehao Li,...Jiafei Wu|[2508.18896](http://arxiv.org/abs/2508.18896)|null|
|**2025-09-29**|**Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods**|Qinqian Lei,...Robby T. Tan|[2508.18753](http://arxiv.org/abs/2508.18753)|null|
|**2025-08-26**|**Deep Sensorimotor Control by Imitating Predictive Models of Human Motion**|Himanshu Gaurav Singh,...Antonio Loquercio|[2508.18691](http://arxiv.org/abs/2508.18691)|**[link](https://hgaurav2k.github.io/trackr/)**|

<p align=right>(<a href=#updated-on-20251008>back to top</a>)</p>

## World Model

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-10-06**|**StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation**|Mingyu Liu,...Chunhua Shen|[2510.05057](http://arxiv.org/abs/2510.05057)|null|
|**2025-10-06**|**Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI**|Kun Xiang,...Xiaodan Liang|[2510.04978](http://arxiv.org/abs/2510.04978)|null|
|**2025-10-06**|**Code World Models for General Game Playing**|Wolfgang Lehrach,...Kevin P. Murphy|[2510.04542](http://arxiv.org/abs/2510.04542)|null|
|**2025-10-05**|**Internal World Models as Imagination Networks in Cognitive Agents**|Saurabh Ranjan,...Brian Odegaard|[2510.04391](http://arxiv.org/abs/2510.04391)|null|
|**2025-10-05**|**MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D World Simulator**|Xuehai He,...Xin Eric Wang|[2510.04390](http://arxiv.org/abs/2510.04390)|null|
|**2025-10-05**|**GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks**|Tejal Patwardhan,...Jerry Tworek|[2510.04374](http://arxiv.org/abs/2510.04374)|null|
|**2025-10-05**|**Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models**|Hao Wu,...Xiaomeng Huang|[2510.04020](http://arxiv.org/abs/2510.04020)|null|
|**2025-10-04**|**Bridging the Gap Between Multimodal Foundation Models and World Models**|Xuehai He,...Xuehai He|[2510.03727](http://arxiv.org/abs/2510.03727)|null|
|**2025-10-03**|**A Generalized Second-Order Positivity-Preserving Numerical Method for Non-Autonomous Dynamical Systems with Applications**|Manh Tuan Hoang,...Matthias Ehrhardt|[2510.03420](http://arxiv.org/abs/2510.03420)|null|
|**2025-10-03**|**Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft**|Junchao Huang,...Li Jiang|[2510.03198](http://arxiv.org/abs/2510.03198)|null|
|**2025-10-02**|**A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models**|Yilin Wang,...Hao Su|[2510.02538](http://arxiv.org/abs/2510.02538)|null|
|**2025-09-30**|**CWM: An Open-Weights LLM for Research on Code Generation with World Models**|FAIR CodeGen team,...Gabriel Synnaeve|[2510.02387](http://arxiv.org/abs/2510.02387)|null|
|**2025-10-02**|**MultiModal Action Conditioned Video Generation**|Yichen Li,...Antonio Torralba|[2510.02287](http://arxiv.org/abs/2510.02287)|null|
|**2025-10-02**|**SoundReactor: Frame-level Online Video-to-Audio Generation**|Koichi Saito,...Yuki Mitsufuji|[2510.02110](http://arxiv.org/abs/2510.02110)|null|
|**2025-10-02**|**FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion Deblurring**|Xiaoyang Liu,...Yulun Zhang|[2510.01641](http://arxiv.org/abs/2510.01641)|null|
|**2025-10-01**|**EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory**|Jiahao Wang,...Jieneng Chen|[2510.01183](http://arxiv.org/abs/2510.01183)|**[link](https://github.com/JiahaoPlus/EvoWorld)**|
|**2025-10-01**|**TOUCAN: Synthesizing 1.5M Tool-Agentic Data from Real-World MCP Environments**|Zhangchen Xu,...Rameswar Panda|[2510.01179](http://arxiv.org/abs/2510.01179)|null|
|**2025-10-01**|**Can World Models Benefit VLMs for World Dynamics?**|Kevin Zhang,...Shanghang Zhang|[2510.00855](http://arxiv.org/abs/2510.00855)|**[link](https://dyva-worldlm.github.io)**|
|**2025-10-01**|**TD-JEPA: Latent-predictive Representations for Zero-Shot Reinforcement Learning**|Marco Bagatella,...Andrea Tirinzoni|[2510.00739](http://arxiv.org/abs/2510.00739)|null|
|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Hengtao Li,...Weihua Su|[2510.00406](http://arxiv.org/abs/2510.00406)|null|
|**2025-09-30**|**BigBang-Proton Technical Report: Next-Word-Prediction is Scientific Multitask Learner**|Hengkui Wu,...Weipeng Xu|[2510.00129](http://arxiv.org/abs/2510.00129)|null|
|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|
|**2025-09-30**|**Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models**|Eric R. Damm,...Thomas M. Howard|[2509.26339](http://arxiv.org/abs/2509.26339)|null|
|**2025-10-01**|**ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning**|Yichao Liang,...Kevin Ellis|[2509.26255](http://arxiv.org/abs/2509.26255)|null|
|**2025-10-02**|**World Model for AI Autonomous Navigation in Mechanical Thrombectomy**|Harry Robertshaw,...Thomas C Booth|[2509.25518](http://arxiv.org/abs/2509.25518)|null|
|**2025-09-29**|**From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models**|Chenyue Zhou,...Yike Guo|[2509.25373](http://arxiv.org/abs/2509.25373)|null|
|**2025-09-29**|**Toward Causal-Visual Programming: Enhancing Agentic Reasoning in Low-Code Environments**|Jiexi Xu,...Su Liu|[2509.25282](http://arxiv.org/abs/2509.25282)|null|
|**2025-09-29**|**Rolling Forcing: Autoregressive Long Video Diffusion in Real Time**|Kunhao Liu,...Shijian Lu|[2509.25161](http://arxiv.org/abs/2509.25161)|**[link](https://kunhao-liu.github.io/Rolling_Forcing_Webpage/)**|
|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|
|**2025-09-29**|**DyMoDreamer: World Modeling with Dynamic Modulation**|Boxuan Zhang,...Gang Wang|[2509.24804](http://arxiv.org/abs/2509.24804)|null|
|**2025-09-29**|**PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control**|Haozhuo Zhang,...Wei Pan|[2509.24591](http://arxiv.org/abs/2509.24591)|null|
|**2025-09-29**|**Emergent World Representations in OpenVLA**|Marco Molinari,...Omar G. Younis|[2509.24559](http://arxiv.org/abs/2509.24559)|null|
|**2025-09-29**|**Training Agents Inside of Scalable World Models**|Danijar Hafner,...Timothy Lillicrap|[2509.24527](http://arxiv.org/abs/2509.24527)|**[link](https://danijar.com/dreamer4/)**|
|**2025-09-29**|**Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning**|Korbinian Moller,...Johannes Betz|[2509.24313](http://arxiv.org/abs/2509.24313)|null|
|**2025-09-29**|**FreeAction: Training-Free Techniques for Enhanced Fidelity of Trajectory-to-Video Generation**|Seungwook Kim,...Minsu Cho|[2509.24241](http://arxiv.org/abs/2509.24241)|null|
|**2025-09-30**|**Dual-Scale World Models for LLM Agents Towards Hard-Exploration Problems**|Minsoo Kim,...Seung-won Hwang|[2509.24116](http://arxiv.org/abs/2509.24116)|null|
|**2025-09-28**|**ByteSized32Refactored: Towards an Extensible Interactive Text Games Corpus for LLM World Modeling and Evaluation**|Haonan Wang,...Ziang Xiao|[2509.23979](http://arxiv.org/abs/2509.23979)|null|
|**2025-09-28**|**Reinforcement Learning with Inverse Rewards for World Model Post-training**|Yang Ye,...Jiang Bian|[2509.23958](http://arxiv.org/abs/2509.23958)|null|
|**2025-10-01**|**Mapping Overlaps in Benchmarks through Perplexity in the Wild**|Siyang Wu,...James A. Evans|[2509.23488](http://arxiv.org/abs/2509.23488)|null|
|**2025-09-27**|**ARSS: Taming Decoder-only Autoregressive Visual Generation for View Synthesis From Single View**|Wenbin Teng,...Yajie Zhao|[2509.23008](http://arxiv.org/abs/2509.23008)|null|
|**2025-09-26**|**Model Context Protocol for Vision Systems: Audit, Security, and Protocol Extensions**|Aditi Tiwari,...Darshan Prasad|[2509.22814](http://arxiv.org/abs/2509.22814)|null|
|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo,...Ziwei Wang|[2509.22643](http://arxiv.org/abs/2509.22643)|null|
|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Xiaowei Chi,...Jian Tang|[2509.22642](http://arxiv.org/abs/2509.22642)|null|
|**2025-09-26**|**Context and Diversity Matter: The Emergence of In-Context Learning in World Models**|Fan Wang,...Yu Kang|[2509.22353](http://arxiv.org/abs/2509.22353)|null|
|**2025-09-30**|**MoWM: Mixture-of-World-Models for Embodied Planning via Latent-to-Pixel Feature Modulation**|Yu Shang,...Yong Li|[2509.21797](http://arxiv.org/abs/2509.21797)|null|
|**2025-09-26**|**LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE**|Yu Shang,...Yong Li|[2509.21790](http://arxiv.org/abs/2509.21790)|null|
|**2025-09-25**|**FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction**|Yixiang Dai,...Yonggang Qi|[2509.21657](http://arxiv.org/abs/2509.21657)|null|
|**2025-09-25**|**What Happens Next? Anticipating Future Motion by Generating Point Trajectories**|Gabrijel Boduljak,...Andrea Vedaldi|[2509.21592](http://arxiv.org/abs/2509.21592)|null|
|**2025-09-25**|**X-Streamer: Unified Human World Modeling with Audiovisual Interaction**|You Xie,...Linjie Luo|[2509.21574](http://arxiv.org/abs/2509.21574)|**[link](https://byteaigc.github.io/X-Streamer)**|
|**2025-09-25**|**KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models**|Sibo Li,...Yong Li|[2509.21027](http://arxiv.org/abs/2509.21027)|null|
|**2025-09-25**|**CORE: Full-Path Evaluation of LLM Agents Beyond Final State**|Panagiotis Michelakis,...Dimitrios Stamoulis|[2509.20998](http://arxiv.org/abs/2509.20998)|null|
|**2025-09-24**|**Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation**|Satyajeet Das,...Gaurav S. Sukhatme|[2509.20623](http://arxiv.org/abs/2509.20623)|null|
|**2025-09-24**|**Embodied AI: From LLMs to World Models**|Tongtong Feng,...Wenwu Zhu|[2509.20021](http://arxiv.org/abs/2509.20021)|null|
|**2025-09-23**|**AnySafe: Adapting Latent Safety Filters at Runtime via Safety Constraint Parameterization in the Latent Space**|Sankalp Agrawal,...Andrea Bajcsy|[2509.19555](http://arxiv.org/abs/2509.19555)|null|
|**2025-09-23**|**DAWM: Diffusion Action World Models for Offline Reinforcement Learning via Action-Inferred Transitions**|Zongyue Li,...Matthias Schubert|[2509.19538](http://arxiv.org/abs/2509.19538)|null|
|**2025-09-23**|**World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation**|Zhennan Jiang,...Dongbin Zhao|[2509.19080](http://arxiv.org/abs/2509.19080)|null|
|**2025-09-23**|**Position: Human-Robot Interaction in Embodied Intelligence Demands a Shift From Static Privacy Controls to Dynamic Learning**|Shuning Zhang,...Hewu Li|[2509.19041](http://arxiv.org/abs/2509.19041)|null|
|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Bahey Tharwat,...Ian Reid|[2509.18428](http://arxiv.org/abs/2509.18428)|null|
|**2025-09-27**|**Remote Sensing-Oriented World Model**|Yuxi Lu,...Bin Liang|[2509.17808](http://arxiv.org/abs/2509.17808)|null|
|**2025-09-23**|**Program Synthesis via Test-Time Transduction**|Kang-il Lee,...Kyomin Jung|[2509.17393](http://arxiv.org/abs/2509.17393)|null|
|**2025-09-19**|**Polarized Signatures of Variable Worlds: Modeling Heterogeneous Habitable Earth- and Early Mars-like (Exo)planets**|Kenneth E. Goodis Gordon,...Eric T. Wolf|[2509.16338](http://arxiv.org/abs/2509.16338)|null|
|**2025-09-19**|**Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds**|Remo Sasso,...Paulo Rauber|[2509.15915](http://arxiv.org/abs/2509.15915)|null|
|**2025-09-19**|**SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models**|Sen Wang,...Hua Gang|[2509.15536](http://arxiv.org/abs/2509.15536)|null|
|**2025-09-18**|**OpenViGA: Video Generation for Automotive Driving Scenes by Streamlining and Fine-Tuning Open Source Models with Public Data**|Björn Möller,...Tim Fingscheidt|[2509.15479](http://arxiv.org/abs/2509.15479)|null|
|**2025-09-18**|**Designing Latent Safety Filters using Pre-Trained Vision Models**|Ihab Tabbara,...Hussein Sibai|[2509.14758](http://arxiv.org/abs/2509.14758)|null|
|**2025-09-17**|**PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models**|Artem Lykov,...Dzmitry Tsetserukou|[2509.13903](http://arxiv.org/abs/2509.13903)|null|
|**2025-09-25**|**From Next Token Prediction to (STRIPS) World Models -- Preliminary Results**|Carlos Núñez-Molina,...Hector Geffner|[2509.13389](http://arxiv.org/abs/2509.13389)|null|
|**2025-09-16**|**A tree-based Polynomial Chaos expansion for surrogate modeling and sensitivity analysis of complex numerical models**|Faten Ben Said,...Fabrice Zaoui|[2509.13384](http://arxiv.org/abs/2509.13384)|null|
|**2025-09-26**|**Empowering Multi-Robot Cooperation via Sequential World Models**|Zijie Zhao,...Dongbin Zhao|[2509.13095](http://arxiv.org/abs/2509.13095)|null|

<p align=right>(<a href=#updated-on-20251008>back to top</a>)</p>

## VLM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-10-06**|**Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization**|Omri Uzan,...Ariel Gera|[2510.05038](http://arxiv.org/abs/2510.05038)|null|
|**2025-10-06**|**Efficient Navigation in Unknown Indoor Environments with Vision-Language Models**|D. Schwartz,...J. P. How|[2510.04991](http://arxiv.org/abs/2510.04991)|null|
|**2025-10-06**|**ViTs: Teaching Machines to See Time Series Anomalies Like Human Experts**|Zexin Wang,...Dan Pei|[2510.04710](http://arxiv.org/abs/2510.04710)|null|
|**2025-10-06**|**Conditional Representation Learning for Customized Tasks**|Honglin Liu,...Xi Peng|[2510.04564](http://arxiv.org/abs/2510.04564)|null|
|**2025-10-06**|**More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models**|Xurui Song,...Jun Luo|[2510.04532](http://arxiv.org/abs/2510.04532)|null|
|**2025-10-06**|**VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery**|Nonghai Zhang,...Hao Tang|[2510.04479](http://arxiv.org/abs/2510.04479)|null|
|**2025-10-06**|**MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models**|Soo Yong Kim,...Gyeongyeon Hwang|[2510.04477](http://arxiv.org/abs/2510.04477)|null|
|**2025-10-06**|**A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering**|Yuanhao Zou,...Chen Chen|[2510.04428](http://arxiv.org/abs/2510.04428)|null|
|**2025-10-06**|**Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting**|Xuyang Guo,...Jiahao Zhang|[2510.04401](http://arxiv.org/abs/2510.04401)|null|
|**2025-10-05**|**AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents**|Yanjie Li,...Bin Xiao|[2510.04257](http://arxiv.org/abs/2510.04257)|null|
|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Huiwon Jang,...Jinwoo Shin|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|
|**2025-10-05**|**Zoom-In to Sort AI-Generated Images Out**|Yikun Ji,...Jianfu Zhang|[2510.04225](http://arxiv.org/abs/2510.04225)|null|
|**2025-10-05**|**Automating construction safety inspections using a multi-modal vision-language RAG framework**|Chenxin Wang,...Daniel Dias-da-Costa|[2510.04145](http://arxiv.org/abs/2510.04145)|null|
|**2025-10-07**|**AgriGPT-VL: Agricultural Vision-Language Understanding Suite**|Bo Yang,...Shijian Li|[2510.04002](http://arxiv.org/abs/2510.04002)|null|
|**2025-10-04**|**No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models**|Min Woo Sun,...Serena Yeung-Levy|[2510.03978](http://arxiv.org/abs/2510.03978)|null|
|**2025-10-04**|**Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models**|Md. Atabuzzaman,...Chris Thomas|[2510.03903](http://arxiv.org/abs/2510.03903)|null|
|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Mingyu Liu,...Chunhua Shen|[2510.03896](http://arxiv.org/abs/2510.03896)|null|
|**2025-10-04**|**Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models**|Pranav Sharma,...Durga Toshniwal|[2510.03840](http://arxiv.org/abs/2510.03840)|null|
|**2025-10-04**|**Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models**|Leander Girrbach,...Zeynep Akata|[2510.03721](http://arxiv.org/abs/2510.03721)|null|
|**2025-10-04**|**MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations**|Jiang Wu,...Jingliang Duan|[2510.03666](http://arxiv.org/abs/2510.03666)|null|
|**2025-10-03**|**Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning**|Yilun Hao,...Yang Zhang|[2510.03182](http://arxiv.org/abs/2510.03182)|null|
|**2025-10-03**|**SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus**|Ming Zhao,...Caifeng Shan|[2510.03160](http://arxiv.org/abs/2510.03160)|null|
|**2025-10-03**|**Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights**|Daphne Tsolissou,...Konstantina Nikita|[2510.02922](http://arxiv.org/abs/2510.02922)|null|
|**2025-10-03**|**Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting**|Nikoo Naghavian,...Mostafa Tavassolipour|[2510.02913](http://arxiv.org/abs/2510.02913)|null|
|**2025-10-03**|**Med-K2N: Flexible K-to-N Modality Translation for Medical Image Synthesis**|Feng Yuan,...Xin Gao|[2510.02815](http://arxiv.org/abs/2510.02815)|null|
|**2025-10-03**|**MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding**|Jingyuan Deng,...Yujiu Yang|[2510.02790](http://arxiv.org/abs/2510.02790)|null|
|**2025-10-03**|**OTR: Synthesizing Overlay Text Dataset for Text Removal**|Jan Zdenek,...Kota Yamaguchi|[2510.02787](http://arxiv.org/abs/2510.02787)|**[link](https://doi.org/10.1145/3746027.3758297)**|
|**2025-10-03**|**Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models**|Prahitha Movva,...Prahitha Movva|[2510.02780](http://arxiv.org/abs/2510.02780)|null|
|**2025-10-03**|**AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding**|Xian Zhang,...Mohammed Bennamoun|[2510.02778](http://arxiv.org/abs/2510.02778)|null|
|**2025-10-03**|**Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models**|Lihua Zhou,...Zhen Lei|[2510.02750](http://arxiv.org/abs/2510.02750)|null|
|**2025-10-03**|**Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4**|Lingfeng Zhang,...Xiaoshuai Hao|[2510.02728](http://arxiv.org/abs/2510.02728)|null|
|**2025-10-03**|**ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks**|Zhaorun Chen,...Bo Li|[2510.02677](http://arxiv.org/abs/2510.02677)|null|
|**2025-10-02**|**Exploring OCR-augmented Generation for Bilingual VQA**|JoonHo Lee,...Sunho Park|[2510.02543](http://arxiv.org/abs/2510.02543)|null|
|**2025-10-02**|**Multimodal Function Vectors for Spatial Relations**|Shuhao Fu,...Hongjing Lu|[2510.02528](http://arxiv.org/abs/2510.02528)|null|
|**2025-10-02**|**From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens**|Hala Sheta,...Freda Shi|[2510.02292](http://arxiv.org/abs/2510.02292)|**[link](https://github.com/compling-wat/vlm-lens)**|
|**2025-10-02**|**microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification**|Sathira Silva,...Muhammad Haris Khan|[2510.02270](http://arxiv.org/abs/2510.02270)|null|
|**2025-10-02**|**Say One Thing, Do Another? Diagnosing Reasoning-Execution Gaps in VLM-Powered Mobile-Use Agents**|Lingzhong Dong,...Zhuosheng Zhang|[2510.02204](http://arxiv.org/abs/2510.02204)|null|
|**2025-10-02**|**GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation**|Weijia Dou,...Heng Tao Shen|[2510.02186](http://arxiv.org/abs/2510.02186)|null|
|**2025-10-02**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Shu Zou,...Jing Zhang|[2510.02155](http://arxiv.org/abs/2510.02155)|null|
|**2025-10-02**|**Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving**|Haibo Hu,...Chun Jason Xue|[2510.01795](http://arxiv.org/abs/2510.01795)|null|
|**2025-10-02**|**Accelerating Attention with Basis Decomposition**|Jialin Zhao,...Jialin Zhao|[2510.01718](http://arxiv.org/abs/2510.01718)|null|
|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim,...Jinwoo Shin|[2510.01711](http://arxiv.org/abs/2510.01711)|null|
|**2025-10-02**|**VaPR -- Vision-language Preference alignment for Reasoning**|Rohan Wadhawan,...Nanyun Peng|[2510.01700](http://arxiv.org/abs/2510.01700)|null|
|**2025-10-02**|**Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning**|Xuchen Li,...Wentao Zhang|[2510.01681](http://arxiv.org/abs/2510.01681)|null|
|**2025-10-02**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon,...Kutluyil Dogancay|[2510.01649](http://arxiv.org/abs/2510.01649)|null|
|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin,...Bihan Wen|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|
|**2025-10-02**|**ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models**|Krishna Teja Chitty-Venkata,...Murali Emani|[2510.01582](http://arxiv.org/abs/2510.01582)|null|
|**2025-10-03**|**Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed**|Isha Gupta,...Sanmi Koyejo|[2510.01494](http://arxiv.org/abs/2510.01494)|null|
|**2025-10-01**|**VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs**|Mohamad Al Mdfaa,...Gonzalo Ferrer|[2510.01483](http://arxiv.org/abs/2510.01483)|null|
|**2025-10-01**|**Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories**|Nilay Naharas,...Baharan Mirzasoleiman|[2510.01454](http://arxiv.org/abs/2510.01454)|**[link](https://bigml-cs-ucla.github.io/XMAS-project-page/)**|
|**2025-10-01**|**GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings**|Angel Daruna,...Rakesh Kumar|[2510.01448](http://arxiv.org/abs/2510.01448)|null|
|**2025-10-01**|**VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation**|Arthur Zhang,...Amirreza Shaban|[2510.01388](http://arxiv.org/abs/2510.01388)|null|
|**2025-10-01**|**Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models**|Yu Zeng,...Feng Zhao|[2510.01304](http://arxiv.org/abs/2510.01304)|null|
|**2025-10-01**|**Dirichlet-Prior Shaping: Guiding Expert Specialization in Upcycled MoEs**|Leyla Mirvakhabova,...Paul Whatmough|[2510.01185](http://arxiv.org/abs/2510.01185)|null|
|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|
|**2025-09-30**|**Query-Kontext: An Unified Multimodal Model for Image Generation and Editing**|Yuxin Song,...Jingdong Wang|[2509.26641](http://arxiv.org/abs/2509.26641)|null|
|**2025-09-30**|**Clarification as Supervision: Reinforcement Learning for Vision-Language Interfaces**|John Gkountouras,...Ivan Titov|[2509.26594](http://arxiv.org/abs/2509.26594)|null|
|**2025-09-30**|**The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows**|Litao Yan,...Emerson Murphy-Hill|[2509.26557](http://arxiv.org/abs/2509.26557)|null|
|**2025-09-30**|**Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation**|Agneet Chatterjee,...Varun Jampani|[2509.26555](http://arxiv.org/abs/2509.26555)|**[link](https://stable-cinemetrics.github.io/)**|
|**2025-09-30**|**Zero-Shot Decentralized Federated Learning**|Alessio Masano,...Giovanni Bellitto|[2509.26462](http://arxiv.org/abs/2509.26462)|**[link](https://github.com/perceivelab/ZeroDFL)**|
|**2025-09-30**|**SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval**|Ren-Di Wu,...Huei-Fang Yang|[2509.26330](http://arxiv.org/abs/2509.26330)|null|
|**2025-09-30**|**ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation**|Edoardo Bianchi,...Antonio Liotta|[2509.26278](http://arxiv.org/abs/2509.26278)|null|
|**2025-09-30**|**Interpret, prune and distill Donut : towards lightweight VLMs for VQA on document**|Adnan Ben Mansour,...David Naccache|[2509.26235](http://arxiv.org/abs/2509.26235)|null|
|**2025-09-30**|**TSalV360: A Method and Dataset for Text-driven Saliency Detection in 360-Degrees Videos**|Ioannis Kontostathis,...Vasileios Mezaris|[2509.26208](http://arxiv.org/abs/2509.26208)|**[link](https://ieeexplore.ieee.org/)**|
|**2025-09-30**|**SGS: Segmentation-Guided Scoring for Global Scene Inconsistencies**|Gagandeep Singh,...Xue Li|[2509.26039](http://arxiv.org/abs/2509.26039)|null|
|**2025-10-01**|**AgenticIQA: An Agentic Framework for Adaptive and Interpretable Image Quality Assessment**|Hanwei Zhu,...Weisi Lin|[2509.26006](http://arxiv.org/abs/2509.26006)|null|
|**2025-09-30**|**Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations**|Nicola Messina,...Antonino Furnari|[2509.26004](http://arxiv.org/abs/2509.26004)|null|
|**2025-09-30**|**Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline**|Haiyang Li,...Zhun Zhong|[2509.25991](http://arxiv.org/abs/2509.25991)|null|
|**2025-09-30**|**NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving**|Yuan Gao,...Johannes Betz|[2509.25944](http://arxiv.org/abs/2509.25944)|null|
|**2025-09-30**|**VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs**|Peng Liu,...Tiancheng Zhao|[2509.25916](http://arxiv.org/abs/2509.25916)|null|
|**2025-10-01**|**LLaVAShield: Safeguarding Multimodal Multi-Turn Dialogues in Vision-Language Models**|Guolei Huang,...Yongjun Shen|[2509.25896](http://arxiv.org/abs/2509.25896)|null|
|**2025-09-30**|**DeepSketcher: Internalizing Visual Manipulation for Multimodal Reasoning**|Chi Zhang,...Jing Zhang|[2509.25866](http://arxiv.org/abs/2509.25866)|null|
|**2025-09-30**|**MAPLE: Multi-scale Attribute-enhanced Prompt Learning for Few-shot Whole Slide Image Classification**|Junjie Zhou,...Daoqiang Zhang|[2509.25863](http://arxiv.org/abs/2509.25863)|null|
|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Zitong Bo,...Hao Chen|[2509.25852](http://arxiv.org/abs/2509.25852)|null|
|**2025-09-29**|**TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models**|Junyi Zhang,...Nanyun Peng|[2509.25143](http://arxiv.org/abs/2509.25143)|null|
|**2025-09-29**|**Visual serial processing deficits explain divergences in human and VLM reasoning**|Nicholas Budny,...Thomas L. Griffiths|[2509.25142](http://arxiv.org/abs/2509.25142)|null|
|**2025-09-29**|**GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning**|Mustansar Fiaz,...Salman Khan|[2509.25026](http://arxiv.org/abs/2509.25026)|**[link](https://mustansarfiaz.github.io/GeoVLM-R1/)**|
|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|
|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Markus Peschl,...Daniel Dijkman|[2509.24917](http://arxiv.org/abs/2509.24917)|null|
|**2025-09-29**|**Training-Free Token Pruning via Zeroth-Order Gradient Estimation in Vision-Language Models**|Youngeun Kim,...Sungeun Hong|[2509.24837](http://arxiv.org/abs/2509.24837)|null|
|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Eric Hannus,...Ville Kyrki|[2509.24768](http://arxiv.org/abs/2509.24768)|null|
|**2025-09-29**|**IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?**|Yang Chen,...Botian Shi|[2509.24709](http://arxiv.org/abs/2509.24709)|null|
|**2025-09-29**|**Can you SPLICE it together? A Human Curated Benchmark for Probing Visual Reasoning in VLMs**|Mohamad Ballout,...Elia Bruni|[2509.24640](http://arxiv.org/abs/2509.24640)|null|
|**2025-09-30**|**Inducing Dyslexia in Vision Language Models**|Melika Honarmand,...Martin Schrimpf|[2509.24597](http://arxiv.org/abs/2509.24597)|null|
|**2025-09-29**|**TokenSwap: Backdoor Attack on the Compositional Understanding of Large Vision-Language Models**|Zhifang Zhang,...Joey Tianyi Zhou|[2509.24566](http://arxiv.org/abs/2509.24566)|null|
|**2025-09-29**|**CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D**|Mohamad Amin Mirzaei,...Matin Mirzababaei|[2509.24528](http://arxiv.org/abs/2509.24528)|null|
|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Zhihao Wang,...Xianyuan Zhan|[2509.24524](http://arxiv.org/abs/2509.24524)|null|
|**2025-09-29**|**GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training**|Hongcheng Wang,...Hao Dong|[2509.24494](http://arxiv.org/abs/2509.24494)|null|
|**2025-09-29**|**Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks**|Shijie Lian,...Kai Chen|[2509.24473](http://arxiv.org/abs/2509.24473)|null|
|**2025-09-29**|**AXIS: Explainable Time Series Anomaly Detection with Large Language Models**|Tian Lan,...Chen Zhang|[2509.24378](http://arxiv.org/abs/2509.24378)|null|
|**2025-09-29**|**SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm**|Yao Wang,...Jiankun Wang|[2509.24321](http://arxiv.org/abs/2509.24321)|null|
|**2025-09-30**|**FrameThinker: Learning to Think with Long Videos via Multi-Turn Frame Spotlighting**|Zefeng He,...Yu Cheng|[2509.24304](http://arxiv.org/abs/2509.24304)|null|
|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Tomoyuki Kagaya,...Yang You|[2509.24219](http://arxiv.org/abs/2509.24219)|null|
|**2025-09-29**|**Talk in Pieces, See in Whole: Disentangling and Hierarchical Aggregating Representations for Language-based Object Detection**|Sojung An,...Donghyun Kim|[2509.24192](http://arxiv.org/abs/2509.24192)|null|
|**2025-09-26**|**See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation**|Chih Yao Hu,...Yu-Lun Liu|[2509.22653](http://arxiv.org/abs/2509.22653)|**[link](https://spf-web.pages.dev)**|
|**2025-09-26**|**CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning**|Long Xing,...Dahua Lin|[2509.22647](http://arxiv.org/abs/2509.22647)|**[link](https://github.com/InternLM/CapRL)**|
|**2025-09-26**|**Hierarchical Representation Matching for CLIP-based Class-Incremental Learning**|Zhen-Hao Wen,...Da-Wei Zhou|[2509.22645](http://arxiv.org/abs/2509.22645)|null|
|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Xiaowei Chi,...Jian Tang|[2509.22642](http://arxiv.org/abs/2509.22642)|null|
|**2025-09-26**|**SPARK: Synergistic Policy And Reward Co-Evolving Framework**|Ziyu Liu,...Jiaqi Wang|[2509.22624](http://arxiv.org/abs/2509.22624)|**[link](https://github.com/InternLM/Spark)**|
|**2025-09-26**|**Color Names in Vision-Language Models**|Alexandra Gomez-Villa,...Javier Vazquez-Corral|[2509.22524](http://arxiv.org/abs/2509.22524)|null|
|**2025-09-26**|**Guiding Evolution of Artificial Life Using Vision-Language Models**|Nikhil Baid,...Frederico Wieser|[2509.22447](http://arxiv.org/abs/2509.22447)|null|
|**2025-09-26**|**Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding**|Ziheng Chi,...Mrinmaya Sachan|[2509.22437](http://arxiv.org/abs/2509.22437)|**[link](https://github.com/CHIzhP/Chimera))**|
|**2025-09-26**|**RAU: Reference-based Anatomical Understanding with Vision Language Models**|Yiwei Li,...Shanhui Sun|[2509.22404](http://arxiv.org/abs/2509.22404)|null|
|**2025-09-26**|**Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach**|Zijian Zhao,...Zijing Zhou|[2509.22378](http://arxiv.org/abs/2509.22378)|null|
|**2025-09-26**|**Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models**|Michael Jungo,...Andreas Fischer|[2509.22283](http://arxiv.org/abs/2509.22283)|**[link](https://github.com/jungomi/vision-finetune)**|
|**2025-09-26**|**Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks**|Miao Jing,...Shangyang Li|[2509.22258](http://arxiv.org/abs/2509.22258)|null|
|**2025-09-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu,...Cheng Deng|[2509.22229](http://arxiv.org/abs/2509.22229)|null|
|**2025-09-26**|**Polysemous Language Gaussian Splatting via Matching-based Mask Lifting**|Jiayu Ding,...Ge Li|[2509.22225](http://arxiv.org/abs/2509.22225)|null|
|**2025-09-26**|**Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models**|Jiaqi Liu,...Bo Yang|[2509.22221](http://arxiv.org/abs/2509.22221)|null|
|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Asher J. Hancock,...Anirudha Majumdar|[2509.22195](http://arxiv.org/abs/2509.22195)|null|
|**2025-09-26**|**MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing**|Junbo Niu,...Conghui He|[2509.22186](http://arxiv.org/abs/2509.22186)|**[link](https://github.com/opendatalab/MinerU)**|
|**2025-09-26**|**Multilingual Vision-Language Models, A Survey**|Andrei-Alexandru Manea,...Jindřich Libovický|[2509.22123](http://arxiv.org/abs/2509.22123)|null|
|**2025-09-26**|**Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics**|Saurav Jha,...Stefan K. Ehrlich|[2509.22014](http://arxiv.org/abs/2509.22014)|null|
|**2025-09-26**|**CoFFT: Chain of Foresight-Focus Thought for Visual Language Models**|Xinyu Zhang,...Mike Zheng Shou|[2509.22010](http://arxiv.org/abs/2509.22010)|null|
|**2025-09-25**|**Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive Cross-Stage Parallelization**|Yuhang Xu,...Guihai Chen|[2509.21301](http://arxiv.org/abs/2509.21301)|null|
|**2025-09-25**|**DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding**|Kin Ian Lo,...Mehrnoosh Sadrzadeh|[2509.21287](http://arxiv.org/abs/2509.21287)|null|
|**2025-09-25**|**Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication**|Evgeny Kaskov,...Alexander Nagaev|[2509.21262](http://arxiv.org/abs/2509.21262)|null|
|**2025-09-25**|**Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation**|Seyed Amir Kasaei,...Mohammad Hossein Rohban|[2509.21257](http://arxiv.org/abs/2509.21257)|null|
|**2025-09-25**|**Learning to Look: Cognitive Attention Alignment with Vision-Language Models**|Ryan L. Yang,...Nidhi Rastogi|[2509.21247](http://arxiv.org/abs/2509.21247)|null|
|**2025-09-25**|**TABLET: A Large-Scale Dataset for Robust Visual Table Understanding**|Iñigo Alonso,...Mirella Lapata|[2509.21205](http://arxiv.org/abs/2509.21205)|null|
|**2025-09-25**|**Human-like Navigation in a World Built for Humans**|Bhargav Chandaka,...Shenlong Wang|[2509.21189](http://arxiv.org/abs/2509.21189)|**[link](https://reasonnav.github.io/)**|
|**2025-09-25**|**Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy**|Aymen Bouguerra,...Chokri Mraidha|[2509.21173](http://arxiv.org/abs/2509.21173)|null|
|**2025-09-25**|**Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning**|Xiefeng Wu,...Mingyu Hu|[2509.21126](http://arxiv.org/abs/2509.21126)|null|
|**2025-09-25**|**Cross-Modal Instructions for Robot Motion Generation**|William Barron,...Weiming Zhi|[2509.21107](http://arxiv.org/abs/2509.21107)|null|
|**2025-09-25**|**Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models**|Suaiba Amina Salahuddin,...Robert Jenssen|[2509.21102](http://arxiv.org/abs/2509.21102)|null|
|**2025-09-25**|**SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials**|Qixin Wan,...Lu Cheng|[2509.21079](http://arxiv.org/abs/2509.21079)|null|
|**2025-09-25**|**Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos**|Sarmistha Das,...Alka Maurya|[2509.20961](http://arxiv.org/abs/2509.20961)|null|
|**2025-09-25**|**Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery**|Angelo Henriques,...M. Ali Nasseri|[2509.20941](http://arxiv.org/abs/2509.20941)|null|
|**2025-09-25**|**MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases**|Ziang Luo,...Diange Yang|[2509.20843](http://arxiv.org/abs/2509.20843)|null|
|**2025-09-25**|**DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation**|Ved Umrajkar,...Ved Umrajkar|[2509.20792](http://arxiv.org/abs/2509.20792)|null|
|**2025-09-25**|**Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems**|Tuo Zhang,...Ruiliang Liu|[2509.20769](http://arxiv.org/abs/2509.20769)|null|
|**2025-09-25**|**Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models**|Zoe Wanying He,...Meenakshi Khosla|[2509.20751](http://arxiv.org/abs/2509.20751)|null|
|**2025-09-25**|**Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery**|Yiming Xiao,...Ali Mostafavi|[2509.20628](http://arxiv.org/abs/2509.20628)|null|
|**2025-09-24**|**InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On**|Julien Han,...Karim Bouyarmane|[2509.20524](http://arxiv.org/abs/2509.20524)|null|

<p align=right>(<a href=#updated-on-20251008>back to top</a>)</p>

## VLA

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-10-06**|**HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks**|Zheng Xiong,...Shimon Whiteson|[2510.04898](http://arxiv.org/abs/2510.04898)|null|
|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Huiwon Jang,...Jinwoo Shin|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|
|**2025-10-05**|**SITCOM: Scaling Inference-Time COMpute for VLAs**|Ayudh Saxena,...Esha Pahwa|[2510.04041](http://arxiv.org/abs/2510.04041)|null|
|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Mingyu Liu,...Chunhua Shen|[2510.03896](http://arxiv.org/abs/2510.03896)|null|
|**2025-10-04**|**NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation**|Zheng Huang,...Chunhua Shen|[2510.03895](http://arxiv.org/abs/2510.03895)|null|
|**2025-10-04**|**LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization**|Xueyang Zhou,...Lichao Sun|[2510.03827](http://arxiv.org/abs/2510.03827)|null|
|**2025-10-02**|**Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer**|Abbas Abdolmaleki,...Yuxiang Zhou|[2510.03342](http://arxiv.org/abs/2510.03342)|null|
|**2025-10-03**|**MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning**|Tianyu Xu,...He Wang|[2510.03142](http://arxiv.org/abs/2510.03142)|**[link](https://pku-epic.github.io/MM-Nav-Web/)**|
|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim,...Jinwoo Shin|[2510.01711](http://arxiv.org/abs/2510.01711)|null|
|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin,...Bihan Wen|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|
|**2025-10-02**|**VLA-R1: Enhancing Reasoning in Vision-Language-Action Models**|Angen Ye,...Zheng Zhu|[2510.01623](http://arxiv.org/abs/2510.01623)|null|
|**2025-10-01**|**INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models**|Ulas Berk Karli,...Tesca FItzgerald|[2510.01389](http://arxiv.org/abs/2510.01389)|null|
|**2025-10-01**|**Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition**|Jiahang Cao,...Andrew F. Luo|[2510.01068](http://arxiv.org/abs/2510.01068)|**[link](https://sagecao1125.github.io/GPC-Site/)**|
|**2025-10-02**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Myungkyu Koo,...Jinwoo Shin|[2510.00695](http://arxiv.org/abs/2510.00695)|**[link](https://myungkyukoo.github.io/hamlet/)**|
|**2025-10-01**|**Hybrid Training for Vision-Language-Action Models**|Pietro Mazzaglia,...Daniel Dijkman|[2510.00600](http://arxiv.org/abs/2510.00600)|null|
|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Hengtao Li,...Weihua Su|[2510.00406](http://arxiv.org/abs/2510.00406)|null|
|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|
|**2025-09-30**|**Seeing Space and Motion: Enhancing Latent Actions with Spatial and Dynamic Awareness for VLA**|Zhejia Cai,...Ruqi Huang|[2509.26251](http://arxiv.org/abs/2509.26251)|null|
|**2025-09-30**|**MUVLA: Learning to Explore Object Navigation via Map Understanding**|Peilong Han,...Jianye Hao|[2509.25966](http://arxiv.org/abs/2509.25966)|null|
|**2025-09-30**|**TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses**|Shuaijun Wang,...Yangwei You|[2509.25746](http://arxiv.org/abs/2509.25746)|null|
|**2025-09-30**|**VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning**|Si-Cheng Wang,...Zeng-Guang Hou|[2509.25718](http://arxiv.org/abs/2509.25718)|null|
|**2025-09-30**|**dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought**|Junjie Wen,...Yi Xu|[2509.25681](http://arxiv.org/abs/2509.25681)|null|
|**2025-09-29**|**AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation**|Ryosuke Takanami,...Tetsuya Ogata|[2509.25032](http://arxiv.org/abs/2509.25032)|null|
|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|
|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Eric Hannus,...Ville Kyrki|[2509.24768](http://arxiv.org/abs/2509.24768)|null|
|**2025-09-29**|**Emergent World Representations in OpenVLA**|Marco Molinari,...Omar G. Younis|[2509.24559](http://arxiv.org/abs/2509.24559)|null|
|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Zhihao Wang,...Xianyuan Zhan|[2509.24524](http://arxiv.org/abs/2509.24524)|null|
|**2025-09-28**|**AutoPrune: Each Complexity Deserves a Pruning Policy**|Hanshi Wang,...Zhipeng Zhang|[2509.23931](http://arxiv.org/abs/2509.23931)|null|
|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Tian Nian,...Bingshan Hu|[2509.23823](http://arxiv.org/abs/2509.23823)|**[link](https://github.com/Tian-Nian/control_your_robot)**|
|**2025-09-28**|**Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models**|Rokas Bendikas,...Pietro Mazzaglia|[2509.23655](http://arxiv.org/abs/2509.23655)|null|
|**2025-09-27**|**Leave No Observation Behind: Real-time Correction for VLA Action Chunks**|Kohei Sendai,...Yusuke Iwasawa|[2509.23224](http://arxiv.org/abs/2509.23224)|null|
|**2025-09-27**|**Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges**|Shuai Li,...Zhibo Pang|[2509.23121](http://arxiv.org/abs/2509.23121)|null|
|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo,...Ziwei Wang|[2509.22643](http://arxiv.org/abs/2509.22643)|null|
|**2025-09-26**|**UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation**|Zhangyuan Wang,...Dixia Fan|[2509.22441](http://arxiv.org/abs/2509.22441)|null|
|**2025-09-26**|**EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer**|Zhehao Dong,...Guan Huang|[2509.22407](http://arxiv.org/abs/2509.22407)|null|
|**2025-09-29**|**MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training**|Haoyun Li,...Xingang Wang|[2509.22199](http://arxiv.org/abs/2509.22199)|null|
|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Asher J. Hancock,...Anirudha Majumdar|[2509.22195](http://arxiv.org/abs/2509.22195)|null|
|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Xiaohuan Pei,...Chang Xu|[2509.22093](http://arxiv.org/abs/2509.22093)|null|
|**2025-09-26**|**Developing Vision-Language-Action Model from Egocentric Videos**|Tomoya Yoshida,...Shinsuke Mori|[2509.21986](http://arxiv.org/abs/2509.21986)|null|
|**2025-09-20**|**KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache**|Wanshun Xu,...Long Zhuang|[2509.21354](http://arxiv.org/abs/2509.21354)|null|
|**2025-09-25**|**RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models**|Jiyeon Koo,...Andrew Jaeyong Choi|[2509.21243](http://arxiv.org/abs/2509.21243)|null|
|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Pengxiang Li,...Xianpeng Lang|[2509.20109](http://arxiv.org/abs/2509.20109)|null|
|**2025-09-24**|**FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models**|Xin Wang,...Yu-Gang Jiang|[2509.19870](http://arxiv.org/abs/2509.19870)|null|
|**2025-09-24**|**Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training**|Rushuai Yang,...Yi Chen|[2509.19752](http://arxiv.org/abs/2509.19752)|null|
|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Sacha Morin,...Liam Paull|[2509.19571](http://arxiv.org/abs/2509.19571)|**[link](https://montrealrobotics.ca/agentic-scene-policies.github.io/)**|
|**2025-09-23**|**OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation**|Noriaki Hirose,...Sergey Levine|[2509.19480](http://arxiv.org/abs/2509.19480)|null|
|**2025-09-25**|**Pure Vision Language Action (VLA) Models: A Comprehensive Survey**|Dapeng Zhang,...Qingguo Zhou|[2509.19012](http://arxiv.org/abs/2509.19012)|null|
|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Hanqing Liu,...Wen Yao|[2509.18953](http://arxiv.org/abs/2509.18953)|null|
|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Bahey Tharwat,...Ian Reid|[2509.18428](http://arxiv.org/abs/2509.18428)|null|
|**2025-09-18**|**VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation**|Jinyue Bian,...Anzhou Hou|[2509.18183](http://arxiv.org/abs/2509.18183)|null|
|**2025-09-19**|**CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine**|Shiyu Fang,...Jian Sun|[2509.15968](http://arxiv.org/abs/2509.15968)|null|
|**2025-09-19**|**A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning**|Shaopeng Zhai,...Jiangmiao Pang|[2509.15937](http://arxiv.org/abs/2509.15937)|null|
|**2025-09-18**|**RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation**|Yuming Jiang,...Xin Li|[2509.15212](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|
|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Tobias Jülg,...Florian Walter|[2509.14932](http://arxiv.org/abs/2509.14932)|null|
|**2025-09-18**|**CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human**|Nan Sun,...Huaping Liu|[2509.14889](http://arxiv.org/abs/2509.14889)|null|
|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Cong Tai,...Tao Shen|[2509.14687](http://arxiv.org/abs/2509.14687)|null|
|**2025-09-18**|**Toward Embodiment Equivariant Vision-Language-Action Policy**|Anzhe Chen,...Yue Wang|[2509.14630](http://arxiv.org/abs/2509.14630)|null|
|**2025-09-17**|**CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping**|Zijian An,...Lifeng Zhou|[2509.14143](http://arxiv.org/abs/2509.14143)|null|
|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Ran Yang,...Yiming Feng|[2509.14138](http://arxiv.org/abs/2509.14138)|null|
|**2025-09-22**|**GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model**|Ali Abouzeid,...Dezhen Song|[2509.14117](http://arxiv.org/abs/2509.14117)|null|

<p align=right>(<a href=#updated-on-20251008>back to top</a>)</p>

## Humanoid

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-10-06**|**Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot**|Aditya Sripada,...Abhishek Warrier|[2510.05001](http://arxiv.org/abs/2510.05001)|null|
|**2025-10-05**|**Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation**|Stephen McCrory,...Robert Griffin|[2510.04353](http://arxiv.org/abs/2510.04353)|null|
|**2025-10-03**|**LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy**|Zekai Liang,...Michael C. Yip|[2510.03529](http://arxiv.org/abs/2510.03529)|null|
|**2025-10-03**|**Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot**|Guiliang Liu,...Kui Jia|[2510.03081](http://arxiv.org/abs/2510.03081)|null|
|**2025-10-03**|**HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton**|Rui Zhong,...Yi Xu|[2510.03022](http://arxiv.org/abs/2510.03022)|null|
|**2025-10-02**|**Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking**|Joao Pedro Araujo,...C. Karen Liu|[2510.02252](http://arxiv.org/abs/2510.02252)|null|
|**2025-10-02**|**Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control**|Philip Reichenberg,...Tim Laue|[2510.02129](http://arxiv.org/abs/2510.02129)|null|
|**2025-10-02**|**Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots**|Wanyue Li,...Peng Lu|[2510.01843](http://arxiv.org/abs/2510.01843)|null|
|**2025-09-30**|**Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning**|Sarmad Mehrdad,...Ludovic Righetti|[2510.00329](http://arxiv.org/abs/2510.00329)|null|
|**2025-09-30**|**OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction**|Lujie Yang,...Guanya Shi|[2509.26633](http://arxiv.org/abs/2509.26633)|**[link](https://omniretarget.github.io)**|
|**2025-09-30**|**ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm**|Benjamin A. Richardson,...Katherine J. Kuchenbecker|[2509.26236](http://arxiv.org/abs/2509.26236)|null|
|**2025-09-30**|**Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance**|Tianyi Jin,...Frank Kirchner|[2509.26082](http://arxiv.org/abs/2509.26082)|null|
|**2025-10-06**|**CoTaP: Compliant Task Pipeline and Reinforcement Learning of Its Controller with Compliance Modulation**|Zewen He,...Yoshihiko Nakamura|[2509.25443](http://arxiv.org/abs/2509.25443)|null|
|**2025-09-29**|**Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering**|Evelyn D'Elia,...Daniele Pucci|[2509.24697](http://arxiv.org/abs/2509.24697)|null|
|**2025-09-29**|**Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game**|Giulia Pusceddu,...Alessandra Sciutti|[2509.24530](http://arxiv.org/abs/2509.24530)|null|
|**2025-09-29**|**Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models**|Wanming Yu,...Sethu Vijayakumar|[2509.24163](http://arxiv.org/abs/2509.24163)|null|
|**2025-09-28**|**SIG-Chat: Spatial Intent-Guided Conversational Gesture Generation Involving How, When and Where**|Yiheng Huang,...Chuanchen Luo|[2509.23852](http://arxiv.org/abs/2509.23852)|null|
|**2025-09-25**|**SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation**|Jaehwi Jang,...Ye Zhao|[2509.21231](http://arxiv.org/abs/2509.21231)|null|
|**2025-09-25**|**RuN: Residual Policy for Natural Humanoid Locomotion**|Qingpeng Li,...Yong Liu|[2509.20696](http://arxiv.org/abs/2509.20696)|null|
|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|Hanna Yurchyk,...David Meger|[2509.20579](http://arxiv.org/abs/2509.20579)|null|
|**2025-09-24**|**VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation**|Shaofeng Yin,...Jiajun Wu|[2509.20322](http://arxiv.org/abs/2509.20322)|**[link](https://visualmimic.github.io)**|
|**2025-09-25**|**HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms**|Bingjie Chen,...Houde Liu|[2509.20263](http://arxiv.org/abs/2509.20263)|null|
|**2025-09-23**|**Chasing Stability: Humanoid Running via Control Lyapunov Function Guided Reinforcement Learning**|Zachary Olkin,...Aaron D. Ames|[2509.19573](http://arxiv.org/abs/2509.19573)|null|
|**2025-09-23**|**RoMoCo: Robotic Motion Control Toolbox for Reduced-Order Model-Based Locomotion on Bipedal and Humanoid Robots**|Min Dai,...Aaron D. Ames|[2509.19545](http://arxiv.org/abs/2509.19545)|null|
|**2025-09-25**|**Residual Off-Policy RL for Finetuning Behavior Cloning Policies**|Lars Ankile,...Anusha Nagabandi|[2509.19301](http://arxiv.org/abs/2509.19301)|**[link](https://residual-offpolicy-rl.github.io)**|
|**2025-09-27**|**HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos**|Haoyang Weng,...Guanya Shi|[2509.16757](http://arxiv.org/abs/2509.16757)|null|
|**2025-09-20**|**KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control**|Jinrui Han,...Chenjia Bai|[2509.16638](http://arxiv.org/abs/2509.16638)|null|
|**2025-09-19**|**A Framework for Optimal Ankle Design of Humanoid Robots**|Guglielmo Cervettini,...Daniele Pucci|[2509.16469](http://arxiv.org/abs/2509.16469)|null|
|**2025-09-19**|**A Matter of Height: The Impact of a Robotic Object on Human Compliance**|Michael Faber,...Hadas Erel|[2509.16032](http://arxiv.org/abs/2509.16032)|null|
|**2025-09-18**|**Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning**|Xingyu Chen,...Haodong Zhang|[2509.15443](http://arxiv.org/abs/2509.15443)|null|
|**2025-09-18**|**CAD-Driven Co-Design for Flight-Ready Jet-Powered Humanoids**|Punith Reddy Vanteddu,...Daniele Pucci|[2509.14935](http://arxiv.org/abs/2509.14935)|null|
|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Cong Tai,...Tao Shen|[2509.14687](http://arxiv.org/abs/2509.14687)|null|
|**2025-09-23**|**Cybersecurity AI: Humanoid Robots as Attack Vectors**|Víctor Mayoral-Vilches,...Kevin Finisterre|[2509.14139](http://arxiv.org/abs/2509.14139)|null|
|**2025-09-17**|**The Cybersecurity of a Humanoid Robot**|Víctor Mayoral-Vilches,...Víctor Mayoral-Vilches|[2509.14096](http://arxiv.org/abs/2509.14096)|null|
|**2025-09-17**|**Behavior Foundation Model for Humanoid Robots**|Weishuai Zeng,...Jiangmiao Pang|[2509.13780](http://arxiv.org/abs/2509.13780)|null|
|**2025-09-17**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Xiaolin Zhou,...Zhizhong Su|[2509.13733](http://arxiv.org/abs/2509.13733)|null|
|**2025-09-16**|**Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning**|Chunxin Zheng,...Jun Ma|[2509.13534](http://arxiv.org/abs/2509.13534)|null|

<p align=right>(<a href=#updated-on-20251008>back to top</a>)</p>

## 3DGS/NeRF

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-10-04**|**Optimized Minimal 4D Gaussian Splatting**|Minseo Lee,...Eunbyung Park|[2510.03857](http://arxiv.org/abs/2510.03857)|null|
|**2025-10-03**|**SketchPlan: Diffusion Based Drone Planning From Human Sketches**|Sixten Norelius,...Mac Schwager|[2510.03545](http://arxiv.org/abs/2510.03545)|**[link](https://github.com/sixnor/SketchPlan)**|
|**2025-09-30**|**Universal Beta Splatting**|Rong Liu,...Ziyan Wu|[2510.03312](http://arxiv.org/abs/2510.03312)|null|
|**2025-10-03**|**Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields**|Zhiting Mei,...Anirudha Majumdar|[2510.03104](http://arxiv.org/abs/2510.03104)|null|
|**2025-10-03**|**GS-Share: Enabling High-fidelity Map Sharing with Incremental Gaussian Splatting**|Xinran Zhang,...Yanyong Zhang|[2510.02884](http://arxiv.org/abs/2510.02884)|null|
|**2025-10-03**|**From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting**|Jianing Chen,...Yucheng Zhang|[2510.02732](http://arxiv.org/abs/2510.02732)|null|
|**2025-10-03**|**FSFSplatter: Build Surface and Novel Views with Sparse-Views within 3min**|Yibin Zhao,...Jianjun Yi|[2510.02691](http://arxiv.org/abs/2510.02691)|null|
|**2025-10-02**|**SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting**|Sung-Yeon Park,...Ziran Wang|[2510.02469](http://arxiv.org/abs/2510.02469)|null|
|**2025-10-02**|**StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions**|Bo-Hsu Ke,...Wei-Chen Chiu|[2510.02314](http://arxiv.org/abs/2510.02314)|**[link](https://hentci.github.io/stealthattack/)**|
|**2025-10-02**|**Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0**|Yan Miao,...Sayan Mitra|[2510.02248](http://arxiv.org/abs/2510.02248)|null|
|**2025-10-02**|**Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects**|Georgios Kouros,...Tinne Tuytelaars|[2510.02069](http://arxiv.org/abs/2510.02069)|null|
|**2025-10-02**|**GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing**|Mengtian Li,...Chaofeng Chen|[2510.02034](http://arxiv.org/abs/2510.02034)|**[link](https://baiyunshu.github.io/GAUSSIANMORPHING.github.io/)**|
|**2025-10-02**|**4DGS-Craft: Consistent and Interactive 4D Gaussian Splatting Editing**|Lei Liu,...Dong Xu|[2510.01991](http://arxiv.org/abs/2510.01991)|null|
|**2025-10-02**|**ROI-GS: Interest-based Local Quality 3D Gaussian Splatting**|Quoc-Anh Bui,...Simone Gasparini|[2510.01978](http://arxiv.org/abs/2510.01978)|null|
|**2025-10-02**|**GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics**|Diram Tabaa,...Gianni Di Caro|[2510.01848](http://arxiv.org/abs/2510.01848)|null|
|**2025-10-02**|**LOBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for Large-Scale Scene Reconstruction**|Sheng-Hsiang Hung,...Hung-Kuo Chu|[2510.01767](http://arxiv.org/abs/2510.01767)|null|
|**2025-10-02**|**MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics**|Changmin Lee,...Tae-Kyun Kim|[2510.01619](http://arxiv.org/abs/2510.01619)|null|
|**2025-10-01**|**Instant4D: 4D Gaussian Splatting in Minutes**|Zhanpeng Luo,...Li Lu|[2510.01119](http://arxiv.org/abs/2510.01119)|null|
|**2025-09-30**|**HART: Human Aligned Reconstruction Transformer**|Xiyi Chen,...Ming Lin|[2509.26621](http://arxiv.org/abs/2509.26621)|**[link](https://xiyichen.github.io/hart)**|
|**2025-09-30**|**Stylos: Multi-View 3D Stylization with Single-Forward Gaussian Splatting**|Hanzhou Liu,...Peng Jiang|[2509.26455](http://arxiv.org/abs/2509.26455)|null|
|**2025-09-30**|**GaussEdit: Adaptive 3D Scene Editing with Text and Image Prompts**|Zhenyu Shu,...Ligang Liu|[2509.26055](http://arxiv.org/abs/2509.26055)|null|
|**2025-09-30**|**PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion**|Zhiwei Zhang,...Lizhuang Ma|[2509.26008](http://arxiv.org/abs/2509.26008)|null|
|**2025-09-30**|**LLM-Powered Code Analysis and Optimization for Gaussian Splatting Kernels**|Yi Hu,...Huiyang Zhou|[2509.25626](http://arxiv.org/abs/2509.25626)|null|
|**2025-09-29**|**GaussianLens: Localized High-Resolution Reconstruction via On-Demand Gaussian Densification**|Yijia Weng,...Leonidas J. Guibas|[2509.25603](http://arxiv.org/abs/2509.25603)|null|
|**2025-09-29**|**Triangle Splatting+: Differentiable Rendering with Opaque Triangles**|Jan Held,...Andrea Tagliasacchi|[2509.25122](http://arxiv.org/abs/2509.25122)|null|
|**2025-10-02**|**GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction**|Huaizhi Qu,...Tianlong Chen|[2509.25075](http://arxiv.org/abs/2509.25075)|null|
|**2025-09-29**|**LVT: Large-Scale Scene Reconstruction via Local View Transformers**|Tooba Imtiaz,...John Flynn|[2509.25001](http://arxiv.org/abs/2509.25001)|**[link](https://toobaimt.github.io/lvt/)**|
|**2025-09-29**|**DWGS: Enhancing Sparse-View Gaussian Splatting with Hybrid-Loss Depth Estimation and Bidirectional Warping**|Yu Ma,...Yue Cheng|[2509.24893](http://arxiv.org/abs/2509.24893)|null|
|**2025-09-29**|**ExGS: Extreme 3D Gaussian Compression with Diffusion Priors**|Jiaqi Chen,...Xiao Sun|[2509.24758](http://arxiv.org/abs/2509.24758)|null|
|**2025-10-01**|**Proxy-GS: Efficient 3D Gaussian Splatting via Proxy Mesh**|Yuanyuan Gao,...Xiao Sun|[2509.24421](http://arxiv.org/abs/2509.24421)|null|
|**2025-09-29**|**OMeGa: Joint Optimization of Explicit Meshes and Gaussian Splats for Robust Scene-Level Surface Reconstruction**|Yuhang Cao,...Danya Yao|[2509.24308](http://arxiv.org/abs/2509.24308)|null|
|**2025-09-28**|**CrashSplat: 2D to 3D Vehicle Damage Segmentation in Gaussian Splatting**|Dragoş-Andrei Chileban,...Cosmin Cernǎzanu-Glǎvan|[2509.23947](http://arxiv.org/abs/2509.23947)|null|
|**2025-09-28**|**From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations**|Javed Ahmad,...Yonas Teodros Tefera|[2509.23555](http://arxiv.org/abs/2509.23555)|null|
|**2025-09-27**|**Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual Videos**|Junyi Wu,...Yan Yan|[2509.23492](http://arxiv.org/abs/2509.23492)|**[link](https://github.com/adreamwu/OriGS}{OriGS})**|
|**2025-09-27**|**OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting**|Atakan Topaloglu,...Federico Tombari|[2509.23258](http://arxiv.org/abs/2509.23258)|null|
|**2025-09-26**|**Learning Unified Representation of 3D Gaussian Splatting**|Yuelin Xin,...Xinke Li|[2509.22917](http://arxiv.org/abs/2509.22917)|null|
|**2025-09-26**|**Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting**|Yasmine Omri,...Thierry Tambe|[2509.22615](http://arxiv.org/abs/2509.22615)|null|
|**2025-09-26**|**GS-2M: Gaussian Splatting for Joint Mesh Reconstruction and Material Decomposition**|Dinh Minh Nguyen,...Thomas Lindemeier|[2509.22276](http://arxiv.org/abs/2509.22276)|null|
|**2025-09-26**|**Polysemous Language Gaussian Splatting via Matching-based Mask Lifting**|Jiayu Ding,...Ge Li|[2509.22225](http://arxiv.org/abs/2509.22225)|null|
|**2025-09-26**|**Large Material Gaussian Model for Relightable 3D Generation**|Jingrui Ye,...Qingmin Liao|[2509.22112](http://arxiv.org/abs/2509.22112)|null|
|**2025-09-26**|**Drag4D: Align Your Motion with Text-Driven 3D Scene Generation**|Minjun Kang,...Kuk-Jin Yoon|[2509.21888](http://arxiv.org/abs/2509.21888)|null|
|**2025-09-30**|**Dynamic Novel View Synthesis in High Dynamic Range**|Kaixuan Zhang,...Xiatian Zhu|[2509.21853](http://arxiv.org/abs/2509.21853)|null|
|**2025-09-25**|**PowerGS: Display-Rendering Power Co-Optimization for Neural Rendering in Power-Constrained XR Systems**|Weikai Lin,...Yuhao Zhu|[2509.21702](http://arxiv.org/abs/2509.21702)|null|
|**2025-09-25**|**Gaussian splatting holography**|Shuhe Zhang,...Liangcai Cao|[2509.20774](http://arxiv.org/abs/2509.20774)|null|
|**2025-09-23**|**SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing**|Yiyu Li,...Rynson W. H. Lau|[2509.20400](http://arxiv.org/abs/2509.20400)|null|
|**2025-09-24**|**4D Driving Scene Generation With Stereo Forcing**|Hao Lu,...Yingcong Chen|[2509.20251](http://arxiv.org/abs/2509.20251)|null|
|**2025-09-24**|**GS-RoadPatching: Inpainting Gaussians via 3D Searching and Placing for Driving Scenes**|Guo Chen,...Sheng Yang|[2509.19937](http://arxiv.org/abs/2509.19937)|null|
|**2025-09-24**|**Aerial-Ground Image Feature Matching via 3D Gaussian Splatting-based Intermediate View Rendering**|Jiangxue Yu,...Qingquan Li|[2509.19898](http://arxiv.org/abs/2509.19898)|null|
|**2025-09-24**|**BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting**|Yixun Zhang,...Jianqin Yin|[2509.19793](http://arxiv.org/abs/2509.19793)|null|
|**2025-09-24**|**PolGS: Polarimetric Gaussian Splatting for Fast Reflective Surface Reconstruction**|Yufei Han,...Zhanyu Ma|[2509.19726](http://arxiv.org/abs/2509.19726)|null|
|**2025-09-23**|**VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction**|Weijie Wang,...Bohan Zhuang|[2509.19297](http://arxiv.org/abs/2509.19297)|**[link](https://lhmd.top/volsplat)**|
|**2025-09-23**|**Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation**|Sherwin Bahmani,...Xuanchi Ren|[2509.19296](http://arxiv.org/abs/2509.19296)|**[link](https://research.nvidia.com/labs/toronto-ai/lyra/)**|
|**2025-09-23**|**WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction**|Hung Nguyen,...Truong Nguyen|[2509.19073](http://arxiv.org/abs/2509.19073)|null|
|**2025-09-23**|**Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting**|Zijing Guo,...Lin Wang|[2509.18956](http://arxiv.org/abs/2509.18956)|null|
|**2025-09-23**|**DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring**|Pengteng Li,...Hui Xiong|[2509.18898](http://arxiv.org/abs/2509.18898)|null|
|**2025-09-23**|**FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation**|Zhaorui Wang,...Renjing Xu|[2509.18759](http://arxiv.org/abs/2509.18759)|null|
|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Maximilian Adang,...Mac Schwager|[2509.18610](http://arxiv.org/abs/2509.18610)|null|
|**2025-09-23**|**Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction**|Xiaoting Yin,...Kaiwei Wang|[2509.18566](http://arxiv.org/abs/2509.18566)|null|
|**2025-09-23**|**BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting for Deformable Intraoperative Surgical Navigation**|Maximilian Fehrentz,...Nassir Navab|[2509.18501](http://arxiv.org/abs/2509.18501)|null|
|**2025-09-23**|**Differentiable Light Transport with Gaussian Surfels via Adapted Radiosity for Efficient Relighting and Geometry Reconstruction**|Kaiwen Jiang,...Ravi Ramamoorthi|[2509.18497](http://arxiv.org/abs/2509.18497)|null|
|**2025-09-22**|**GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction**|Jiahe Li,...Lin Gu|[2509.18090](http://arxiv.org/abs/2509.18090)|**[link](https://fictionarry.github.io/GeoSVR-project/)**|
|**2025-09-22**|**GaussianPSL: A novel framework based on Gaussian Splatting for exploring the Pareto frontier in multi-criteria optimization**|Phuong Mai Dinh,...Van-Nam Huynh|[2509.17889](http://arxiv.org/abs/2509.17889)|null|
|**2025-09-22**|**ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos**|Shi Chen,...Martin R. Oswald|[2509.17864](http://arxiv.org/abs/2509.17864)|null|

<p align=right>(<a href=#updated-on-20251008>back to top</a>)</p>

