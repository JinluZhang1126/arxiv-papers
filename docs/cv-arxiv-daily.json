{"Interaction": {"2509.18937": "|**2025-09-23**|**Lang2Morph: Language-Driven Morphological Design of Robotic Hands**|Yanyuan Qiao,...Josie Hughes|[2509.18937](http://arxiv.org/abs/2509.18937)|null|\n", "2509.18571": "|**2025-09-23**|**Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought**|Yuhan Wang,...Weichao Wu|[2509.18571](http://arxiv.org/abs/2509.18571)|null|\n", "2509.17888": "|**2025-09-22**|**Trainee Action Recognition through Interaction Analysis in CCATT Mixed-Reality Training**|Divya Mereddy,...Benjamin Goldberg|[2509.17888](http://arxiv.org/abs/2509.17888)|null|\n", "2509.16557": "|**2025-09-20**|**Person Identification from Egocentric Human-Object Interactions using 3D Hand Pose**|Muhammad Hamza,...Muhammad Tahir Akram|[2509.16557](http://arxiv.org/abs/2509.16557)|null|\n", "2509.16398": "|**2025-09-19**|**Dynamic Objects Relocalization in Changing Environments with Flow Matching**|Francesco Argenziano,...Liam Paull|[2509.16398](http://arxiv.org/abs/2509.16398)|null|\n", "2509.12784": "|**2025-10-03**|**Contextualized Representation Learning for Effective Human-Object Interaction Detection**|Zhehao Li,...Jiafei Wu|[2509.12784](http://arxiv.org/abs/2509.12784)|null|\n", "2509.12554": "|**2025-09-16**|**Explicit Multimodal Graph Modeling for Human-Object Interaction Detection**|Wenxuan Ji,...Xiao-Yu zhang|[2509.12554](http://arxiv.org/abs/2509.12554)|null|\n", "2509.12250": "|**2025-09-12**|**OnlineHOI: Towards Online Human-Object Interaction Generation and Perception**|Yihong Ji,...Fei Yu|[2509.12250](http://arxiv.org/abs/2509.12250)|null|\n", "2509.09555": "|**2025-09-11**|**InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation**|Sirui Xu,...Liang-Yan Gui|[2509.09555](http://arxiv.org/abs/2509.09555)|null|\n", "2509.09067": "|**2025-09-18**|**Improvement of Human-Object Interaction Action Recognition Using Scene Information and Multi-Task Learning Approach**|Hesham M. Shehata,...Mohammad Abdolrahmani|[2509.09067](http://arxiv.org/abs/2509.09067)|null|\n", "2509.07920": "|**2025-09-09**|**ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion**|Ao Li,...Yansong Tang|[2509.07920](http://arxiv.org/abs/2509.07920)|null|\n", "2509.01232": "|**2025-09-01**|**FantasyHSI: Video-Generation-Centric 4D Human Synthesis In Any Scene through A Graph-based Multi-Agent Framework**|Lingzhou Mu,...Kai Zhang|[2509.01232](http://arxiv.org/abs/2509.01232)|**[link](https://fantasy-amap.github.io/fantasy-hsi/)**|\n", "2509.00767": "|**2025-08-31**|**InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos**|Yangsong Zhang,...Ivan Laptev|[2509.00767](http://arxiv.org/abs/2509.00767)|**[link](https://mael-zys.github.io/InterPose/)**|\n", "2509.00760": "|**2025-08-31**|**No More Sibling Rivalry: Debiasing Human-Object Interaction Detection**|Bin Yang,...Sibei Yang|[2509.00760](http://arxiv.org/abs/2509.00760)|null|\n", "2508.21556": "|**2025-08-29**|**ECHO: Ego-Centric modeling of Human-Object interactions**|Ilya A. Petrov,...Gerard Pons-Moll|[2508.21556](http://arxiv.org/abs/2508.21556)|null|\n", "2508.19852": "|**2025-08-28**|**Ego-centric Predictive Model Conditioned on Hand Trajectories**|Binjie Zhang,...Mike Zheng Shou|[2508.19852](http://arxiv.org/abs/2508.19852)|null|\n", "2508.19575": "|**2025-08-28**|**Interact-Custom: Customized Human Object Interaction Image Generation**|Zhu Xu,...Yang Liu|[2508.19575](http://arxiv.org/abs/2508.19575)|null|\n", "2508.18896": "|**2025-08-26**|**DQEN: Dual Query Enhancement Network for DETR-based HOI Detection**|Zhehao Li,...Jiafei Wu|[2508.18896](http://arxiv.org/abs/2508.18896)|null|\n", "2508.18753": "|**2025-09-29**|**Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods**|Qinqian Lei,...Robby T. Tan|[2508.18753](http://arxiv.org/abs/2508.18753)|null|\n", "2508.18691": "|**2025-08-26**|**Deep Sensorimotor Control by Imitating Predictive Models of Human Motion**|Himanshu Gaurav Singh,...Antonio Loquercio|[2508.18691](http://arxiv.org/abs/2508.18691)|**[link](https://hgaurav2k.github.io/trackr/)**|\n", "2509.23612": "|**2025-09-30**|**InteractMove: Text-Controlled Human-Object Interaction Generation in 3D Scenes with Movable Objects**|Xinhao Cai,...Yang Liu|[2509.23612](http://arxiv.org/abs/2509.23612)|null|\n", "2509.26621": "|**2025-09-30**|**HART: Human Aligned Reconstruction Transformer**|Xiyi Chen,...Ming Lin|[2509.26621](http://arxiv.org/abs/2509.26621)|**[link](https://xiyichen.github.io/hart)**|\n", "2509.26004": "|**2025-09-30**|**Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations**|Nicola Messina,...Antonino Furnari|[2509.26004](http://arxiv.org/abs/2509.26004)|null|\n", "2510.02155": "|**2025-10-02**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Shu Zou,...Jing Zhang|[2510.02155](http://arxiv.org/abs/2510.02155)|null|\n", "2510.03135": "|**2025-10-03**|**Mask2IV: Interaction-Centric Video Generation via Mask Trajectories**|Gen Li,...Laura Sevilla-Lara|[2510.03135](http://arxiv.org/abs/2510.03135)|**[link](https://reagan1311.github.io/mask2iv)**|\n", "2510.05609": "|**2025-10-07**|**HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection**|Junwen Chen,...Keiji Yanai|[2510.05609](http://arxiv.org/abs/2510.05609)|null|\n", "2510.07828": "|**2025-10-11**|**MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions**|Kaen Kogashi,...Meng-Yu Jennifer Kuo|[2510.07828](http://arxiv.org/abs/2510.07828)|null|\n", "2510.11649": "|**2025-10-13**|**PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from a Single Image**|Pradyumna Yalandur Muralidhar,...Gerard Pons-Moll|[2510.11649](http://arxiv.org/abs/2510.11649)|**[link](https://yuxuan-xue.com/physic)**|\n", "2510.16272": "|**2025-10-17**|**Proactive Scene Decomposition and Reconstruction**|Baicheng Li,...Hongbin Zha|[2510.16272](http://arxiv.org/abs/2510.16272)|null|\n", "2510.18357": "|**2025-10-21**|**Learning Human-Object Interaction as Groups**|Jiajun Hong,...Wenguan Wang|[2510.18357](http://arxiv.org/abs/2510.18357)|null|\n", "2510.23203": "|**2025-10-27**|**DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification**|Lukas Bierling,...Angelo Broere|[2510.23203](http://arxiv.org/abs/2510.23203)|null|\n", "2510.22199": "|**2025-10-25**|**MOGRAS: Human Motion with Grasping in 3D Scenes**|Kunal Bhosikar,...Charu Sharma|[2510.22199](http://arxiv.org/abs/2510.22199)|null|\n", "2510.21769": "|**2025-10-17**|**H2OFlow: Grounding Human-Object Affordances with 3D Generative Models and Dense Diffused Flows**|Harry Zhang,...Luca Carlone|[2510.21769](http://arxiv.org/abs/2510.21769)|null|\n", "2510.25268": "|**2025-10-29**|**SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation**|Wang zhi,...Dan Guo|[2510.25268](http://arxiv.org/abs/2510.25268)|null|\n", "2510.25094": "|**2025-10-29**|**Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection**|Chanhyeong Yang,...Hyunwoo J. Kim|[2510.25094](http://arxiv.org/abs/2510.25094)|null|\n", "2510.27020": "|**2025-10-30**|**Incremental Human-Object Interaction Detection with Invariant Relation Representation Learning**|Yana Wei,...Xuming He|[2510.27020](http://arxiv.org/abs/2510.27020)|null|\n", "2309.07918": "|**2024-11-06**|**Unified Human-Scene Interaction via Prompted Chain-of-Contacts**|Zeqi Xiao,...Jiangmiao Pang|[2309.07918](http://arxiv.org/abs/2309.07918)|**[link](https://xizaoqu.github.io/unihsi/)**|\n", "2503.12763": "|**2025-04-09**|**A Survey on Human Interaction Motion Generation**|Kewei Sui,...Chuan Guo|[2503.12763](http://arxiv.org/abs/2503.12763)|**[link](https://github.com/soraproducer/Awesome-Human-Interaction-Motion-Generation)**|\n", "2103.01555": "|**2021-03-11**|**Careful with That! Observation of Human Movements to Estimate Objects Properties**|Linda Lastrico,...Francesco Rea|[2103.01555](http://arxiv.org/abs/2103.01555)|null|\n", "2205.02830": "|**2024-03-19**|**Interaction Replica: Tracking Human-Object Interaction and Scene Changes From Human Motion**|Vladimir Guzov,...Gerard Pons-Moll|[2205.02830](http://arxiv.org/abs/2205.02830)|null|\n", "2103.08214": "|**2021-03-26**|**Detecting Human-Object Interaction via Fabricated Compositional Learning**|Zhi Hou,...Dacheng Tao|[2103.08214](http://arxiv.org/abs/2103.08214)|null|\n", "1605.08464": "|**2016-05-30**|**Low-Cost Scene Modeling using a Density Function Improves Segmentation Performance**|Vivek Sharma,...Luc Van Gool|[1605.08464](http://arxiv.org/abs/1605.08464)|null|\n", "2506.19639": "|**2025-06-25**|**HOIverse: A Synthetic Scene Graph Dataset With Human Object Interactions**|Mrunmai Vivek Phatak,...Rainer Lienhart|[2506.19639](http://arxiv.org/abs/2506.19639)|null|\n", "2506.01579": "|**2025-06-03**|**HOSIG: Full-Body Human-Object-Scene Interaction Generation with Hierarchical Scene Perception**|Wei Yao,...Jinhui Tang|[2506.01579](http://arxiv.org/abs/2506.01579)|null|\n", "2207.12824": "|**2022-07-27**|**Compositional Human-Scene Interaction Synthesis with Semantic Control**|Kaifeng Zhao,...Siyu Tang|[2207.12824](http://arxiv.org/abs/2207.12824)|**[link](https://zkf1997.github.io/COINS/index.html)**|\n", "2108.08584": "|**2021-08-20**|**Exploiting Scene Graphs for Human-Object Interaction Detection**|Tao He,...Yuan-Fang Li|[2108.08584](http://arxiv.org/abs/2108.08584)|null|\n", "2312.03913": "|**2024-07-16**|**Controllable Human-Object Interaction Synthesis**|Jiaman Li,...C. Karen Liu|[2312.03913](http://arxiv.org/abs/2312.03913)|**[link](https://lijiaman.github.io/projects/chois/)**|\n", "1909.01507": "|**2019-09-05**|**Holistic++ Scene Understanding: Single-view 3D Holistic Scene Parsing and Human Pose Estimation with Human-Object Interaction and Physical Commonsense**|Yixin Chen,...Song-Chun Zhu|[1909.01507](http://arxiv.org/abs/1909.01507)|null|\n", "2112.09448": "|**2021-12-20**|**Distillation of Human-Object Interaction Contexts for Action Recognition**|Muna Almushyti,...Frederick W. Li|[2112.09448](http://arxiv.org/abs/2112.09448)|null|\n", "2404.10685": "|**2024-04-17**|**Generating Human Interaction Motions in Scenes with Text Control**|Hongwei Yi,...Davis Rempe|[2404.10685](http://arxiv.org/abs/2404.10685)|**[link](https://research.nvidia.com/labs/toronto-ai/tesmo/)**|\n", "2108.08633": "|**2021-08-20**|**Spatio-Temporal Interaction Graph Parsing Networks for Human-Object Interaction Recognition**|Ning Wang,...Cong Hua|[2108.08633](http://arxiv.org/abs/2108.08633)|null|\n", "2105.03089": "|**2021-05-10**|**Human Object Interaction Detection using Two-Direction Spatial Enhancement and Exclusive Object Prior**|Lu Liu,...Robby T. Tan|[2105.03089](http://arxiv.org/abs/2105.03089)|null|\n", "2403.08629": "|**2024-05-27**|**Scaling Up Dynamic Human-Scene Interaction Modeling**|Nan Jiang,...Siyuan Huang|[2403.08629](http://arxiv.org/abs/2403.08629)|null|\n", "2511.10539": "|**2025-11-13**|**Dynamic Avatar-Scene Rendering from Human-centric Context**|Wenqing Wang,...Xiatian Zhu|[2511.10539](http://arxiv.org/abs/2511.10539)|null|\n", "2511.10492": "|**2025-11-16**|**Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding**|Yunkai Zhang,...Diji Yang|[2511.10492](http://arxiv.org/abs/2511.10492)|null|\n", "2511.10110": "|**2025-11-13**|**Learning a Thousand Tasks in a Day**|Kamil Dreczkowski,...Edward Johns|[2511.10110](http://arxiv.org/abs/2511.10110)|**[link](https://www.science.org/doi/10.1126/scirobotics.adv7594.)**|\n", "2511.10032": "|**2025-11-13**|**Moral Change or Noise? On Problems of Aligning AI With Temporally Unstable Human Feedback**|Vijay Keswani,...Walter Sinnott-Armstrong|[2511.10032](http://arxiv.org/abs/2511.10032)|null|\n", "2511.10017": "|**2025-11-13**|**AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models**|Xinyi Wang,...Na Zhao|[2511.10017](http://arxiv.org/abs/2511.10017)|null|\n", "2511.09827": "|**2025-11-13**|**AHA! Animating Human Avatars in Diverse Scenes with Gaussian Splatting**|Aymen Mir,...Bing Zhou|[2511.09827](http://arxiv.org/abs/2511.09827)|null|\n", "2511.09710": "|**2025-11-12**|**Echoing: Identity Failures when LLM Agents Talk to Each Other**|Sarath Shekkizhar,...Silvio Savarese|[2511.09710](http://arxiv.org/abs/2511.09710)|null|\n", "2511.09141": "|**2025-11-12**|**RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation**|Xuetao Li,...Miao Li|[2511.09141](http://arxiv.org/abs/2511.09141)|null|\n", "2511.09047": "|**2025-11-12**|**Preference is More Than Comparisons: Rethinking Dueling Bandits with Augmented Human Feedback**|Shengbo Wang,...Ke Li|[2511.09047](http://arxiv.org/abs/2511.09047)|null|\n", "2511.08897": "|**2025-11-12**|**Improving VisNet for Object Recognition**|Mehdi Fatan Serj,...Xavier Otazu|[2511.08897](http://arxiv.org/abs/2511.08897)|null|\n", "2511.08763": "|**2025-11-11**|**Modeling multi-agent motion dynamics in immersive rooms**|Mincong,...Stefan T. Radev|[2511.08763](http://arxiv.org/abs/2511.08763)|null|\n", "2511.08294": "|**2025-11-11**|**SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering**|Laura Bragagnolo,...Stefano Ghidoni|[2511.08294](http://arxiv.org/abs/2511.08294)|null|\n", "2511.07732": "|**2025-11-11**|**ViPRA: Video Prediction for Robot Actions**|Sandeep Routray,...Deepak Pathak|[2511.07732](http://arxiv.org/abs/2511.07732)|**[link](https://vipra-project.github.io)**|\n", "2511.07619": "|**2025-11-10**|**CAVER: Curious Audiovisual Exploring Robot**|Luca Macesanu,...Roberto Mart\u00edn-Mart\u00edn|[2511.07619](http://arxiv.org/abs/2511.07619)|null|\n", "2511.08640": "|**2025-11-10**|**Predict and Resist: Long-Term Accident Anticipation under Sensor Noise**|Xingcheng Liu,...Zhenning Li|[2511.08640](http://arxiv.org/abs/2511.08640)|null|\n", "2511.05889": "|**2025-11-08**|**From Words to Safety: Language-Conditioned Safety Filtering for Robot Navigation**|Zeyuan Feng,...Somil Bansal|[2511.05889](http://arxiv.org/abs/2511.05889)|null|\n", "2511.05855": "|**2025-11-08**|**Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills**|Jiayu Zhou,...Renjing Xu|[2511.05855](http://arxiv.org/abs/2511.05855)|null|\n", "2511.05681": "|**2025-11-07**|**Culture in Action: Evaluating Text-to-Image Models through Social Activities**|Sina Malakouti,...Adriana Kovashka|[2511.05681](http://arxiv.org/abs/2511.05681)|null|\n", "2511.05622": "|**2025-11-06**|**Grounding Foundational Vision Models with 3D Human Poses for Robust Action Recognition**|Nicholas Babey,...Kevin Zhu|[2511.05622](http://arxiv.org/abs/2511.05622)|**[link](https://github.com/nbabey20/groundactrec)**|\n", "2511.04679": "|**2025-11-06**|**GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction**|Qingzhou Lu,...C. Karen Liu|[2511.04679](http://arxiv.org/abs/2511.04679)|**[link](https://gentle-humanoid.axell.top)**|\n", "2511.11456": "|**2025-11-14**|**SimTac: A Physics-Based Simulator for Vision-Based Tactile Sensing with Biomorphic Structures**|Xuyang Zhang,...Shan Luo|[2511.11456](http://arxiv.org/abs/2511.11456)|null|\n", "2511.10987": "|**2025-11-14**|**Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment**|Wenbin Bai,...Yi Sun|[2511.10987](http://arxiv.org/abs/2511.10987)|null|\n", "2511.10853": "|**2025-11-13**|**Advanced Tool for Traffic Crash Analysis: An AI-Driven Multi-Agent Approach to Pre-Crash Reconstruction**|Gerui Xu,...Shan Bao|[2511.10853](http://arxiv.org/abs/2511.10853)|null|\n", "2511.13524": "|**2025-11-17**|**FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI**|Yuhang Peng,...Jiangtao Gong|[2511.13524](http://arxiv.org/abs/2511.13524)|null|\n", "2511.13327": "|**2025-11-17**|**ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning**|Juntao Jian,...Ruizhen Hu|[2511.13327](http://arxiv.org/abs/2511.13327)|null|\n", "2511.13315": "|**2025-11-17**|**Computer Vision based group activity detection and action spotting**|Narthana Sivalingam,...H. M. V. R. Herath|[2511.13315](http://arxiv.org/abs/2511.13315)|null|\n", "2511.13069": "|**2025-11-17**|**Towards Requirements Engineering for GenAI-Enabled Software: Bridging Responsibility Gaps through Human Oversight Requirements**|Zhenyu Mao,...Jialong Li|[2511.13069](http://arxiv.org/abs/2511.13069)|null|\n", "2511.13032": "|**2025-11-17**|**Uni-Inter: Unifying 3D Human Motion Synthesis Across Diverse Interaction Contexts**|Sheng Liu,...Xuelong Li|[2511.13032](http://arxiv.org/abs/2511.13032)|null|\n", "2511.12878": "|**2025-11-18**|**Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views**|Junyi Ma,...Hesheng Wang|[2511.12878](http://arxiv.org/abs/2511.12878)|null|\n", "2511.12030": "|**2025-11-15**|**VPHO: Joint Visual-Physical Cue Learning and Aggregation for Hand-Object Pose Estimation**|Jun Zhou,...Li Cheng|[2511.12030](http://arxiv.org/abs/2511.12030)|null|\n", "2511.11775": "|**2025-11-14**|**Data-driven strategic sensor placement for detecting disinfection by-products in water distribution networks**|Aristotelis Magklis,...Andreas Kamilaris|[2511.11775](http://arxiv.org/abs/2511.11775)|null|\n", "2511.14396": "|**2025-11-18**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Xiuxiu Qi,...Hongpeng Wang|[2511.14396](http://arxiv.org/abs/2511.14396)|**[link](https://qhemu.github.io/CCoL/)**|\n", "2511.14262": "|**2025-11-18**|**Object-Centric World Models for Causality-Aware Reinforcement Learning**|Yosuke Nishimoto,...Takashi Matsubara|[2511.14262](http://arxiv.org/abs/2511.14262)|null|\n", "2511.13863": "|**2025-11-19**|**Segmenting Collision Sound Sources in Egocentric Videos**|Kranti Kumar Parida,...Dima Damen|[2511.13863](http://arxiv.org/abs/2511.13863)|**[link](https://krantiparida.github.io/projects/cs3.html)**|\n", "2511.15046": "|**2025-11-19**|**UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space**|Panqi Yang,...Yongqiang Ma|[2511.15046](http://arxiv.org/abs/2511.15046)|null|\n", "2511.14972": "|**2025-11-18**|**Harmful Traits of AI Companions**|W. Bradley Knox,...Samuel Baker|[2511.14972](http://arxiv.org/abs/2511.14972)|null|\n", "2511.14964": "|**2025-11-18**|**How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus Legal Identity**|Heather J. Alexander,...Fr\u00e9d\u00e9ric Pinard|[2511.14964](http://arxiv.org/abs/2511.14964)|null|\n", "2511.15948": "|**2025-11-20**|**Click2Graph: Interactive Panoptic Video Scene Graphs from a Single Click**|Raphael Ruschel,...B. S. Manjunath|[2511.15948](http://arxiv.org/abs/2511.15948)|null|\n", "2511.17335": "|**2025-11-21**|**Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM**|Chiori Hori,...Jonathan Le Roux|[2511.17335](http://arxiv.org/abs/2511.17335)|null|\n", "2511.17045": "|**2025-11-27**|**RacketVision: A Multiple Racket Sports Benchmark for Unified Ball and Racket Analysis**|Linfeng Dong,...Xiao Sun|[2511.17045](http://arxiv.org/abs/2511.17045)|null|\n", "2511.16951": "|**2025-11-21**|**FingerCap: Fine-grained Finger-level Hand Motion Captioning**|Xin Shen,...Xin Yu|[2511.16951](http://arxiv.org/abs/2511.16951)|null|\n", "2511.16857": "|**2025-11-20**|**BOP-ASK: Object-Interaction Reasoning for Vision-Language Models**|Vineet Bhat,...Jonathan Tremblay|[2511.16857](http://arxiv.org/abs/2511.16857)|null|\n", "2511.16712": "|**2025-11-20**|**PairHuman: A High-Fidelity Photographic Dataset for Customized Dual-Person Generation**|Ting Pan,...Yu Liu|[2511.16712](http://arxiv.org/abs/2511.16712)|null|\n", "2511.21398": "|**2025-11-26**|**Prune4Web: DOM Tree Pruning Programming for Web Agent**|Jiayuan Zhang,...Jing Zhang|[2511.21398](http://arxiv.org/abs/2511.21398)|null|\n", "2511.21191": "|**2025-11-26**|**Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding**|Yutao Tang,...Mei Chen|[2511.21191](http://arxiv.org/abs/2511.21191)|null|\n", "2511.20937": "|**2025-11-26**|**ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction**|Qineng Wang,...Manling Li|[2511.20937](http://arxiv.org/abs/2511.20937)|null|\n", "2511.20809": "|**2025-11-25**|**Layer-Aware Video Composition via Split-then-Merge**|Ozgur Kara,...Du Tran|[2511.20809](http://arxiv.org/abs/2511.20809)|**[link](https://split-then-merge.github.io)**|\n", "2511.20525": "|**2025-11-25**|**Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos**|Yayuan Li,...Jason J. Corso|[2511.20525](http://arxiv.org/abs/2511.20525)|null|\n", "2511.20446": "|**2025-11-25**|**Learning to Generate Human-Human-Object Interactions from Textual Descriptions**|Jeonghyeon Na,...Hanbyul Joo|[2511.20446](http://arxiv.org/abs/2511.20446)|**[link](https://tlb-miss.github.io/hhoi/)**|\n", "2511.20431": "|**2025-11-26**|**BRIC: Bridging Kinematic Plans and Physical Control at Test Time**|Dohun Lim,...Sungchan Kim|[2511.20431](http://arxiv.org/abs/2511.20431)|null|\n", "2511.20351": "|**2025-11-26**|**Thinking in 360\u00b0: Humanoid Visual Search in the Wild**|Heyang Yu,...Yiming Li|[2511.20351](http://arxiv.org/abs/2511.20351)|**[link](https://humanoid-vstar.github.io/)**|\n", "2511.20299": "|**2025-11-25**|**How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks**|R\u00f3is\u00edn Keenan,...Joost C. Dessing|[2511.20299](http://arxiv.org/abs/2511.20299)|null|\n", "2511.20201": "|**2025-11-25**|**GHR-VQA: Graph-guided Hierarchical Relational Reasoning for Video Question Answering**|Dionysia Danai Brilli,...Petros Maragos|[2511.20201](http://arxiv.org/abs/2511.20201)|null|\n", "2511.20162": "|**2025-11-25**|**While recognizing actions, LMMs struggle to detect core interaction events**|Daniel Harari,...Muhammad Haris Khan|[2511.20162](http://arxiv.org/abs/2511.20162)|null|\n", "2511.19396": "|**2025-11-24**|**Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments**|Jorge Ortigoso-Narro,...Maximo Cobos|[2511.19396](http://arxiv.org/abs/2511.19396)|null|\n", "2511.19543": "|**2025-11-24**|**A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers**|Omar Faris,...Fulvio Forni|[2511.19543](http://arxiv.org/abs/2511.19543)|null|\n", "2511.18811": "|**2025-11-24**|**Mitigating Long-Tail Bias in HOI Detection via Adaptive Diversity Cache**|Yuqiu Jiang,...Zhe Sun|[2511.18811](http://arxiv.org/abs/2511.18811)|null|\n", "2511.18718": "|**2025-11-24**|**AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation**|Omar Garib,...Dimitri N. Mavris|[2511.18718](http://arxiv.org/abs/2511.18718)|null|\n", "2511.18598": "|**2025-11-23**|**Assessing Gaze and Pointing: Human Cue Interpretation by Indian Free-Ranging Dogs in a Food Retrieval Task**|Srijaya Nandi,...Anindita Bhadra|[2511.18598](http://arxiv.org/abs/2511.18598)|null|\n", "2511.18470": "|**2025-11-23**|**Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span**|Heeseung Yun,...Gunhee Kim|[2511.18470](http://arxiv.org/abs/2511.18470)|null|\n", "2511.18286": "|**2025-11-23**|**RoadSceneVQA: Benchmarking Visual Question Answering in Roadside Perception Systems for Intelligent Transportation System**|Runwei Guan,...Yutao Yue|[2511.18286](http://arxiv.org/abs/2511.18286)|null|\n", "2511.17986": "|**2025-11-22**|**Plan-X: Instruct Video Generation via Semantic Planning**|Lun Huang,...Guillermo Sapiro|[2511.17986](http://arxiv.org/abs/2511.17986)|**[link](https://byteaigc.github.io/Plan-X)**|\n", "2511.17926": "|**2025-11-22**|**Three-Class Emotion Classification for Audiovisual Scenes Based on Ensemble Learning Scheme**|Xiangrui Xiong,...Ning Wu|[2511.17926](http://arxiv.org/abs/2511.17926)|null|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Yuhong Zhang,...Haoqian Wang|[2512.02729](http://arxiv.org/abs/2512.02729)|null|\n", "2512.02549": "|**2025-12-02**|**Robotic capabilities framework: A boundary object and intermediate-level knowledge artifact for co-designing robotic processes**|Alessandro Ianniello,...David Abbink|[2512.02549](http://arxiv.org/abs/2512.02549)|null|\n", "2512.02009": "|**2025-12-01**|**AirSim360: A Panoramic Simulation Platform within Drone View**|Xian Ge,...Lu Qi|[2512.02009](http://arxiv.org/abs/2512.02009)|**[link](https://insta360-research-team.github.io/AirSim360-website/)**|\n", "2512.01061": "|**2025-11-30**|**Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer**|Haoru Xue,...Yuke Zhu|[2512.01061](http://arxiv.org/abs/2512.01061)|**[link](https://doorman-humanoid.github.io/)**|\n", "2512.01052": "|**2025-11-30**|**Autonomous Grasping On Quadruped Robot With Task Level Interaction**|Muhtadin,...Chastine Fatichah|[2512.01052](http://arxiv.org/abs/2512.01052)|null|\n", "2512.00960": "|**2025-12-06**|**Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction**|Boran Wen,...Yong-Lu Li|[2512.00960](http://arxiv.org/abs/2512.00960)|null|\n", "2512.00885": "|**2025-11-30**|**HanDyVQA: A Video QA Benchmark for Fine-Grained Hand-Object Interaction Dynamics**|Masatoshi Tateno,...Takuma Yagi|[2512.00885](http://arxiv.org/abs/2512.00885)|**[link](https://masatate.github.io/HanDyVQA-project-page/)**|\n", "2512.00663": "|**2025-11-29**|**Graphing the Truth: Structured Visualizations for Automated Hallucination Detection in LLMs**|Tanmay Agrawal,...Tanmay Agrawal|[2512.00663](http://arxiv.org/abs/2512.00663)|null|\n", "2512.00547": "|**2025-11-29**|**Asset-Driven Sematic Reconstruction of Dynamic Scene with Multi-Human-Object Interactions**|Sandika Biswas,...Hamid Rezatofighi|[2512.00547](http://arxiv.org/abs/2512.00547)|null|\n", "2512.00470": "|**2025-12-02**|**LAP: Fast LAtent Diffusion Planner with Fine-Grained Feature Distillation for Autonomous Driving**|Jinhao Zhang,...Jie Mei|[2512.00470](http://arxiv.org/abs/2512.00470)|null|\n", "2512.00413": "|**2025-11-29**|**SplatFont3D: Structure-Aware Text-to-3D Artistic Font Generation with Part-Level Style Control**|Ji Gan,...Xinbo Gao|[2512.00413](http://arxiv.org/abs/2512.00413)|null|\n", "2512.00403": "|**2025-11-29**|**SelfAI: Building a Self-Training AI System with LLM Agents**|Xiao Wu,...Yutong Xie|[2512.00403](http://arxiv.org/abs/2512.00403)|null|\n", "2512.00294": "|**2025-11-29**|**Words into World: A Task-Adaptive Agent for Language-Guided Spatial Retrieval in AR**|Lixing Guo,...Tobias H\u00f6llerer|[2512.00294](http://arxiv.org/abs/2512.00294)|null|\n", "2511.23304": "|**2025-11-28**|**Multi-Modal Scene Graph with Kolmogorov-Arnold Experts for Audio-Visual Question Answering**|Zijian Fu,...Huadong Ma|[2511.23304](http://arxiv.org/abs/2511.23304)|null|\n", "2511.23300": "|**2025-11-28**|**SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot**|Yara Mahmoud,...Dzmitry Tsetserukou|[2511.23300](http://arxiv.org/abs/2511.23300)|null|\n", "2511.22815": "|**2025-11-28**|**Captain Safari: A World Engine**|Yu-Cheng Chou,...Junfei Xiao|[2511.22815](http://arxiv.org/abs/2511.22815)|null|\n", "2511.22025": "|**2025-11-27**|**Layover or Direct Flight: Rethinking Audio-Guided Image Segmentation**|Joel Alberto Santos,...Radu Timofte|[2511.22025](http://arxiv.org/abs/2511.22025)|null|\n", "2511.21909": "|**2025-11-26**|**A Customer Journey in the Land of Oz: Leveraging the Wizard of Oz Technique to Model Emotions in Customer Service Interactions**|Sofie Labat,...V\u00e9ronique Hoste|[2511.21909](http://arxiv.org/abs/2511.21909)|null|\n", "2512.04884": "|**2025-12-04**|**Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation**|Tim Engelbracht,...Zuria Bauer|[2512.04884](http://arxiv.org/abs/2512.04884)|null|\n", "2512.04686": "|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Yipu Wang,...Xiaolong Zheng|[2512.04686](http://arxiv.org/abs/2512.04686)|null|\n", "2512.04597": "|**2025-12-04**|**When Robots Should Say \"I Don't Know\": Benchmarking Abstention in Embodied Question Answering**|Tao Wu,...Jianfei Yang|[2512.04597](http://arxiv.org/abs/2512.04597)|null|\n", "2512.04451": "|**2025-12-04**|**StreamEQA: Towards Streaming Video Understanding for Embodied Scenarios**|Yifei Wang,...Xiaoling Wang|[2512.04451](http://arxiv.org/abs/2512.04451)|null|\n", "2512.04302": "|**2025-12-03**|**Towards better dense rewards in Reinforcement Learning Applications**|Shuyuan Zhang,...Shuyuan Zhang|[2512.04302](http://arxiv.org/abs/2512.04302)|null|\n", "2512.03828": "|**2025-12-03**|**IM HERE: Interaction Model for Human Effort Based Robot Engagement**|Dominykas Strazdas,...Ayoub Al-Hamadi|[2512.03828](http://arxiv.org/abs/2512.03828)|null|\n", "2512.03790": "|**2025-12-03**|**ExOAR: Expert-Guided Object and Activity Recognition from Textual Data**|Iris Beerepoot,...Xixi Lu|[2512.03790](http://arxiv.org/abs/2512.03790)|null|\n", "2512.03687": "|**2025-12-03**|**Active Visual Perception: Opportunities and Challenges**|Yian Li,...Xiaowei Dai|[2512.03687](http://arxiv.org/abs/2512.03687)|null|\n", "2512.03666": "|**2025-12-03**|**ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos**|Qi'ao Xu,...Liang He|[2512.03666](http://arxiv.org/abs/2512.03666)|null|\n", "2512.09646": "|**2025-12-10**|**VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification**|Wanyue Zhang,...Christian Theobalt|[2512.09646](http://arxiv.org/abs/2512.09646)|null|\n", "2512.09406": "|**2025-12-10**|**H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos**|Hai Ci,...Mike Zheng Shou|[2512.09406](http://arxiv.org/abs/2512.09406)|null|\n", "2512.08500": "|**2025-12-09**|**Learning to Control Physically-simulated 3D Characters via Generating and Mimicking 2D Motions**|Jianan Li,...Tien-Tsin Wong|[2512.08500](http://arxiv.org/abs/2512.08500)|null|\n", "2512.14095": "|**2025-12-16**|**AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation**|Sisi Dai,...Kai Xu|[2512.14095](http://arxiv.org/abs/2512.14095)|null|\n", "2512.12664": "|**2025-12-14**|**InteracTalker: Prompt-Based Human-Object Interaction with Co-Speech Gesture Generation**|Sreehari Rajan,...Charu Sharma|[2512.12664](http://arxiv.org/abs/2512.12664)|null|\n", "2512.11988": "|**2025-12-12**|**CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction**|Xianghui Xie,...Stan Birchfield|[2512.11988](http://arxiv.org/abs/2512.11988)|**[link](https://nvlabs.github.io/CARI4D/)**|\n"}, "World Model": {"2509.21027": "|**2025-09-25**|**KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models**|Sibo Li,...Yong Li|[2509.21027](http://arxiv.org/abs/2509.21027)|null|\n", "2509.20998": "|**2025-09-25**|**CORE: Full-Path Evaluation of LLM Agents Beyond Final State**|Panagiotis Michelakis,...Dimitrios Stamoulis|[2509.20998](http://arxiv.org/abs/2509.20998)|null|\n", "2509.20623": "|**2025-09-24**|**Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation**|Satyajeet Das,...Gaurav S. Sukhatme|[2509.20623](http://arxiv.org/abs/2509.20623)|null|\n", "2509.20021": "|**2025-09-24**|**Embodied AI: From LLMs to World Models**|Tongtong Feng,...Wenwu Zhu|[2509.20021](http://arxiv.org/abs/2509.20021)|null|\n", "2509.19555": "|**2025-09-23**|**AnySafe: Adapting Latent Safety Filters at Runtime via Safety Constraint Parameterization in the Latent Space**|Sankalp Agrawal,...Andrea Bajcsy|[2509.19555](http://arxiv.org/abs/2509.19555)|null|\n", "2509.19538": "|**2025-09-23**|**DAWM: Diffusion Action World Models for Offline Reinforcement Learning via Action-Inferred Transitions**|Zongyue Li,...Matthias Schubert|[2509.19538](http://arxiv.org/abs/2509.19538)|null|\n", "2509.19080": "|**2025-09-23**|**World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation**|Zhennan Jiang,...Dongbin Zhao|[2509.19080](http://arxiv.org/abs/2509.19080)|null|\n", "2509.19041": "|**2025-09-23**|**Position: Human-Robot Interaction in Embodied Intelligence Demands a Shift From Static Privacy Controls to Dynamic Learning**|Shuning Zhang,...Hewu Li|[2509.19041](http://arxiv.org/abs/2509.19041)|null|\n", "2509.18428": "|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Bahey Tharwat,...Ian Reid|[2509.18428](http://arxiv.org/abs/2509.18428)|null|\n", "2509.17808": "|**2025-09-27**|**Remote Sensing-Oriented World Model**|Yuxi Lu,...Bin Liang|[2509.17808](http://arxiv.org/abs/2509.17808)|null|\n", "2509.17393": "|**2025-09-23**|**Program Synthesis via Test-Time Transduction**|Kang-il Lee,...Kyomin Jung|[2509.17393](http://arxiv.org/abs/2509.17393)|null|\n", "2509.16338": "|**2025-09-19**|**Polarized Signatures of Variable Worlds: Modeling Heterogeneous Habitable Earth- and Early Mars-like (Exo)planets**|Kenneth E. Goodis Gordon,...Eric T. Wolf|[2509.16338](http://arxiv.org/abs/2509.16338)|null|\n", "2509.15915": "|**2025-09-22**|**Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds**|Remo Sasso,...Paulo Rauber|[2509.15915](http://arxiv.org/abs/2509.15915)|null|\n", "2509.15536": "|**2025-09-19**|**SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models**|Sen Wang,...Hua Gang|[2509.15536](http://arxiv.org/abs/2509.15536)|null|\n", "2509.15479": "|**2025-09-18**|**OpenViGA: Video Generation for Automotive Driving Scenes by Streamlining and Fine-Tuning Open Source Models with Public Data**|Bj\u00f6rn M\u00f6ller,...Tim Fingscheidt|[2509.15479](http://arxiv.org/abs/2509.15479)|null|\n", "2509.14758": "|**2025-09-18**|**Designing Latent Safety Filters using Pre-Trained Vision Models**|Ihab Tabbara,...Hussein Sibai|[2509.14758](http://arxiv.org/abs/2509.14758)|null|\n", "2509.13903": "|**2025-09-17**|**PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models**|Artem Lykov,...Dzmitry Tsetserukou|[2509.13903](http://arxiv.org/abs/2509.13903)|null|\n", "2509.13389": "|**2025-09-25**|**From Next Token Prediction to (STRIPS) World Models -- Preliminary Results**|Carlos N\u00fa\u00f1ez-Molina,...Hector Geffner|[2509.13389](http://arxiv.org/abs/2509.13389)|null|\n", "2509.13095": "|**2025-09-26**|**Empowering Multi-Robot Cooperation via Sequential World Models**|Zijie Zhao,...Dongbin Zhao|[2509.13095](http://arxiv.org/abs/2509.13095)|null|\n", "2509.13384": "|**2025-09-16**|**A tree-based Polynomial Chaos expansion for surrogate modeling and sensitivity analysis of complex numerical models**|Faten Ben Said,...Fabrice Zaoui|[2509.13384](http://arxiv.org/abs/2509.13384)|null|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo,...Ziwei Wang|[2509.22643](http://arxiv.org/abs/2509.22643)|null|\n", "2509.22642": "|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Xiaowei Chi,...Jian Tang|[2509.22642](http://arxiv.org/abs/2509.22642)|null|\n", "2509.22353": "|**2025-09-26**|**Context and Diversity Matter: The Emergence of In-Context Learning in World Models**|Fan Wang,...Yu Kang|[2509.22353](http://arxiv.org/abs/2509.22353)|null|\n", "2509.21797": "|**2025-09-30**|**MoWM: Mixture-of-World-Models for Embodied Planning via Latent-to-Pixel Feature Modulation**|Yu Shang,...Yong Li|[2509.21797](http://arxiv.org/abs/2509.21797)|null|\n", "2509.21790": "|**2025-09-26**|**LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE**|Yu Shang,...Yong Li|[2509.21790](http://arxiv.org/abs/2509.21790)|null|\n", "2509.21657": "|**2025-09-25**|**FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction**|Yixiang Dai,...Yonggang Qi|[2509.21657](http://arxiv.org/abs/2509.21657)|null|\n", "2509.21592": "|**2025-09-25**|**What Happens Next? Anticipating Future Motion by Generating Point Trajectories**|Gabrijel Boduljak,...Andrea Vedaldi|[2509.21592](http://arxiv.org/abs/2509.21592)|null|\n", "2509.21574": "|**2025-09-25**|**X-Streamer: Unified Human World Modeling with Audiovisual Interaction**|You Xie,...Linjie Luo|[2509.21574](http://arxiv.org/abs/2509.21574)|**[link](https://byteaigc.github.io/X-Streamer)**|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24804": "|**2025-09-29**|**DyMoDreamer: World Modeling with Dynamic Modulation**|Boxuan Zhang,...Gang Wang|[2509.24804](http://arxiv.org/abs/2509.24804)|null|\n", "2509.24591": "|**2025-09-29**|**PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control**|Haozhuo Zhang,...Wei Pan|[2509.24591](http://arxiv.org/abs/2509.24591)|null|\n", "2509.24559": "|**2025-09-29**|**Emergent World Representations in OpenVLA**|Marco Molinari,...Omar G. Younis|[2509.24559](http://arxiv.org/abs/2509.24559)|null|\n", "2509.24527": "|**2025-09-29**|**Training Agents Inside of Scalable World Models**|Danijar Hafner,...Timothy Lillicrap|[2509.24527](http://arxiv.org/abs/2509.24527)|**[link](https://danijar.com/dreamer4/)**|\n", "2509.24313": "|**2025-09-29**|**Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning**|Korbinian Moller,...Johannes Betz|[2509.24313](http://arxiv.org/abs/2509.24313)|null|\n", "2509.24241": "|**2025-09-29**|**FreeAction: Training-Free Techniques for Enhanced Fidelity of Trajectory-to-Video Generation**|Seungwook Kim,...Minsu Cho|[2509.24241](http://arxiv.org/abs/2509.24241)|null|\n", "2509.24116": "|**2025-09-30**|**Dual-Scale World Models for LLM Agents Towards Hard-Exploration Problems**|Minsoo Kim,...Seung-won Hwang|[2509.24116](http://arxiv.org/abs/2509.24116)|null|\n", "2509.23979": "|**2025-09-28**|**ByteSized32Refactored: Towards an Extensible Interactive Text Games Corpus for LLM World Modeling and Evaluation**|Haonan Wang,...Ziang Xiao|[2509.23979](http://arxiv.org/abs/2509.23979)|null|\n", "2509.23958": "|**2025-09-28**|**Reinforcement Learning with Inverse Rewards for World Model Post-training**|Yang Ye,...Jiang Bian|[2509.23958](http://arxiv.org/abs/2509.23958)|null|\n", "2509.23488": "|**2025-10-01**|**Mapping Overlaps in Benchmarks through Perplexity in the Wild**|Siyang Wu,...James A. Evans|[2509.23488](http://arxiv.org/abs/2509.23488)|null|\n", "2509.23008": "|**2025-09-27**|**ARSS: Taming Decoder-only Autoregressive Visual Generation for View Synthesis From Single View**|Wenbin Teng,...Yajie Zhao|[2509.23008](http://arxiv.org/abs/2509.23008)|null|\n", "2509.22814": "|**2025-09-26**|**Model Context Protocol for Vision Systems: Audit, Security, and Protocol Extensions**|Aditi Tiwari,...Darshan Prasad|[2509.22814](http://arxiv.org/abs/2509.22814)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.26339": "|**2025-09-30**|**Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models**|Eric R. Damm,...Thomas M. Howard|[2509.26339](http://arxiv.org/abs/2509.26339)|null|\n", "2509.26255": "|**2025-10-01**|**ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning**|Yichao Liang,...Kevin Ellis|[2509.26255](http://arxiv.org/abs/2509.26255)|null|\n", "2509.25518": "|**2025-10-02**|**World Model for AI Autonomous Navigation in Mechanical Thrombectomy**|Harry Robertshaw,...Thomas C Booth|[2509.25518](http://arxiv.org/abs/2509.25518)|null|\n", "2509.25373": "|**2025-09-29**|**From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models**|Chenyue Zhou,...Yike Guo|[2509.25373](http://arxiv.org/abs/2509.25373)|null|\n", "2509.25161": "|**2025-09-29**|**Rolling Forcing: Autoregressive Long Video Diffusion in Real Time**|Kunhao Liu,...Shijian Lu|[2509.25161](http://arxiv.org/abs/2509.25161)|**[link](https://kunhao-liu.github.io/Rolling_Forcing_Webpage/)**|\n", "2509.25282": "|**2025-09-29**|**Toward Causal-Visual Programming: Enhancing Agentic Reasoning in Low-Code Environments**|Jiexi Xu,...Su Liu|[2509.25282](http://arxiv.org/abs/2509.25282)|null|\n", "2510.02287": "|**2025-10-02**|**MultiModal Action Conditioned Video Generation**|Yichen Li,...Antonio Torralba|[2510.02287](http://arxiv.org/abs/2510.02287)|null|\n", "2510.02110": "|**2025-10-02**|**SoundReactor: Frame-level Online Video-to-Audio Generation**|Koichi Saito,...Yuki Mitsufuji|[2510.02110](http://arxiv.org/abs/2510.02110)|null|\n", "2510.01641": "|**2025-10-02**|**FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion Deblurring**|Xiaoyang Liu,...Yulun Zhang|[2510.01641](http://arxiv.org/abs/2510.01641)|null|\n", "2510.01183": "|**2025-10-01**|**EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory**|Jiahao Wang,...Jieneng Chen|[2510.01183](http://arxiv.org/abs/2510.01183)|**[link](https://github.com/JiahaoPlus/EvoWorld)**|\n", "2510.01179": "|**2025-10-01**|**TOUCAN: Synthesizing 1.5M Tool-Agentic Data from Real-World MCP Environments**|Zhangchen Xu,...Rameswar Panda|[2510.01179](http://arxiv.org/abs/2510.01179)|null|\n", "2510.00855": "|**2025-10-01**|**Can World Models Benefit VLMs for World Dynamics?**|Kevin Zhang,...Shanghang Zhang|[2510.00855](http://arxiv.org/abs/2510.00855)|**[link](https://dyva-worldlm.github.io)**|\n", "2510.00739": "|**2025-10-01**|**TD-JEPA: Latent-predictive Representations for Zero-Shot Reinforcement Learning**|Marco Bagatella,...Andrea Tirinzoni|[2510.00739](http://arxiv.org/abs/2510.00739)|null|\n", "2510.00406": "|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Hengtao Li,...Weihua Su|[2510.00406](http://arxiv.org/abs/2510.00406)|null|\n", "2510.00129": "|**2025-09-30**|**BigBang-Proton Technical Report: Next-Word-Prediction is Scientific Multitask Learner**|Hengkui Wu,...Weipeng Xu|[2510.00129](http://arxiv.org/abs/2510.00129)|null|\n", "2510.03198": "|**2025-10-03**|**Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft**|Junchao Huang,...Li Jiang|[2510.03198](http://arxiv.org/abs/2510.03198)|null|\n", "2510.02538": "|**2025-10-02**|**A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models**|Yilin Wang,...Hao Su|[2510.02538](http://arxiv.org/abs/2510.02538)|null|\n", "2510.02387": "|**2025-09-30**|**CWM: An Open-Weights LLM for Research on Code Generation with World Models**|FAIR CodeGen team,...Gabriel Synnaeve|[2510.02387](http://arxiv.org/abs/2510.02387)|null|\n", "2510.05057": "|**2025-10-06**|**StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation**|Mingyu Liu,...Chunhua Shen|[2510.05057](http://arxiv.org/abs/2510.05057)|null|\n", "2510.04978": "|**2025-10-06**|**Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI**|Kun Xiang,...Xiaodan Liang|[2510.04978](http://arxiv.org/abs/2510.04978)|null|\n", "2510.04542": "|**2025-10-06**|**Code World Models for General Game Playing**|Wolfgang Lehrach,...Kevin P. Murphy|[2510.04542](http://arxiv.org/abs/2510.04542)|null|\n", "2510.04391": "|**2025-10-05**|**Internal World Models as Imagination Networks in Cognitive Agents**|Saurabh Ranjan,...Brian Odegaard|[2510.04391](http://arxiv.org/abs/2510.04391)|null|\n", "2510.04390": "|**2025-10-05**|**MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D World Simulator**|Xuehai He,...Xin Eric Wang|[2510.04390](http://arxiv.org/abs/2510.04390)|null|\n", "2510.04374": "|**2025-10-05**|**GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks**|Tejal Patwardhan,...Jerry Tworek|[2510.04374](http://arxiv.org/abs/2510.04374)|null|\n", "2510.04020": "|**2025-10-09**|**Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models**|Hao Wu,...Xiaomeng Huang|[2510.04020](http://arxiv.org/abs/2510.04020)|null|\n", "2510.03727": "|**2025-10-04**|**Bridging the Gap Between Multimodal Foundation Models and World Models**|Xuehai He,...Xuehai He|[2510.03727](http://arxiv.org/abs/2510.03727)|null|\n", "2510.03420": "|**2025-10-03**|**A Generalized Second-Order Positivity-Preserving Numerical Method for Non-Autonomous Dynamical Systems with Applications**|Manh Tuan Hoang,...Matthias Ehrhardt|[2510.03420](http://arxiv.org/abs/2510.03420)|null|\n", "2510.06209": "|**2025-10-07**|**Drive&Gen: Co-Evaluating End-to-End Driving and Video Generation Models**|Jiahao Wang,...Chiyu Max Jiang|[2510.06209](http://arxiv.org/abs/2510.06209)|null|\n", "2510.05865": "|**2025-10-07**|**The Safety Challenge of World Models for Embodied AI Agents: A Review**|Lorenzo Baraldi,...Lorenzo Baraldi|[2510.05865](http://arxiv.org/abs/2510.05865)|null|\n", "2510.07313": "|**2025-10-08**|**WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation**|Zezhong Qian,...Shanghang Zhang|[2510.07313](http://arxiv.org/abs/2510.07313)|null|\n", "2510.07092": "|**2025-10-09**|**Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report**|Riccardo Mereu,...Paul Chang|[2510.07092](http://arxiv.org/abs/2510.07092)|null|\n", "2510.06492": "|**2025-10-07**|**What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?**|Matthew Kim,...Andrea Bajcsy|[2510.06492](http://arxiv.org/abs/2510.06492)|null|\n", "2510.06448": "|**2025-10-07**|**How NOT to benchmark your SITE metric: Beyond Static Leaderboards and Towards Realistic Evaluation**|Prabhant Singh,...Joaquin Vanschoren|[2510.06448](http://arxiv.org/abs/2510.06448)|null|\n", "2510.08558": "|**2025-10-13**|**Agent Learning via Early Experience**|Kai Zhang,...Yifan Wu|[2510.08558](http://arxiv.org/abs/2510.08558)|null|\n", "2510.08553": "|**2025-10-09**|**Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation**|Yunzhe Xu,...Zhe Liu|[2510.08553](http://arxiv.org/abs/2510.08553)|null|\n", "2510.08398": "|**2025-10-09**|**VideoVerse: How Far is Your T2V Generator from a World Model?**|Zeqing Wang,...Lei Zhang|[2510.08398](http://arxiv.org/abs/2510.08398)|null|\n", "2510.07974": "|**2025-10-11**|**Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning**|Jialu Du,...Weiming Lu|[2510.07974](http://arxiv.org/abs/2510.07974)|null|\n", "2510.07944": "|**2025-10-16**|**CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving**|Tianrui Zhang,...Zehuan Wu|[2510.07944](http://arxiv.org/abs/2510.07944)|null|\n", "2510.07456": "|**2025-10-08**|**ExpertAgent: Enhancing Personalized Education through Dynamic Planning and Retrieval-Augmented Long-Chain Reasoning**|Binrong Zhu,...Nina Jiang|[2510.07456](http://arxiv.org/abs/2510.07456)|null|\n", "2510.07417": "|**2025-10-08**|**FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams**|Corban Rivera,...David Handelman|[2510.07417](http://arxiv.org/abs/2510.07417)|null|\n", "2510.09036": "|**2025-10-10**|**iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation**|Chuanrui Zhang,...Ziwei Wang|[2510.09036](http://arxiv.org/abs/2510.09036)|null|\n", "2510.08713": "|**2025-10-09**|**Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation**|Yifei Dong,...Alexander G Hauptmann|[2510.08713](http://arxiv.org/abs/2510.08713)|**[link](https://github.com/F1y1113/UniWM)**|\n", "2510.11682": "|**2025-10-13**|**Ego-Vision World Model for Humanoid Contact Planning**|Hang Liu,...Koushil Sreenath|[2510.11682](http://arxiv.org/abs/2510.11682)|null|\n", "2510.10960": "|**2025-10-13**|**Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving**|Dong Hu,...Chao Huang|[2510.10960](http://arxiv.org/abs/2510.10960)|null|\n", "2510.10670": "|**2025-10-12**|**AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D Scenes**|Yu Li,...Yujiu Yang|[2510.10670](http://arxiv.org/abs/2510.10670)|null|\n", "2510.10325": "|**2025-10-11**|**KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments**|Walid Abdela,...Walid Abdela|[2510.10325](http://arxiv.org/abs/2510.10325)|null|\n", "2510.10125": "|**2025-10-15**|**Ctrl-World: A Controllable Generative World Model for Robot Manipulation**|Yanjiang Guo,...Chelsea Finn|[2510.10125](http://arxiv.org/abs/2510.10125)|null|\n", "2510.12796": "|**2025-10-14**|**DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving**|Yingyan Li,...Zhaoxiang Zhang|[2510.12796](http://arxiv.org/abs/2510.12796)|null|\n", "2510.12560": "|**2025-10-14**|**CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving**|Xiaoji Zheng,...Jiangtao Gong|[2510.12560](http://arxiv.org/abs/2510.12560)|null|\n", "2510.12312": "|**2025-10-14**|**Deep SPI: Safe Policy Improvement via World Models**|Florent Delgrange,...Willem R\u00f6pke|[2510.12312](http://arxiv.org/abs/2510.12312)|null|\n", "2510.12088": "|**2025-10-14**|**One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration**|Zaid Khan,...Mohit Bansal|[2510.12088](http://arxiv.org/abs/2510.12088)|**[link](https://onelife-worldmodel.github.io/)**|\n", "2510.11892": "|**2025-10-13**|**R-WoM: Retrieval-augmented World Model For Computer-use Agents**|Kai Mei,...Jiarong Jiang|[2510.11892](http://arxiv.org/abs/2510.11892)|null|\n", "2510.13809": "|**2025-10-15**|**PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning**|Sihui Ji,...Hengshuang Zhao|[2510.13809](http://arxiv.org/abs/2510.13809)|**[link](https://sihuiji.github.io/PhysMaster-Page/)**|\n", "2510.13804": "|**2025-10-15**|**Generative Universal Verifier as Multimodal Meta-Reasoner**|Xinchen Zhang,...Yujiu Yang|[2510.13804](http://arxiv.org/abs/2510.13804)|null|\n", "2510.13247": "|**2025-10-15**|**Agency cannot be a purely quantum phenomenon**|Emily C. Adlam,...Mordecai Waegell|[2510.13247](http://arxiv.org/abs/2510.13247)|null|\n", "2510.14977": "|**2025-10-16**|**Terra: Explorable Native 3D World Model with Point Latents**|Yuanhui Huang,...Jiwen Lu|[2510.14977](http://arxiv.org/abs/2510.14977)|**[link](https://huang-yh.github.io/terra/)**|\n", "2510.14783": "|**2025-10-16**|**SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning**|Aderik Verraest,...Christophe De Wagter|[2510.14783](http://arxiv.org/abs/2510.14783)|null|\n", "2510.15422": "|**2025-10-17**|**Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction**|Lin Wang,...Lin Wang|[2510.15422](http://arxiv.org/abs/2510.15422)|null|\n", "2510.15144": "|**2025-10-16**|**HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks**|Chance Jiajie Li,...Kent Larson|[2510.15144](http://arxiv.org/abs/2510.15144)|null|\n", "2510.15047": "|**2025-10-16**|**Internalizing World Models via Self-Play Finetuning for Agentic RL**|Shiqi Chen,...Manling Li|[2510.15047](http://arxiv.org/abs/2510.15047)|null|\n", "2510.15041": "|**2025-10-20**|**Generalized Dynamics Generation towards Scannable Physical World Model**|Yichen Li,...Antonio Torralba|[2510.15041](http://arxiv.org/abs/2510.15041)|null|\n", "2510.17731": "|**2025-10-20**|**Can Image-To-Video Models Simulate Pedestrian Dynamics?**|Aaron Appelle,...Jerome P. Lynch|[2510.17731](http://arxiv.org/abs/2510.17731)|**[link](https://physical-world-modeling.github.io/)**|\n", "2510.17482": "|**2025-10-22**|**SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries**|Chenxu Dang,...Yan Wang|[2510.17482](http://arxiv.org/abs/2510.17482)|null|\n", "2510.16907": "|**2025-10-19**|**VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents**|Kangrui Wang,...Manling Li|[2510.16907](http://arxiv.org/abs/2510.16907)|null|\n", "2510.16732": "|**2025-10-19**|**A Comprehensive Survey on World Models for Embodied AI**|Xinqing Li,...Yun Liu|[2510.16732](http://arxiv.org/abs/2510.16732)|**[link](https://github.com/Li-Zn-H/AwesomeWorldModels)**|\n", "2510.16729": "|**2025-10-19**|**Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models**|Jianbiao Mei,...Yong Liu|[2510.16729](http://arxiv.org/abs/2510.16729)|null|\n", "2510.16500": "|**2025-10-18**|**Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks**|Chen Min,...Yu Hu|[2510.16500](http://arxiv.org/abs/2510.16500)|null|\n", "2510.16240": "|**2025-10-17**|**Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning**|Lukas Zbinden,...Sean Huver|[2510.16240](http://arxiv.org/abs/2510.16240)|null|\n", "2510.16123": "|**2025-10-17**|**Zero-shot World Models via Search in Memory**|Federico Malato,...Ville Hautam\u00e4ki|[2510.16123](http://arxiv.org/abs/2510.16123)|null|\n", "2510.16039": "|**2025-10-16**|**Vector Quantization in the Brain: Grid-like Codes in World Models**|Xiangyuan Peng,...Si Wu|[2510.16039](http://arxiv.org/abs/2510.16039)|null|\n", "2510.18315": "|**2025-10-21**|**Higher Embedding Dimension Creates a Stronger World Model for a Simple Sorting Task**|Brady Bhalla,...Tony Yue YU|[2510.18315](http://arxiv.org/abs/2510.18315)|null|\n", "2510.18313": "|**2025-10-24**|**OmniNWM: Omniscient Driving Navigation World Models**|Bohan Li,...Xin Jin|[2510.18313](http://arxiv.org/abs/2510.18313)|**[link](https://arlo0o.github.io/OmniNWM/)**|\n", "2510.18135": "|**2025-10-20**|**World-in-World: World Models in a Closed-Loop World**|Jiahan Zhang,...Jieneng Chen|[2510.18135](http://arxiv.org/abs/2510.18135)|**[link](https://github.com/World-In-World/world-in-world)**|\n", "2510.19818": "|**2025-10-22**|**Semantic World Models**|Jacob Berg,...Abhishek Gupta|[2510.19818](http://arxiv.org/abs/2510.19818)|null|\n", "2510.19788": "|**2025-10-23**|**Benchmarking World-Model Learning**|Archana Warrier,...Zenna Tavares|[2510.19788](http://arxiv.org/abs/2510.19788)|null|\n", "2510.19654": "|**2025-10-22**|**From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction**|Zhida Zhao,...Huchuan Lu|[2510.19654](http://arxiv.org/abs/2510.19654)|null|\n", "2510.19430": "|**2025-10-22**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**|GigaBrain Team,...Zheng Zhu|[2510.19430](http://arxiv.org/abs/2510.19430)|**[link](https://gigabrain0.github.io/)**|\n", "2510.19364": "|**2025-10-22**|**ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling**|Golnaz Raja,...Reza Ghabcheloo|[2510.19364](http://arxiv.org/abs/2510.19364)|null|\n", "2510.19270": "|**2025-10-22**|**Social World Model-Augmented Mechanism Design Policy Learning**|Xiaoyuan Zhang,...Xue Feng|[2510.19270](http://arxiv.org/abs/2510.19270)|null|\n", "2510.19195": "|**2025-10-24**|**Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks**|Kai Zeng,...Wentao Zhang|[2510.19195](http://arxiv.org/abs/2510.19195)|null|\n", "2510.20668": "|**2025-10-23**|**From Masks to Worlds: A Hitchhiker's Guide to World Models**|Jinbin Bai,...Ming-Hsuan Yang|[2510.20668](http://arxiv.org/abs/2510.20668)|**[link](https://github.com/M-E-AGI-Lab/Awesome-World-Models)**|\n", "2510.21682": "|**2025-10-24**|**WorldGrow: Generating Infinite 3D World**|Sikuang Li,...Qi Tian|[2510.21682](http://arxiv.org/abs/2510.21682)|**[link](https://world-grow.github.io/)**|\n", "2510.21447": "|**2025-10-24**|**PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis**|Yu Yang,...Wangmeng Zuo|[2510.21447](http://arxiv.org/abs/2510.21447)|null|\n", "2510.21418": "|**2025-10-24**|**DreamerV3-XP: Optimizing exploration through uncertainty estimation**|Lukas Bierling,...Kiki Van Gerwen|[2510.21418](http://arxiv.org/abs/2510.21418)|null|\n", "2510.21232": "|**2025-10-24**|**How Hard is it to Confuse a World Model?**|Waris Radji,...Odalric-Ambrym Maillard|[2510.21232](http://arxiv.org/abs/2510.21232)|null|\n", "2510.21219": "|**2025-10-24**|**World Models Should Prioritize the Unification of Physical and Social Dynamics**|Xiaoyuan Zhang,...Yaodong Yang|[2510.21219](http://arxiv.org/abs/2510.21219)|null|\n", "2510.20884": "|**2025-10-23**|**ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning**|Pranamya Kulkarni,...Ali Tajer|[2510.20884](http://arxiv.org/abs/2510.20884)|null|\n", "2510.23509": "|**2025-10-27**|**Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model**|Weizheng Wang,...Byung-Cheol Min|[2510.23509](http://arxiv.org/abs/2510.23509)|null|\n", "2510.23258": "|**2025-10-27**|**Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation**|Riko Yokozawa,...Shingo Murata|[2510.23258](http://arxiv.org/abs/2510.23258)|null|\n", "2510.22732": "|**2025-10-26**|**ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation**|Jiali Cheng,...Hadi Amiri|[2510.22732](http://arxiv.org/abs/2510.22732)|null|\n", "2510.22304": "|**2025-10-28**|**ODesign: A World Model for Biomolecular Interaction Design**|Odin Zhang,...Shuangjia Zheng|[2510.22304](http://arxiv.org/abs/2510.22304)|null|\n", "2510.22200": "|**2025-10-28**|**LongCat-Video Technical Report**|Meituan LongCat Team,...Tong Zhang|[2510.22200](http://arxiv.org/abs/2510.22200)|null|\n", "2510.21867": "|**2025-10-23**|**Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs**|Haicheng Liao,...Zhenning Li|[2510.21867](http://arxiv.org/abs/2510.21867)|null|\n", "2510.21840": "|**2025-10-22**|**Improving the Physics of Video Generation with VJEPA-2 Reward Signal**|Jianhao Yuan,...Adriana Romero-Soriano|[2510.21840](http://arxiv.org/abs/2510.21840)|null|\n", "2510.24690": "|**2025-10-28**|**Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning**|Shengjie Liu,...Zhenyu Zhang|[2510.24690](http://arxiv.org/abs/2510.24690)|null|\n", "2510.24654": "|**2025-10-28**|**Evolving Diagnostic Agents in a Virtual Clinical Environment**|Pengcheng Qiu,...Weidi Xie|[2510.24654](http://arxiv.org/abs/2510.24654)|null|\n", "2510.24546": "|**2025-10-28**|**Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks**|Lingyi Wang,...Naren Ramakrishnan|[2510.24546](http://arxiv.org/abs/2510.24546)|null|\n", "2510.24459": "|**2025-10-28**|**Affordance Representation and Recognition for Autonomous Agents**|Habtom Kahsay Gidey,...Alois Knoll|[2510.24459](http://arxiv.org/abs/2510.24459)|null|\n", "2510.24030": "|**2025-10-28**|**Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts**|Ahmet Akkaya Melih,...Hanuman Bhatia|[2510.24030](http://arxiv.org/abs/2510.24030)|null|\n", "2510.25529": "|**2025-10-29**|**Off-policy Reinforcement Learning with Model-based Exploration Augmentation**|Likun Wang,...Shengbo Eben Li|[2510.25529](http://arxiv.org/abs/2510.25529)|null|\n", "2510.25129": "|**2025-10-29**|**AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit Structured Gaussians**|Xiyu Zhang,...Guofeng Zhang|[2510.25129](http://arxiv.org/abs/2510.25129)|**[link](https://zju3dv.github.io/AtlasGS/)**|\n", "2510.24785": "|**2025-10-27**|**Semantic Communications with World Models**|Peiwen Jiang,...Jun Zhang|[2510.24785](http://arxiv.org/abs/2510.24785)|null|\n", "2510.26796": "|**2025-10-30**|**SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting**|Dongyue Lu,...Ziwei Liu|[2510.26796](http://arxiv.org/abs/2510.26796)|**[link](https://see-4d.github.io/)**|\n", "2510.26782": "|**2025-10-30**|**Clone Deterministic 3D Worlds with Geometrically-Regularized World Models**|Zaishuo Xia,...Yubei Chen|[2510.26782](http://arxiv.org/abs/2510.26782)|null|\n", "2510.26654": "|**2025-10-30**|**Bridge and Bound: A Logic-Based Framework for Abstracting (Preliminary Report)**|Andrzej Szalas,...Andrzej Szalas|[2510.26654](http://arxiv.org/abs/2510.26654)|null|\n", "2510.26583": "|**2025-10-30**|**Emu3.5: Native Multimodal Models are World Learners**|Yufeng Cui,...Xinlong Wang|[2510.26583](http://arxiv.org/abs/2510.26583)|**[link](https://emu.world)**|\n", "2510.26433": "|**2025-10-30**|**Co-Evolving Latent Action World Models**|Yucen Wang,...Jiang Bian|[2510.26433](http://arxiv.org/abs/2510.26433)|null|\n", "2510.25927": "|**2025-10-29**|**Constraints on the resolution of spacetime singularities**|Arvin Shahbazi-Moghaddam,...Arvin Shahbazi-Moghaddam|[2510.25927](http://arxiv.org/abs/2510.25927)|null|\n", "2510.27607": "|**2025-11-04**|**Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model**|John Won,...Jinwoo Shin|[2510.27607](http://arxiv.org/abs/2510.27607)|null|\n", "2510.27002": "|**2025-10-30**|**Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase**|Mihir Mahajan,...Stefan Bauer|[2510.27002](http://arxiv.org/abs/2510.27002)|**[link](https://pdoom.org/jasmine.html)**|\n", "2511.02824": "|**2025-11-05**|**Kosmos: An AI Scientist for Autonomous Discovery**|Ludovico Mitchener,...Andrew D. White|[2511.02824](http://arxiv.org/abs/2511.02824)|null|\n", "2511.02748": "|**2025-11-04**|**Agentic World Modeling for 6G: Near-Real-Time Generative State-Space Reasoning**|Farhad Rezazadeh,...Lingjia Liu|[2511.02748](http://arxiv.org/abs/2511.02748)|null|\n", "2511.02347": "|**2025-11-04**|**LTD-Bench: Evaluating Large Language Models by Letting Them Draw**|Liuhao Lin,...Rongrong Ji|[2511.02347](http://arxiv.org/abs/2511.02347)|null|\n", "2511.02225": "|**2025-11-04**|**Learning Interactive World Model for Object-Centric Reinforcement Learning**|Fan Feng,...Sara Magliacane|[2511.02225](http://arxiv.org/abs/2511.02225)|null|\n", "2511.02091": "|**2025-11-03**|**Natural Building Blocks for Structured World Models: Theory, Evidence, and Scaling**|Lancelot Da Costa,...Bernhard Sch\u00f6lkopf|[2511.02091](http://arxiv.org/abs/2511.02091)|null|\n", "2511.01775": "|**2025-11-03**|**How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment**|Zhen Chen,...Jiebo Luo|[2511.01775](http://arxiv.org/abs/2511.01775)|null|\n", "2511.01310": "|**2025-11-03**|**From Pixels to Cooperation Multi Agent Reinforcement Learning based on Multimodal World Models**|Sureyya Akin,...Rahu Srivastava|[2511.01310](http://arxiv.org/abs/2511.01310)|null|\n", "2511.01177": "|**2025-11-03**|**Scaling Cross-Embodiment World Models for Dexterous Manipulation**|Zihao He,...Hao Su|[2511.01177](http://arxiv.org/abs/2511.01177)|null|\n", "2511.01093": "|**2025-11-02**|**Continual Learning, Not Training: Online Adaptation For Agents**|Aman Jaglan,...Jarrod Barnes|[2511.01093](http://arxiv.org/abs/2511.01093)|null|\n", "2511.00940": "|**2025-11-02**|**URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model**|Zhe Li,...Shanghang Zhang|[2511.00940](http://arxiv.org/abs/2511.00940)|null|\n", "2511.00549": "|**2025-11-01**|**Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations**|Qiang Li,...Lina Yu|[2511.00549](http://arxiv.org/abs/2511.00549)|null|\n", "2511.00423": "|**2025-11-01**|**Bootstrap Off-policy with World Model**|Guojian Zhan,...Shengbo Eben Li|[2511.00423](http://arxiv.org/abs/2511.00423)|null|\n", "2511.02097": "|**2025-10-31**|**A Step Toward World Models: A Survey on Robotic Manipulation**|Peng-Fei Zhang,...Heng Tao Shen|[2511.02097](http://arxiv.org/abs/2511.02097)|null|\n", "2511.03550": "|**2025-11-05**|**Indicating Robot Vision Capabilities with Augmented Reality**|Hong Wang,...Zhao Han|[2511.03550](http://arxiv.org/abs/2511.03550)|null|\n", "2511.03077": "|**2025-11-04**|**WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models**|R. Khorrambakht,...Ludovic Righetti|[2511.03077](http://arxiv.org/abs/2511.03077)|null|\n", "2511.04670": "|**2025-11-06**|**Cambrian-S: Towards Spatial Supersensing in Video**|Shusheng Yang,...Saining Xie|[2511.04670](http://arxiv.org/abs/2511.04670)|**[link](https://cambrian-mllm.github.io/)**|\n", "2511.04646": "|**2025-11-06**|**DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration**|Narjes Nourzad,...Carlee Joe-Wong|[2511.04646](http://arxiv.org/abs/2511.04646)|null|\n", "2511.04541": "|**2025-11-06**|**LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems**|Baptiste Bonin,...Audrey Durand|[2511.04541](http://arxiv.org/abs/2511.04541)|null|\n", "2511.03782": "|**2025-11-05**|**Expert Evaluation of LLM World Models: A High-$T_c$ Superconductivity Case Study**|Haoyu Guo,...Eun-Ah Kim|[2511.03782](http://arxiv.org/abs/2511.03782)|null|\n", "2511.05256": "|**2025-11-07**|**Entanglement, defects, and $T\\bar{T}$ on a black hole background**|Ankur Dey,...Ankur Dey|[2511.05256](http://arxiv.org/abs/2511.05256)|null|\n", "2511.04847": "|**2025-11-06**|**Grounded Test-Time Adaptation for LLM Agents**|Arthur Chen,...Caiming Xiong|[2511.04847](http://arxiv.org/abs/2511.04847)|null|\n", "2511.07416": "|**2025-11-10**|**Robot Learning from a Physical World Model**|Jiageng Mao,...Yue Wang|[2511.07416](http://arxiv.org/abs/2511.07416)|**[link](https://pointscoder.github.io/PhysWorld_Web/)**|\n", "2511.07403": "|**2025-11-10**|**SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards**|Hunar Batra,...Ronald Clark|[2511.07403](http://arxiv.org/abs/2511.07403)|null|\n", "2511.07399": "|**2025-11-10**|**StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video Generation**|Tianrui Feng,...Chenfeng Xu|[2511.07399](http://arxiv.org/abs/2511.07399)|**[link](http://streamdiffusionv2.github.io)**|\n", "2511.06946": "|**2025-11-10**|**Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning**|Daniel De Dios Allegue,...Frans A. Oliehoek|[2511.06946](http://arxiv.org/abs/2511.06946)|null|\n", "2511.06252": "|**2025-11-09**|**MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios**|Xuantang Xiong,...Bo Xu|[2511.06252](http://arxiv.org/abs/2511.06252)|null|\n", "2511.06136": "|**2025-11-08**|**When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks**|Stefano Ferraro,...Yutaka Matsuo|[2511.06136](http://arxiv.org/abs/2511.06136)|null|\n", "2511.05972": "|**2025-11-08**|**DWM-RO: Decentralized World Models with Reasoning Offloading for SWIPT-enabled Satellite-Terrestrial HetNets**|Guangyuan Liu,...Ping Zhang|[2511.05972](http://arxiv.org/abs/2511.05972)|null|\n", "2511.05963": "|**2025-11-08**|**Next-Latent Prediction Transformers Learn Compact World Models**|Jayden Teoh,...John Langford|[2511.05963](http://arxiv.org/abs/2511.05963)|null|\n", "2406.09455": "|**2024-06-17**|**Pandora: Towards General World Model with Natural Language Actions and Video States**|Jiannan Xiang,...Zhiting Hu|[2406.09455](http://arxiv.org/abs/2406.09455)|**[link](https://world-model.maitrix.org/)**|\n", "2405.03520": "|**2025-10-29**|**Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond**|Zheng Zhu,...Guan Huang|[2405.03520](http://arxiv.org/abs/2405.03520)|**[link](https://github.com/GigaAI-research/General-World-Models-Survey)**|\n", "2506.18701": "|**2025-06-24**|**Matrix-Game: Interactive World Foundation Model**|Yifan Zhang,...Yahui Zhou|[2506.18701](http://arxiv.org/abs/2506.18701)|null|\n", "2507.00917": "|**2025-09-04**|**A Survey: Learning Embodied Intelligence from Physical Simulators and World Models**|Xiaoxiao Long,...Qionghai Dai|[2507.00917](http://arxiv.org/abs/2507.00917)|**[link](https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey)**|\n", "2401.09985": "|**2024-01-19**|**WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens**|Xiaofeng Wang,...Jiwen Lu|[2401.09985](http://arxiv.org/abs/2401.09985)|**[link](https://world-dreamer.github.io/)**|\n", "2505.21996": "|**2025-10-31**|**Learning World Models for Interactive Video Generation**|Taiye Chen,...Chi Jin|[2505.21996](http://arxiv.org/abs/2505.21996)|**[link](https://sites.google.com/view/vrag)**|\n", "2402.06665": "|**2024-05-01**|**The Essential Role of Causality in Foundation World Models for Embodied AI**|Tarun Gupta,...Cheng Zhang|[2402.06665](http://arxiv.org/abs/2402.06665)|null|\n", "2508.13009": "|**2025-08-19**|**Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model**|Xianglong He,...Yahui Zhou|[2508.13009](http://arxiv.org/abs/2508.13009)|**[link](https://matrix-game-v2.github.io)**|\n", "2508.17600": "|**2025-09-18**|**GWM: Towards Scalable Gaussian World Models for Robotic Manipulation**|Guanxing Lu,...Siyuan Huang|[2508.17600](http://arxiv.org/abs/2508.17600)|**[link](https://gaussian-world-model.github.io/)**|\n", "2501.03575": "|**2025-07-11**|**Cosmos World Foundation Model Platform for Physical AI**|NVIDIA,...Artur Zolkowski|[2501.03575](http://arxiv.org/abs/2501.03575)|null|\n", "2509.04633": "|**2025-11-05**|**The Physical Basis of Prediction: World Model Formation in Neural Organoids via an LLM-Generated Curriculum**|Brennen Hill,...Brennen Hill|[2509.04633](http://arxiv.org/abs/2509.04633)|null|\n", "2411.17027": "|**2024-11-27**|**D$^2$-World: An Efficient World Model through Decoupled Dynamic Flow**|Haiming Zhang,...Bingbing Liu|[2411.17027](http://arxiv.org/abs/2411.17027)|null|\n", "2506.00613": "|**2025-10-01**|**WorldGym: World Model as An Environment for Policy Evaluation**|Julian Quevedo,...Sherry Yang|[2506.00613](http://arxiv.org/abs/2506.00613)|**[link](https://world-model-eval.github.io)**|\n", "2410.12822": "|**2024-11-26**|**AVID: Adapting Video Diffusion Models to World Models**|Marc Rigter,...Chao Ma|[2410.12822](http://arxiv.org/abs/2410.12822)|**[link](https://sites.google.com/view/avid-world-model-adapters/home)**|\n", "2503.04641": "|**2025-08-14**|**Simulating the Real World: A Unified Survey of Multimodal Generative Models**|Yuqi Hu,...Hui Xiong|[2503.04641](http://arxiv.org/abs/2503.04641)|**[link](https://github.com/ALEEEHU/World-Simulator)**|\n", "2410.10738": "|**2024-10-15**|**DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model**|Yuqi Wang,...Zhaoxiang Zhang|[2410.10738](http://arxiv.org/abs/2410.10738)|**[link](https://drivingdojo.github.io/)**|\n", "1604.00360": "|**2016-04-04**|**A General World Model with Poiesis: Poppers Three Worlds updated with Software**|Walter Hehl,...Walter Hehl|[1604.00360](http://arxiv.org/abs/1604.00360)|null|\n", "2511.08585": "|**2025-11-12**|**Simulating the Visual World with Artificial Intelligence: A Roadmap**|Jingtong Yue,...Ziwei Liu|[2511.08585](http://arxiv.org/abs/2511.08585)|**[link](https://world-model-roadmap.github.io/)**|\n", "2511.10627": "|**2025-11-13**|**Querying Labeled Time Series Data with Scenario Programs**|Edward Kim,...Sanjit A Seshia|[2511.10627](http://arxiv.org/abs/2511.10627)|null|\n", "2511.10615": "|**2025-11-13**|**Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals**|Shruti Singh Baghel,...Pawan Goyal|[2511.10615](http://arxiv.org/abs/2511.10615)|null|\n", "2511.10590": "|**2025-11-13**|**Pretrained Joint Predictions for Scalable Batch Bayesian Optimization of Molecular Designs**|Miles Wang-Henderson,...John Parkhill|[2511.10590](http://arxiv.org/abs/2511.10590)|null|\n", "2511.10572": "|**2025-11-13**|**Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback**|Mohammadsina Almasi,...Hadis Anahideh|[2511.10572](http://arxiv.org/abs/2511.10572)|null|\n", "2511.10571": "|**2025-11-13**|**Belief Net: A Filter-Based Framework for Learning Hidden Markov Models from Observations**|Reginald Zhiyan Chen,...Prashant G. Mehta|[2511.10571](http://arxiv.org/abs/2511.10571)|null|\n", "2511.10539": "|**2025-11-13**|**Dynamic Avatar-Scene Rendering from Human-centric Context**|Wenqing Wang,...Xiatian Zhu|[2511.10539](http://arxiv.org/abs/2511.10539)|null|\n", "2511.10518": "|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Wei Li,...Liqiang Nie|[2511.10518](http://arxiv.org/abs/2511.10518)|**[link](https://github.com/JiuTian-VL/SemanticVLA)**|\n", "2511.10516": "|**2025-11-13**|**How Worrying Are Privacy Attacks Against Machine Learning?**|Josep Domingo-Ferrer,...Josep Domingo-Ferrer|[2511.10516](http://arxiv.org/abs/2511.10516)|null|\n", "2511.10502": "|**2025-11-13**|**On the Detectability of Active Gradient Inversion Attacks in Federated Learning**|Vincenzo Carletti,...Mario Vento|[2511.10502](http://arxiv.org/abs/2511.10502)|null|\n", "2511.10501": "|**2025-11-13**|**Strategic Opponent Modeling with Graph Neural Networks, Deep Reinforcement Learning and Probabilistic Topic Modeling**|Georgios Chalkiadakis,...Leonidas Bakopoulos|[2511.10501](http://arxiv.org/abs/2511.10501)|null|\n", "2511.10459": "|**2025-11-13**|**LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning**|Zihan Gao,...Jacob Thebault-Spieker|[2511.10459](http://arxiv.org/abs/2511.10459)|null|\n", "2511.10434": "|**2025-11-13**|**Unlocking Dynamic Inter-Client Spatial Dependencies: A Federated Spatio-Temporal Graph Learning Method for Traffic Flow Forecasting**|Feng Wang,...Zhiming Zheng|[2511.10434](http://arxiv.org/abs/2511.10434)|null|\n", "2511.10411": "|**2025-11-13**|**LongComp: Long-Tail Compositional Zero-Shot Generalization for Robust Trajectory Prediction**|Benjamin Stoler,...Jean Oh|[2511.10411](http://arxiv.org/abs/2511.10411)|null|\n", "2511.10403": "|**2025-11-13**|**nuPlan-R: A Closed-Loop Planning Benchmark for Autonomous Driving via Reactive Multi-Agent Simulation**|Mingxing Peng,...Jun Ma|[2511.10403](http://arxiv.org/abs/2511.10403)|null|\n", "2511.10400": "|**2025-11-13**|**Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance**|Lifan Zheng,...Yu Tian|[2511.10400](http://arxiv.org/abs/2511.10400)|null|\n", "2511.10394": "|**2025-11-13**|**LLM-YOLOMS: Large Language Model-based Semantic Interpretation and Fault Diagnosis for Wind Turbine Components**|Yaru Li,...Jianbo Feng|[2511.10394](http://arxiv.org/abs/2511.10394)|null|\n", "2511.10390": "|**2025-11-13**|**MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns**|Jiarui Zhang,...Xiang Bai|[2511.10390](http://arxiv.org/abs/2511.10390)|null|\n", "2511.10387": "|**2025-11-13**|**Physics informed Transformer-VAE for biophysical parameter estimation: PROSAIL model inversion in Sentinel-2 imagery**|Prince Mensah,...Arnu Pretorius|[2511.10387](http://arxiv.org/abs/2511.10387)|null|\n", "2511.10385": "|**2025-11-13**|**SAMIRO: Spatial Attention Mutual Information Regularization with a Pre-trained Model as Oracle for Lane Detection**|Hyunjong Lee,...Jaekoo Lee|[2511.10385](http://arxiv.org/abs/2511.10385)|null|\n", "2511.10383": "|**2025-11-13**|**Operator Models for Continuous-Time Offline Reinforcement Learning**|Nicolas Hoischen,...Sandra Hirche|[2511.10383](http://arxiv.org/abs/2511.10383)|null|\n", "2511.11562": "|**2025-11-14**|**PRBench: Large-Scale Expert Rubrics for Evaluating High-Stakes Professional Reasoning**|Afra Feyza Aky\u00fcrek,...Yunzhong He|[2511.11562](http://arxiv.org/abs/2511.11562)|null|\n", "2511.11520": "|**2025-11-14**|**Scalable Policy Evaluation with Video World Models**|Wei-Cheng Tseng,...Lin Yen-Chen|[2511.11520](http://arxiv.org/abs/2511.11520)|null|\n", "2511.11503": "|**2025-11-14**|**SynthSoM-Twin: A Multi-Modal Sensing-Communication Digital-Twin Dataset for Sim2Real Transfer via Synesthesia of Machines**|Junlong Chen,...Liuqing Yang|[2511.11503](http://arxiv.org/abs/2511.11503)|null|\n", "2511.11473": "|**2025-11-14**|**Proactive Hearing Assistants that Isolate Egocentric Conversations**|Guilin Hu,...Shyamnath Gollakota|[2511.11473](http://arxiv.org/abs/2511.11473)|null|\n", "2511.11470": "|**2025-11-14**|**Sat2RealCity: Geometry-Aware and Appearance-Controllable 3D Urban Generation from Satellite Imagery**|Yijie Kang,...Hailong Zhu|[2511.11470](http://arxiv.org/abs/2511.11470)|null|\n", "2511.11462": "|**2025-11-14**|**MoCap2Radar: A Spatiotemporal Transformer for Synthesizing Micro-Doppler Radar Signatures from Motion Capture**|Kevin Chen,...Anish Arora|[2511.11462](http://arxiv.org/abs/2511.11462)|null|\n", "2511.11459": "|**2025-11-14**|**FairReweighing: Density Estimation-Based Reweighing Framework for Improving Separation in Fair Regression**|Xiaoyin Xi,...Zhe Yu|[2511.11459](http://arxiv.org/abs/2511.11459)|null|\n", "2511.11450": "|**2025-11-14**|**VoxTell: Free-Text Promptable Universal 3D Medical Image Segmentation**|Maximilian Rokuss,...Klaus Maier-Hein|[2511.11450](http://arxiv.org/abs/2511.11450)|null|\n", "2511.11440": "|**2025-11-14**|**From Synthetic Scenes to Real Performance: Enhancing Spatial Reasoning in VLMs**|Massimo Rizzoli,...Giuseppe Riccardi|[2511.11440](http://arxiv.org/abs/2511.11440)|null|\n", "2511.11438": "|**2025-11-14**|**VP-Bench: A Comprehensive Benchmark for Visual Prompting in Multimodal Large Language Models**|Mingjie Xu,...Wenqiang Lei|[2511.11438](http://arxiv.org/abs/2511.11438)|null|\n", "2511.11434": "|**2025-11-14**|**WEAVE: Unleashing and Benchmarking the In-context Interleaved Comprehension and Generation**|Wei Chow,...Tat-Seng Chua|[2511.11434](http://arxiv.org/abs/2511.11434)|null|\n", "2511.11406": "|**2025-11-14**|**Disentangling Emotional Bases and Transient Fluctuations: A Low-Rank Sparse Decomposition Approach for Video Affective Analysis**|Feng-Qi Cui,...Meng Wang|[2511.11406](http://arxiv.org/abs/2511.11406)|null|\n", "2511.11393": "|**2025-11-14**|**Robust and Efficient Communication in Multi-Agent Reinforcement Learning**|Zejiao Liu,...Yang Tang|[2511.11393](http://arxiv.org/abs/2511.11393)|null|\n", "2511.11357": "|**2025-11-14**|**KarmaTS: A Universal Simulation Platform for Multivariate Time Series with Functional Causal Dynamics**|Haixin Li,...Diego Paez-Granados|[2511.11357](http://arxiv.org/abs/2511.11357)|null|\n", "2511.11338": "|**2025-11-14**|**Extreme-PLS with missing data under weak dependence**|St\u00e9phane Girard,...Cambyse Pakzad|[2511.11338](http://arxiv.org/abs/2511.11338)|null|\n", "2511.11323": "|**2025-11-14**|**RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms**|Yitian Kou,...Shuguang Kuai|[2511.11323](http://arxiv.org/abs/2511.11323)|null|\n", "2511.11315": "|**2025-11-14**|**LAET: A Layer-wise Adaptive Ensemble Tuning Framework for Pretrained Language Models**|Jawad Ibn Ahad,...Shafin Rahman|[2511.11315](http://arxiv.org/abs/2511.11315)|null|\n", "2511.11298": "|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Yihao Zhang,...Xi Zheng|[2511.11298](http://arxiv.org/abs/2511.11298)|null|\n", "2511.11294": "|**2025-11-14**|**Decomposing Direct and Indirect Biases in Linear Models under Demographic Parity Constraint**|Bertille Tierny,...Fran\u00e7ois Hu|[2511.11294](http://arxiv.org/abs/2511.11294)|null|\n", "2511.11286": "|**2025-11-14**|**D-GAP: Improving Out-of-Domain Robustness via Dataset-Agnostic and Gradient-Guided Augmentation in Amplitude and Pixel Spaces**|Ruoqi Wang,...Qiong Luo|[2511.11286](http://arxiv.org/abs/2511.11286)|null|\n", "2511.13717": "|**2025-11-17**|**TZ-LLM: Protecting On-Device Large Language Models with Arm TrustZone**|Xunjie Wang,...Jinyu Gu|[2511.13717](http://arxiv.org/abs/2511.13717)|null|\n", "2511.13715": "|**2025-11-17**|**Segment Anything Across Shots: A Method and Benchmark**|Hengrui Hu,...Henghui Ding|[2511.13715](http://arxiv.org/abs/2511.13715)|**[link](https://henghuiding.com/SAAS/)**|\n", "2511.13714": "|**2025-11-17**|**UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity**|Junwei Yu,...XuDong Wang|[2511.13714](http://arxiv.org/abs/2511.13714)|null|\n", "2511.13713": "|**2025-11-17**|**Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine**|Xincheng Shuai,...Dacheng Tao|[2511.13713](http://arxiv.org/abs/2511.13713)|**[link](https://henghuiding.com/FFSE/)**|\n", "2511.13712": "|**2025-11-17**|**From Black Box to Insight: Explainable AI for Extreme Event Preparedness**|Kiana Vu,...Jennifer Wei|[2511.13712](http://arxiv.org/abs/2511.13712)|null|\n", "2511.13710": "|**2025-11-17**|**From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands**|Jianglong Ye,...Xiaolong Wang|[2511.13710](http://arxiv.org/abs/2511.13710)|**[link](https://jianglongye.com/power-to-precision)**|\n", "2511.13703": "|**2025-11-17**|**Generalist Foundation Models Are Not Clinical Enough for Hospital Operations**|Lavender Y. Jiang,...Eric Karl Oermann|[2511.13703](http://arxiv.org/abs/2511.13703)|null|\n", "2511.13661": "|**2025-11-17**|**Ontology-Driven Model-to-Model Transformation of Workflow Specifications**|Francisco Abreu,...S\u00e9rgio Guerreiro|[2511.13661](http://arxiv.org/abs/2511.13661)|null|\n", "2511.13655": "|**2025-11-17**|**OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation**|Henry Herzog,...Patrick Beukema|[2511.13655](http://arxiv.org/abs/2511.13655)|null|\n", "2511.13648": "|**2025-11-17**|**PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image**|Ziang Cao,...Ziwei Liu|[2511.13648](http://arxiv.org/abs/2511.13648)|**[link](https://physx-anything.github.io/)**|\n", "2511.13646": "|**2025-11-17**|**Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?**|Chunqiu Steven Xia,...Lingming Zhang|[2511.13646](http://arxiv.org/abs/2511.13646)|null|\n", "2511.13629": "|**2025-11-17**|**Sensitivity to low-mass WIMPs with an improved liquid argon ionization response model within the DarkSide programme**|F. Acerbi,...M. P. Zykova|[2511.13629](http://arxiv.org/abs/2511.13629)|null|\n", "2511.13590": "|**2025-11-17**|**Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation**|Hao Wang,...Xing Chen|[2511.13590](http://arxiv.org/abs/2511.13590)|null|\n", "2511.13541": "|**2025-11-17**|**Graph Out-of-Distribution Detection via Test-Time Calibration with Dual Dynamic Dictionaries**|Yue Hou,...Ke Xu|[2511.13541](http://arxiv.org/abs/2511.13541)|null|\n", "2511.13523": "|**2025-11-17**|**Compact Multimodal Language Models as Robust OCR Alternatives for Noisy Textual Clinical Reports**|Nikita Neveditsin,...Vijay Mago|[2511.13523](http://arxiv.org/abs/2511.13523)|null|\n", "2511.13502": "|**2025-11-17**|**Tight and Practical Privacy Auditing for Differentially Private In-Context Learning**|Yuyang Xia,...Li Xiong|[2511.13502](http://arxiv.org/abs/2511.13502)|null|\n", "2511.13481": "|**2025-11-17**|**Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact on Abnormal Returns**|Attapol T. Rutherford,...Nanthicha Angsuwichitkul|[2511.13481](http://arxiv.org/abs/2511.13481)|null|\n", "2511.13478": "|**2025-11-17**|**Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling**|Adam Hazimeh,...Pascal Frossard|[2511.13478](http://arxiv.org/abs/2511.13478)|null|\n", "2511.13476": "|**2025-11-17**|**Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation**|Zhipeng Ma,...Zheng Grace Ma|[2511.13476](http://arxiv.org/abs/2511.13476)|null|\n", "2511.13463": "|**2025-11-17**|**Multi-task GINN-LP for Multi-target Symbolic Regression**|Hussein Rajabu,...Xishuang Dong|[2511.13463](http://arxiv.org/abs/2511.13463)|null|\n", "2511.14759": "|**2025-11-18**|**$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience**|Ali Amin,...Zhiyuan Zhou|[2511.14759](http://arxiv.org/abs/2511.14759)|null|\n", "2511.14738": "|**2025-11-18**|**LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data**|Tzu-Hsuan Chou,...Chun-Nan Chou|[2511.14738](http://arxiv.org/abs/2511.14738)|null|\n", "2511.14715": "|**2025-11-18**|**\\textit{FLARE}: Adaptive Multi-Dimensional Reputation for Robust Client Reliability in Federated Learning**|Abolfazl Younesi,...Thomas Fahringer|[2511.14715](http://arxiv.org/abs/2511.14715)|null|\n", "2511.14711": "|**2025-11-18**|**Why Do We Code? A Theory on Motivations and Challenges in Software Engineering from Education to Practice**|Aaliyah Chang,...Brittany Johnson|[2511.14711](http://arxiv.org/abs/2511.14711)|null|\n", "2511.14698": "|**2025-11-18**|**HyMAD: A Hybrid Multi-Activity Detection Approach for Border Surveillance and Monitoring**|Sriram Srinivasan,...Siva Ram Krisha Vadali|[2511.14698](http://arxiv.org/abs/2511.14698)|null|\n", "2511.14659": "|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung,...Soujanya Poria|[2511.14659](http://arxiv.org/abs/2511.14659)|**[link](https://declare-lab.github.io/nora-1.5)**|\n", "2511.14640": "|**2025-11-18**|**Doppler Invariant CNN for Signal Classification**|Avi Bagchi,...Dwight Hutchenson|[2511.14640](http://arxiv.org/abs/2511.14640)|null|\n", "2511.14638": "|**2025-11-18**|**A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases**|Tao Yang,...Mulin Jun Li|[2511.14638](http://arxiv.org/abs/2511.14638)|null|\n", "2511.14620": "|**2025-11-18**|**Fusing Biomechanical and Spatio-Temporal Features for Fall Prediction: Characterizing and Mitigating the Simulation-to-Reality Gap**|Md Fokhrul Islam,...Heman Shakeri|[2511.14620](http://arxiv.org/abs/2511.14620)|null|\n", "2511.14604": "|**2025-11-18**|**XAttn-BMD: Multimodal Deep Learning with Cross-Attention for Femoral Neck Bone Mineral Density Estimation**|Yilin Zhang,...Rahman Attar|[2511.14604](http://arxiv.org/abs/2511.14604)|null|\n", "2511.14599": "|**2025-11-18**|**CCSD: Cross-Modal Compositional Self-Distillation for Robust Brain Tumor Segmentation with Missing Modalities**|Dongqing Xie,...Lei Wang|[2511.14599](http://arxiv.org/abs/2511.14599)|null|\n", "2511.14543": "|**2025-11-18**|**MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation**|Youran Zhou,...Sunil Aryal|[2511.14543](http://arxiv.org/abs/2511.14543)|null|\n", "2511.14536": "|**2025-11-18**|**A General Framework for Physician Rostering Using Mixed-Integer Programming and a Web-Based Graphical User Interface**|Florian Meier,...Clemens Thielen|[2511.14536](http://arxiv.org/abs/2511.14536)|null|\n", "2511.14473": "|**2025-11-18**|**Learning Subglacial Bed Topography from Sparse Radar with Physics-Guided Residuals**|Bayu Adhi Tama,...Mostafa Cham|[2511.14473](http://arxiv.org/abs/2511.14473)|null|\n", "2511.14441": "|**2025-11-18**|**Skewness-Robust Causal Discovery in Location-Scale Noise Models**|Daniel Klippert,...Alexander Marx|[2511.14441](http://arxiv.org/abs/2511.14441)|null|\n", "2511.14440": "|**2025-11-18**|**Learning to See Through a Baby's Eyes: Early Visual Diets Enable Robust Visual Intelligence in Humans and Machines**|Yusen Cai,...Mengmi Zhang|[2511.14440](http://arxiv.org/abs/2511.14440)|null|\n", "2511.14416": "|**2025-11-18**|**Toward Robust and Harmonious Adaptation for Cross-modal Retrieval**|Haobin Li,...Xi Peng|[2511.14416](http://arxiv.org/abs/2511.14416)|null|\n", "2511.14386": "|**2025-11-18**|**Cheating Stereo Matching in Full-scale: Physical Adversarial Attack against Binocular Depth Estimation in Autonomous Driving**|Kangqiao Zhao,...Jun Luo|[2511.14386](http://arxiv.org/abs/2511.14386)|null|\n", "2511.14385": "|**2025-11-18**|**Mitigating Label Length Bias in Large Language Models**|Mario Sanz-Guerrero,...Katharina von der Wense|[2511.14385](http://arxiv.org/abs/2511.14385)|null|\n", "2511.14368": "|**2025-11-18**|**O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model**|Rishi Gupta,...Anirban Chakraborty|[2511.14368](http://arxiv.org/abs/2511.14368)|null|\n", "2511.15706": "|**2025-11-19**|**RoMa v2: Harder Better Faster Denser Feature Matching**|Johan Edstedt,...Michael Felsberg|[2511.15706](http://arxiv.org/abs/2511.15706)|null|\n", "2511.15705": "|**2025-11-19**|**GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization**|Yikun Wang,...Yongming Rao|[2511.15705](http://arxiv.org/abs/2511.15705)|null|\n", "2511.15633": "|**2025-11-19**|**Hierarchical Semantic Tree Anchoring for CLIP-Based Class-Incremental Learning**|Tao Hu,...Da-Wei Zhou|[2511.15633](http://arxiv.org/abs/2511.15633)|null|\n", "2511.15605": "|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Senyu Fei,...Xipeng Qiu|[2511.15605](http://arxiv.org/abs/2511.15605)|null|\n", "2511.15567": "|**2025-11-19**|**Computer-Use Agents as Judges for Generative User Interface**|Kevin Qinghong Lin,...Mike Zheng Shou|[2511.15567](http://arxiv.org/abs/2511.15567)|**[link](https://showlab.github.io/AUI)**|\n", "2511.15565": "|**2025-11-19**|**Scriboora: Rethinking Human Pose Forecasting**|Daniel Bermuth,...Wolfgang Reif|[2511.15565](http://arxiv.org/abs/2511.15565)|null|\n", "2511.15532": "|**2025-11-19**|**NMPC-based Motion Planning with Adaptive Weighting for Dynamic Object Interception**|Chen Cai,...Steven Liu|[2511.15532](http://arxiv.org/abs/2511.15532)|null|\n", "2511.15511": "|**2025-11-19**|**Efficient Exoplanet Imaging Simulations of the Habitable Worlds Observatory**|Jamila Taaki,...Alfred O. Hero|[2511.15511](http://arxiv.org/abs/2511.15511)|null|\n", "2511.15479": "|**2025-11-19**|**Towards a Formal Verification of Secure Vehicle Software Updates**|Martin Slind Hagen,...Elad Michael Schiller|[2511.15479](http://arxiv.org/abs/2511.15479)|null|\n", "2511.15468": "|**2025-11-19**|**Deep Learning for Accurate Vision-based Catch Composition in Tropical Tuna Purse Seiners**|Xabier Lekunberri,...Jose A. Fernandes-Salvador|[2511.15468](http://arxiv.org/abs/2511.15468)|null|\n", "2511.15463": "|**2025-11-19**|**How To Cook The Fragmented Rug Pull?**|Minh Trung Tran,...Qin Wang|[2511.15463](http://arxiv.org/abs/2511.15463)|null|\n", "2511.15443": "|**2025-11-19**|**CroPS: Improving Dense Retrieval with Cross-Perspective Positive Samples in Short-Video Search**|Ao Xie,...Han Li|[2511.15443](http://arxiv.org/abs/2511.15443)|null|\n", "2511.15429": "|**2025-11-19**|**WarNav: An Autonomous Driving Benchmark for Segmentation of Navigable Zones in War Scenes**|Marc-Emmanuel Coupvent des Graviers,...Romaric Audigier|[2511.15429](http://arxiv.org/abs/2511.15429)|null|\n", "2511.15411": "|**2025-11-19**|**D4C: Data-free Quantization for Contrastive Language-Image Pre-training Models**|Wenlun Zhang,...Kentaro Yoshioka|[2511.15411](http://arxiv.org/abs/2511.15411)|null|\n", "2511.15407": "|**2025-11-19**|**IPR-1: Interactive Physical Reasoner**|Mingyu Zhang,...Yong-Lu Li|[2511.15407](http://arxiv.org/abs/2511.15407)|null|\n", "2511.15392": "|**2025-11-19**|**DEPO: Dual-Efficiency Preference Optimization for LLM Agents**|Sirui Chen,...Chaochao Lu|[2511.15392](http://arxiv.org/abs/2511.15392)|null|\n", "2511.15390": "|**2025-11-19**|**Breaking Expert Knowledge Limits: Self-Pruning for Large Language Models**|Haidong Kang,...Hao Wang|[2511.15390](http://arxiv.org/abs/2511.15390)|null|\n", "2511.15379": "|**2025-11-19**|**Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training**|Yunjiao Zhou,...Jianfei Yang|[2511.15379](http://arxiv.org/abs/2511.15379)|null|\n", "2511.15377": "|**2025-11-19**|**Towards Evolutionary Optimization Using the Ising Model**|Simon Kl\u00fcttermann,...Simon Kl\u00fcttermann|[2511.15377](http://arxiv.org/abs/2511.15377)|null|\n", "2511.15375": "|**2025-11-19**|**Parameter Importance-Driven Continual Learning for Foundation Models**|Lingxiang Wang,...Zhiming Zheng|[2511.15375](http://arxiv.org/abs/2511.15375)|null|\n", "2511.16669": "|**2025-11-20**|**Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO**|Junhao Cheng,...Jing Liao|[2511.16669](http://arxiv.org/abs/2511.16669)|**[link](https://video-as-answer.github.io/)**|\n", "2511.16668": "|**2025-11-20**|**V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models**|Yang Luo,...Yang You|[2511.16668](http://arxiv.org/abs/2511.16668)|**[link](https://oahzxl.github.io/VReasonBench)**|\n", "2511.16655": "|**2025-11-20**|**Solving Spatial Supersensing Without Spatial Supersensing**|Vishaal Udandarao,...Ameya Prabhu|[2511.16655](http://arxiv.org/abs/2511.16655)|null|\n", "2511.16651": "|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Yang Tian,...Jiangmiao Pang|[2511.16651](http://arxiv.org/abs/2511.16651)|null|\n", "2511.16624": "|**2025-11-20**|**SAM 3D: 3Dfy Anything in Images**|SAM 3D Team,...Jitendra Malik|[2511.16624](http://arxiv.org/abs/2511.16624)|**[link](https://ai.meta.com/sam3d/)**|\n", "2511.16618": "|**2025-11-20**|**SAM2S: Segment Anything in Surgical Videos via Semantic Long-term Tracking**|Haofeng Liu,...Yueming Jin|[2511.16618](http://arxiv.org/abs/2511.16618)|null|\n", "2511.16602": "|**2025-11-20**|**Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization**|Yi Zhang,...Xiaozhu Ju|[2511.16602](http://arxiv.org/abs/2511.16602)|null|\n", "2511.16596": "|**2025-11-20**|**Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies**|Zohar Rimon,...Aviv Tamar|[2511.16596](http://arxiv.org/abs/2511.16596)|null|\n", "2511.16571": "|**2025-11-20**|**Boosting Predictive Performance on Tabular Data through Data Augmentation with Latent-Space Flow-Based Diffusion**|Md. Tawfique Ihsan,...Abdullahil Azeem|[2511.16571](http://arxiv.org/abs/2511.16571)|null|\n", "2511.16555": "|**2025-11-20**|**Lite Any Stereo: Efficient Zero-Shot Stereo Matching**|Junpeng Jing,...Krystian Mikolajczyk|[2511.16555](http://arxiv.org/abs/2511.16555)|null|\n", "2511.16551": "|**2025-11-20**|**Toward Valid Generative Clinical Trial Data with Survival Endpoints**|Perrine Chassat,...Agathe Guilloux|[2511.16551](http://arxiv.org/abs/2511.16551)|null|\n", "2511.16549": "|**2025-11-20**|**FairLRF: Achieving Fairness through Sparse Low Rank Factorization**|Yuanbo Guo,...Yiyu Shi|[2511.16549](http://arxiv.org/abs/2511.16549)|null|\n", "2511.16528": "|**2025-11-20**|**TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval**|\u00d6zay Ezerceli,...Ya\u011f\u0131z Asker|[2511.16528](http://arxiv.org/abs/2511.16528)|null|\n", "2511.16484": "|**2025-11-20**|**Flow and Depth Assisted Video Prediction with Latent Transformer**|Eliyas Suleyman,...Nicolas Pugeault|[2511.16484](http://arxiv.org/abs/2511.16484)|null|\n", "2511.16482": "|**2025-11-20**|**Correlation-Aware Feature Attribution Based Explainable AI**|Poushali Sengupta,...Sabita Maharjan|[2511.16482](http://arxiv.org/abs/2511.16482)|null|\n", "2511.16450": "|**2025-11-20**|**Optimizing Federated Learning in the Era of LLMs: Message Quantization and Streaming**|Ziyue Xu,...Andrew Feng|[2511.16450](http://arxiv.org/abs/2511.16450)|null|\n", "2511.16440": "|**2025-11-20**|**StreetView-Waste: A Multi-Task Dataset for Urban Waste Management**|Diogo J. Paulo,...Jo\u00e3o C. Neves|[2511.16440](http://arxiv.org/abs/2511.16440)|null|\n", "2511.16432": "|**2025-11-20**|**From generative AI to the brain: five takeaways**|Claudius Gros,...Claudius Gros|[2511.16432](http://arxiv.org/abs/2511.16432)|null|\n", "2511.16427": "|**2025-11-20**|**Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations**|Muhammad Aslanimoghanloo,...Marcel van Gerven|[2511.16427](http://arxiv.org/abs/2511.16427)|null|\n", "2511.16426": "|**2025-11-20**|**FreqFlow: Long-term forecasting using lightweight flow matching**|Seyed Mohamad Moghadas,...Adrian Munteanu|[2511.16426](http://arxiv.org/abs/2511.16426)|null|\n", "2511.17502": "|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Jun Cen,...Hao Chen|[2511.17502](http://arxiv.org/abs/2511.17502)|null|\n", "2511.17496": "|**2025-11-21**|**MDG: Masked Denoising Generation for Multi-Agent Behavior Modeling in Traffic Environments**|Zhiyu Huang,...Jiaqi Ma|[2511.17496](http://arxiv.org/abs/2511.17496)|null|\n", "2511.17492": "|**2025-11-21**|**EvDiff: High Quality Video with an Event Camera**|Weilun Li,...Danda Pani Paudel|[2511.17492](http://arxiv.org/abs/2511.17492)|null|\n", "2511.17484": "|**2025-11-21**|**Radar2Shape: 3D Shape Reconstruction from High-Frequency Radar using Multiresolution Signed Distance Functions**|Neel Sortur,...Robin Walters|[2511.17484](http://arxiv.org/abs/2511.17484)|null|\n", "2511.17481": "|**2025-11-21**|**Counterfactual World Models via Digital Twin-conditioned Video Diffusion**|Yiqing Shen,...Mathias Unberath|[2511.17481](http://arxiv.org/abs/2511.17481)|null|\n", "2511.17421": "|**2025-11-21**|**Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers**|Christopher Boland,...Sonia Dahdouh|[2511.17421](http://arxiv.org/abs/2511.17421)|**[link](https://melba-journal.org/2025:020)**|\n", "2511.17411": "|**2025-11-21**|**SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding**|Nikolay Nikolov,...Danda Pani Paudel|[2511.17411](http://arxiv.org/abs/2511.17411)|null|\n", "2511.17400": "|**2025-11-21**|**Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel Interactions Required?**|Sukwon Yun,...Russell Littman|[2511.17400](http://arxiv.org/abs/2511.17400)|null|\n", "2511.17384": "|**2025-11-21**|**IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation**|Yifan Li,...Yu Kong|[2511.17384](http://arxiv.org/abs/2511.17384)|null|\n", "2511.17368": "|**2025-11-21**|**Exploring Scientific Debt: Harnessing AI for SATD Identification in Scientific Software**|Eric L. Melin,...Shurui Zhou|[2511.17368](http://arxiv.org/abs/2511.17368)|null|\n", "2511.17366": "|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Yankai Fu,...Shanghang Zhang|[2511.17366](http://arxiv.org/abs/2511.17366)|null|\n", "2511.17353": "|**2025-11-21**|**Learning Latent Transmission and Glare Maps for Lens Veiling Glare Removal**|Xiaolong Qian,...Kaiwei Wang|[2511.17353](http://arxiv.org/abs/2511.17353)|**[link](https://github.com/XiaolongQian/DeVeiler)**|\n", "2511.17344": "|**2025-11-21**|**Loomis Painter: Reconstructing the Painting Process**|Markus Pobitzer,...Nicu Sebe|[2511.17344](http://arxiv.org/abs/2511.17344)|null|\n", "2511.17335": "|**2025-11-21**|**Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM**|Chiori Hori,...Jonathan Le Roux|[2511.17335](http://arxiv.org/abs/2511.17335)|null|\n", "2511.17304": "|**2025-11-21**|**Law-Strength Frontiers and a No-Free-Lunch Result for Law-Seeking Reinforcement Learning on Volatility Law Manifolds**|Jian'an Zhang,...Jian'an Zhang|[2511.17304](http://arxiv.org/abs/2511.17304)|null|\n", "2511.17247": "|**2025-11-21**|**Signed Networks: theory, methods, and applications**|Fernando Diaz-Diaz,...Andreia Sofia Teixeira|[2511.17247](http://arxiv.org/abs/2511.17247)|null|\n", "2511.17245": "|**2025-11-21**|**Simulated Annealing for Quadratic and Higher-Order Unconstrained Integer Optimization**|Kohei Suzuki,...Kohei Suzuki|[2511.17245](http://arxiv.org/abs/2511.17245)|null|\n", "2511.17238": "|**2025-11-21**|**Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables**|Anshul Singh,...Abhay Kumary|[2511.17238](http://arxiv.org/abs/2511.17238)|null|\n", "2511.17235": "|**2025-11-21**|**NX-CGRA: A Programmable Hardware Accelerator for Core Transformer Algorithms on Edge Devices**|Rohit Prasad,...Rohit Prasad|[2511.17235](http://arxiv.org/abs/2511.17235)|null|\n", "2511.17228": "|**2025-11-21**|**Intrinsic preservation of plasticity in continual quantum learning**|Yu-Qin Chen,...Shi-Xin Zhang|[2511.17228](http://arxiv.org/abs/2511.17228)|null|\n", "2511.21690": "|**2025-11-26**|**TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos**|Seungjae Lee,...Furong Huang|[2511.21690](http://arxiv.org/abs/2511.21690)|null|\n", "2511.21668": "|**2025-11-26**|**Through the telecom lens: Are all training samples important?**|Shruti Bothe,...Md Moin Uddin Chowdhury|[2511.21668](http://arxiv.org/abs/2511.21668)|null|\n", "2511.21667": "|**2025-11-26**|**Escaping the Verifier: Learning to Reason via Demonstrations**|Locke Cai,...Ivan Provilkov|[2511.21667](http://arxiv.org/abs/2511.21667)|null|\n", "2511.21666": "|**2025-11-26**|**Uncertainty Quantification for Visual Object Pose Estimation**|Lorenzo Shaikewitz,...Luca Carlone|[2511.21666](http://arxiv.org/abs/2511.21666)|**[link](https://github.com/MIT-SPARK/PoseUncertaintySets)**|\n", "2511.21652": "|**2025-11-26**|**Continual Error Correction on Low-Resource Devices**|Kirill Paramonov,...Umberto Michieli|[2511.21652](http://arxiv.org/abs/2511.21652)|null|\n", "2511.21631": "|**2025-11-26**|**Qwen3-VL Technical Report**|Shuai Bai,...Ke Zhu|[2511.21631](http://arxiv.org/abs/2511.21631)|null|\n", "2511.21624": "|**2025-11-26**|**TAGFN: A Text-Attributed Graph Dataset for Fake News Detection in the Age of LLMs**|Kay Liu,...Philip S. Yu|[2511.21624](http://arxiv.org/abs/2511.21624)|null|\n", "2511.21579": "|**2025-11-26**|**Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy**|Teng Hu,...Ran Yi|[2511.21579](http://arxiv.org/abs/2511.21579)|null|\n", "2511.21557": "|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Hui Zhou,...Shaoshuai Shi|[2511.21557](http://arxiv.org/abs/2511.21557)|null|\n", "2511.21542": "|**2025-11-26**|**$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Zhihao Zhan,...Guangrun Wang|[2511.21542](http://arxiv.org/abs/2511.21542)|null|\n", "2511.21531": "|**2025-11-26**|**Predictive Safety Shield for Dyna-Q Reinforcement Learning**|Jin Pin,...Vanneaux Elena|[2511.21531](http://arxiv.org/abs/2511.21531)|null|\n", "2511.21519": "|**2025-11-26**|**Self-Paced Learning for Images of Antinuclear Antibodies**|Yiyang Jiang,...Xiao-Yong Wei|[2511.21519](http://arxiv.org/abs/2511.21519)|null|\n", "2511.21471": "|**2025-11-26**|**SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition**|Peiran Xu,...Yunjian Zhang|[2511.21471](http://arxiv.org/abs/2511.21471)|null|\n", "2511.21465": "|**2025-11-26**|**Ensemble Performance Through the Lens of Linear Independence of Classifier Votes in Data Streams**|Enes Bektas,...Fazli Can|[2511.21465](http://arxiv.org/abs/2511.21465)|null|\n", "2511.21460": "|**2025-11-26**|**MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning**|Junjian Wang,...Xi Sheryl Zhang|[2511.21460](http://arxiv.org/abs/2511.21460)|null|\n", "2511.21398": "|**2025-11-26**|**Prune4Web: DOM Tree Pruning Programming for Web Agent**|Jiayuan Zhang,...Jing Zhang|[2511.21398](http://arxiv.org/abs/2511.21398)|null|\n", "2511.21395": "|**2025-11-26**|**Monet: Reasoning in Latent Visual Space Beyond Images and Language**|Qixun Wang,...Yisen Wang|[2511.21395](http://arxiv.org/abs/2511.21395)|null|\n", "2511.21389": "|**2025-11-26**|**FITRep: Attention-Guided Item Representation via MLLMs**|Guoxiao Zhang,...Xingxing Wang|[2511.21389](http://arxiv.org/abs/2511.21389)|null|\n", "2511.21378": "|**2025-11-26**|**Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data**|Jungi Lee,...Seok-Joo Byun|[2511.21378](http://arxiv.org/abs/2511.21378)|null|\n", "2511.21369": "|**2025-11-26**|**Differentiable Physics-Neural Models enable Learning of Non-Markovian Closures for Accelerated Coarse-Grained Physics Simulations**|Tingkai Xue,...Chang Wei Kang|[2511.21369](http://arxiv.org/abs/2511.21369)|null|\n", "2512.03044": "|**2025-12-02**|**Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling**|Yueru Jia,...Shanghang Zhang|[2512.03044](http://arxiv.org/abs/2512.03044)|null|\n", "2512.03036": "|**2025-12-02**|**ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation**|Mengchen Zhang,...Dahua Lin|[2512.03036](http://arxiv.org/abs/2512.03036)|null|\n", "2512.03034": "|**2025-12-02**|**MAViD: A Multimodal Framework for Audio-Visual Dialogue Understanding and Generation**|Youxin Pang,...Yebin Liu|[2512.03034](http://arxiv.org/abs/2512.03034)|**[link](https://carlyx.github.io/MAViD/)**|\n", "2512.03021": "|**2025-12-02**|**Semiparametric Robust Estimation of Population Location**|Ananyabrata Barua,...Ayanendranath Basu|[2512.03021](http://arxiv.org/abs/2512.03021)|null|\n", "2512.03000": "|**2025-12-02**|**DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling**|Kairun Wen,...Zhiwen Fan|[2512.03000](http://arxiv.org/abs/2512.03000)|null|\n", "2512.02983": "|**2025-12-02**|**ProteinPNet: Prototypical Part Networks for Concept Learning in Spatial Proteomics**|Louis McConnell,...Marianna Rapsomaniki|[2512.02983](http://arxiv.org/abs/2512.02983)|null|\n", "2512.02982": "|**2025-12-02**|**U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences**|Xiang Xu,...Qingshan Liu|[2512.02982](http://arxiv.org/abs/2512.02982)|null|\n", "2512.02981": "|**2025-12-02**|**InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration**|Zhongyu Yang,...Wei Pang|[2512.02981](http://arxiv.org/abs/2512.02981)|null|\n", "2512.02952": "|**2025-12-02**|**Layout Anything: One Transformer for Universal Room Layout Estimation**|Md Sohag Mia,...Muhammad Abdullah Adnan|[2512.02952](http://arxiv.org/abs/2512.02952)|null|\n", "2512.02942": "|**2025-12-02**|**Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench**|Lanxiang Hu,...Hao Zhang|[2512.02942](http://arxiv.org/abs/2512.02942)|null|\n", "2512.02924": "|**2025-12-02**|**AutoNeural: Co-Designing Vision-Language Models for NPU Inference**|Wei Chen,...Han Yang|[2512.02924](http://arxiv.org/abs/2512.02924)|null|\n", "2512.02912": "|**2025-12-02**|**Hypothesis Testing for Generalized Thurstone Models**|Anuran Makur,...Japneet Singh|[2512.02912](http://arxiv.org/abs/2512.02912)|null|\n", "2512.02861": "|**2025-12-02**|**Network Self-Configuration based on Fine-Tuned Small Language Models**|Oscar G. Lira,...Nelson L. S. Da Fonseca|[2512.02861](http://arxiv.org/abs/2512.02861)|null|\n", "2512.02851": "|**2025-12-02**|**SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots**|Iana Zhura,...Dzmitry Tsetserukou|[2512.02851](http://arxiv.org/abs/2512.02851)|null|\n", "2512.02844": "|**2025-12-02**|**VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion**|Xinzheng Wu,...Yong Shen|[2512.02844](http://arxiv.org/abs/2512.02844)|null|\n", "2512.02841": "|**2025-12-02**|**Cross-Lingual Prompt Steerability: Towards Accurate and Robust LLM Behavior across Languages**|Lechen Zhang,...David Jurgens|[2512.02841](http://arxiv.org/abs/2512.02841)|null|\n", "2512.02838": "|**2025-12-02**|**Experimental Blueprint for Distinguishing Decoherence from Objective Collapse**|Ridha Horchani,...Ridha Horchani|[2512.02838](http://arxiv.org/abs/2512.02838)|null|\n", "2512.02835": "|**2025-12-02**|**ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning**|Yifan Li,...Yanwei Fu|[2512.02835](http://arxiv.org/abs/2512.02835)|null|\n", "2512.02787": "|**2025-12-02**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Xianchao Zeng,...Yong-Lu Li|[2512.02787](http://arxiv.org/abs/2512.02787)|null|\n", "2512.02772": "|**2025-12-02**|**Towards Unification of Hallucination Detection and Fact Verification for Large Language Models**|Weihang Su,...Yiqun Liu|[2512.02772](http://arxiv.org/abs/2512.02772)|null|\n", "2512.05115": "|**2025-12-04**|**Light-X: Generative 4D Video Rendering with Camera and Illumination Control**|Tianqi Liu,...Ziwei Liu|[2512.05115](http://arxiv.org/abs/2512.05115)|**[link](https://lightx-ai.github.io/)**|\n", "2512.05103": "|**2025-12-04**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Xiaochuang Han,...Emily Dinan|[2512.05103](http://arxiv.org/abs/2512.05103)|null|\n", "2512.05089": "|**2025-12-04**|**The Geometry of Intelligence: Deterministic Functional Topology as a Foundation for Real-World Perception**|Eduardo Di Santi,...Eduardo Di Santi|[2512.05089](http://arxiv.org/abs/2512.05089)|null|\n", "2512.05079": "|**2025-12-04**|**Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints**|Minghan Zhu,...Michael Posa|[2512.05079](http://arxiv.org/abs/2512.05079)|**[link](https://contactgen3d.github.io/)**|\n", "2512.05076": "|**2025-12-04**|**BulletTime: Decoupled Control of Time and Camera Pose for Video Generation**|Yiming Wang,...Gordon Wetzstein|[2512.05076](http://arxiv.org/abs/2512.05076)|**[link](https://19reborn.github.io/Bullet4D/)**|\n", "2512.05066": "|**2025-12-04**|**Multi-LLM Collaboration for Medication Recommendation**|Huascar Sanchez,...Linda Briesemeister|[2512.05066](http://arxiv.org/abs/2512.05066)|null|\n", "2512.05049": "|**2025-12-04**|**QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory**|Yu-Chao Hsu,...Hsi-Sheng Goan|[2512.05049](http://arxiv.org/abs/2512.05049)|null|\n", "2512.05045": "|**2025-12-04**|**On random matrix statistics of 3d gravity**|Daniel L. Jafferis,...Diandian Wang|[2512.05045](http://arxiv.org/abs/2512.05045)|null|\n", "2512.05044": "|**2025-12-04**|**Joint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image**|Yanran Zhang,...Jiwen Lu|[2512.05044](http://arxiv.org/abs/2512.05044)|null|\n", "2512.04988": "|**2025-12-04**|**Strategic Self-Improvement for Competitive Agents in AI Labour Markets**|Christopher Chiu,...Mihaela van der Schaar|[2512.04988](http://arxiv.org/abs/2512.04988)|null|\n", "2512.04987": "|**2025-12-04**|**Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction**|Nex-AGI Team,...Xipeng Qiu|[2512.04987](http://arxiv.org/abs/2512.04987)|null|\n", "2512.04976": "|**2025-12-04**|**Multipole decomposition of the gravitational field of a point mass at the black hole horizon**|Jo\u00e3o P. B. Brito,...Lu\u00eds C. B. Crispino|[2512.04976](http://arxiv.org/abs/2512.04976)|null|\n", "2512.04969": "|**2025-12-04**|**Rethinking the Use of Vision Transformers for AI-Generated Image Detection**|NaHyeon Park,...Hyunjung Shim|[2512.04969](http://arxiv.org/abs/2512.04969)|**[link](https://github.com/nahyeonkaty/mold)**|\n", "2512.04960": "|**2025-12-04**|**Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies**|Jonne Van Haastregt,...Danica Kragic|[2512.04960](http://arxiv.org/abs/2512.04960)|null|\n", "2512.04952": "|**2025-12-04**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization**|Yicheng Liu,...Hang Zhao|[2512.04952](http://arxiv.org/abs/2512.04952)|null|\n", "2512.04945": "|**2025-12-04**|**TripleC Learning and Lightweight Speech Enhancement for Multi-Condition Target Speech Extraction**|Ziling Huang,...Ziling Huang|[2512.04945](http://arxiv.org/abs/2512.04945)|null|\n", "2512.04885": "|**2025-12-04**|**Stability-Guaranteed Dual Kalman Filtering for Electrochemical Battery State Estimation**|Feng Guo,...Mohammadhosein Safari|[2512.04885](http://arxiv.org/abs/2512.04885)|null|\n", "2512.04883": "|**2025-12-04**|**SDG-Track: A Heterogeneous Observer-Follower Framework for High-Resolution UAV Tracking on Embedded Platforms**|Jiawen Wen,...Xiaowen Chu|[2512.04883](http://arxiv.org/abs/2512.04883)|**[link](https://github.com/Jeffry-wen/SDG-Track)**|\n", "2512.04837": "|**2025-12-04**|**A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World**|Jikang Cheng,...Ling Liang|[2512.04837](http://arxiv.org/abs/2512.04837)|null|\n", "2512.04831": "|**2025-12-04**|**Clustering country-level all-cause mortality data: a review**|Pedro Menezes de Araujo,...Thomas Brendan Murphy|[2512.04831](http://arxiv.org/abs/2512.04831)|null|\n", "2512.07821": "|**2025-12-08**|**WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling**|Shaoheng Fang,...Qixing Huang|[2512.07821](http://arxiv.org/abs/2512.07821)|null|\n", "2512.07733": "|**2025-12-08**|**SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery**|Meng Cao,...Xiaodan Liang|[2512.07733](http://arxiv.org/abs/2512.07733)|null|\n", "2512.07437": "|**2025-12-08**|**KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models**|Chenwei Shi,...Xueyu Luan|[2512.07437](http://arxiv.org/abs/2512.07437)|null|\n", "2512.07237": "|**2025-12-08**|**Unified Camera Positional Encoding for Controlled Video Generation**|Cheng Zhang,...Jianfei Cai|[2512.07237](http://arxiv.org/abs/2512.07237)|**[link](https://github.com/chengzhag/UCPE)**|\n", "2512.06983": "|**2025-12-07**|**On Memory: A comparison of memory mechanisms in world models**|Eli J. Laird,...Corey Clark|[2512.06983](http://arxiv.org/abs/2512.06983)|null|\n", "2512.06865": "|**2025-12-07**|**Spatial Retrieval Augmented Autonomous Driving**|Xiaosong Jia,...Yu-Gang Jiang|[2512.06865](http://arxiv.org/abs/2512.06865)|**[link](https://spatialretrievalad.github.io/)**|\n", "2512.06628": "|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Ruicheng Zhang,...Xiu Li|[2512.06628](http://arxiv.org/abs/2512.06628)|null|\n", "2512.06563": "|**2025-12-06**|**Deep Manifold Part 2: Neural Network Mathematics**|Max Y. Ma,...Gen-Hua Shi|[2512.06563](http://arxiv.org/abs/2512.06563)|null|\n", "2512.05955": "|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Haowen Liu,...Yilun Du|[2512.05955](http://arxiv.org/abs/2512.05955)|null|\n", "2512.05933": "|**2025-12-05**|**Speech World Model: Causal State-Action Planning with Explicit Reasoning for Speech**|Xuanru Zhou,...Gopala Anumanchipalli|[2512.05933](http://arxiv.org/abs/2512.05933)|null|\n", "2512.05927": "|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Zhiting Mei,...Anirudha Majumdar|[2512.05927](http://arxiv.org/abs/2512.05927)|null|\n", "2512.05809": "|**2025-12-05**|**Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling**|Saurav Jha,...Sarath Chandar|[2512.05809](http://arxiv.org/abs/2512.05809)|null|\n", "2512.05361": "|**2025-12-05**|**FieldSeer I: Physics-Guided World Models for Long-Horizon Electromagnetic Dynamics under Partial Observability**|Ziheng Guo,...Yang Bu|[2512.05361](http://arxiv.org/abs/2512.05361)|null|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Pei Yang,...Mike Zheng Shou|[2512.04537](http://arxiv.org/abs/2512.04537)|null|\n", "2512.04515": "|**2025-12-04**|**EgoLCD: Egocentric Video Generation with Long Context Diffusion**|Liuzhou Zhang,...Hao Tang|[2512.04515](http://arxiv.org/abs/2512.04515)|null|\n", "2512.04513": "|**2025-12-04**|**BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models**|Yu-Wei Zhan,...Wenwu Zhu|[2512.04513](http://arxiv.org/abs/2512.04513)|null|\n", "2512.04441": "|**2025-12-08**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Bin Sun,...Ziying Song|[2512.04441](http://arxiv.org/abs/2512.04441)|null|\n", "2512.04341": "|**2025-12-04**|**Long-Horizon Model-Based Offline Reinforcement Learning Without Conservatism**|Tianwei Ni,...Pierre-Luc Bacon|[2512.04341](http://arxiv.org/abs/2512.04341)|null|\n", "2512.04279": "|**2025-12-03**|**Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies**|Feeza Khan Khanzada,...Jaerock Kwon|[2512.04279](http://arxiv.org/abs/2512.04279)|null|\n", "2512.10958": "|**2025-12-11**|**WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World**|Ao Liang,...Ziwei Liu|[2512.10958](http://arxiv.org/abs/2512.10958)|**[link](https://worldbench.github.io/worldlens)**|\n", "2512.10723": "|**2025-12-11**|**Generalized Spherical Neural Operators: Green's Function Formulation**|Hao Tang,...Chao Li|[2512.10723](http://arxiv.org/abs/2512.10723)|null|\n", "2512.10675": "|**2025-12-11**|**Evaluating Gemini Robotics Policies in a Veo World Simulator**|Gemini Robotics Team,...Allan Zhou|[2512.10675](http://arxiv.org/abs/2512.10675)|null|\n", "2512.10226": "|**2025-12-11**|**Latent Chain-of-Thought World Modeling for End-to-End Driving**|Shuhan Tan,...Boris Ivanovic|[2512.10226](http://arxiv.org/abs/2512.10226)|null|\n", "2512.10016": "|**2025-12-10**|**Latent Action World Models for Control with Unlabeled Trajectories**|Marvin Alles,...Philip Becker-Ehmck|[2512.10016](http://arxiv.org/abs/2512.10016)|null|\n", "2512.09929": "|**2025-12-10**|**Closing the Train-Test Gap in World Models for Gradient-Based Planning**|Arjun Parthasarathy,...Micah Goldblum|[2512.09929](http://arxiv.org/abs/2512.09929)|null|\n", "2512.09864": "|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Hao Lu,...Ying-Cong Chen|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|\n", "2512.08931": "|**2025-12-09**|**Astra: General Interactive World Model with Autoregressive Denoising**|Yixuan Zhu,...Jiwen Lu|[2512.08931](http://arxiv.org/abs/2512.08931)|**[link](https://github.com/EternalEvan/Astra)**|\n", "2512.08478": "|**2025-12-09**|**Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform**|Yuning Gong,...Zhihang Zhong|[2512.08478](http://arxiv.org/abs/2512.08478)|**[link](https://visionary-laboratory.github.io/visionary)**|\n", "2512.08411": "|**2025-12-09**|**Prismatic World Model: Learning Compositional Dynamics for Planning in Hybrid Systems**|Mingwei Li,...Yaodong Yang|[2512.08411](http://arxiv.org/abs/2512.08411)|null|\n", "2512.08405": "|**2025-12-09**|**Learning Robot Manipulation from Audio World Models**|Fan Zhang,...Michael Gienger|[2512.08405](http://arxiv.org/abs/2512.08405)|null|\n", "2512.08271": "|**2025-12-09**|**Zero-Splat TeleAssist: A Zero-Shot Pose Estimation Framework for Semantic Teleoperation**|Srijan Dokania,...Dharini Raghavan|[2512.08271](http://arxiv.org/abs/2512.08271)|null|\n", "2512.08230": "|**2025-12-09**|**Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions**|Eunice Yiu,...Alison Gopnik|[2512.08230](http://arxiv.org/abs/2512.08230)|null|\n", "2512.08188": "|**2025-12-09**|**Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model**|Wenjiang Xu,...Rui Chen|[2512.08188](http://arxiv.org/abs/2512.08188)|**[link](https://embodied-tree-of-thoughts.github.io)**|\n", "2512.08029": "|**2025-12-08**|**CLARITY: Medical World Model for Guiding Treatment Decisions by Modeling Context-Aware Disease Trajectories in Latent Space**|Tianxingjian Ding,...Yu Tian|[2512.08029](http://arxiv.org/abs/2512.08029)|null|\n", "2512.08991": "|**2025-12-08**|**Deterministic World Models for Verification of Closed-loop Vision-based Systems**|Yuang Geng,...Ivan Ruchkin|[2512.08991](http://arxiv.org/abs/2512.08991)|null|\n", "2512.11797": "|**2025-12-12**|**AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis**|Junjie Ye,...Vitor Guizilini|[2512.11797](http://arxiv.org/abs/2512.11797)|**[link](https://jay-ye.github.io/AnchorDream/)**|\n", "2512.11226": "|**2025-12-12**|**FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model**|Hongbin Lin,...Zhen Li|[2512.11226](http://arxiv.org/abs/2512.11226)|null|\n", "2512.11225": "|**2025-12-12**|**VFMF: World Modeling by Forecasting Vision Foundation Model Features**|Gabrijel Boduljak,...Andrea Vedaldi|[2512.11225](http://arxiv.org/abs/2512.11225)|null|\n", "2512.11061": "|**2025-12-11**|**VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation**|Felix O'Mahony,...Ayush Tewari|[2512.11061](http://arxiv.org/abs/2512.11061)|**[link](https://felixomahony.github.io/vdaworld/)**|\n", "2512.15621": "|**2025-12-17**|**OccSTeP: Benchmarking 4D Occupancy Spatio-Temporal Persistence**|Yu Zheng,...Jiaming Zhang|[2512.15621](http://arxiv.org/abs/2512.15621)|null|\n", "2512.15493": "|**2025-12-17**|**Soft Geometric Inductive Bias for Object Centric Dynamics**|Hampus Linander,...Christopher Buckley|[2512.15493](http://arxiv.org/abs/2512.15493)|null|\n", "2512.14691": "|**2025-12-17**|**MMGR: Multi-Modal Generative Reasoning**|Zefan Cai,...Junjie Hu|[2512.14691](http://arxiv.org/abs/2512.14691)|null|\n", "2512.14614": "|**2025-12-16**|**WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling**|Wenqiang Sun,...Chunchao Guo|[2512.14614](http://arxiv.org/abs/2512.14614)|**[link](https://3d-models.hunyuan.tencent.com/world/)**|\n", "2512.14014": "|**2025-12-16**|**MobileWorldBench: Towards Semantic World Modeling For Mobile Agents**|Shufan Li,...Aditya Grover|[2512.14014](http://arxiv.org/abs/2512.14014)|null|\n", "2512.13821": "|**2025-12-15**|**The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces**|Subramanyam Sahoo,...Jared Junkin|[2512.13821](http://arxiv.org/abs/2512.13821)|null|\n", "2512.13644": "|**2025-12-15**|**World Models Can Leverage Human Videos for Dexterous Manipulation**|Raktim Gautam Goswami,...Yann LeCun|[2512.13644](http://arxiv.org/abs/2512.13644)|null|\n", "2512.13604": "|**2025-12-15**|**LongVie 2: Multimodal Controllable Ultra-Long Video World Model**|Jianxiong Gao,...Ziwei Liu|[2512.13604](http://arxiv.org/abs/2512.13604)|**[link](https://vchitect.github.io/LongVie2-project/)**|\n", "2512.13517": "|**2025-12-15**|**A Deep Learning Model of Mental Rotation Informed by Interactive VR Experiments**|Raymond Khazoum,...Stephane Deny|[2512.13517](http://arxiv.org/abs/2512.13517)|null|\n", "2512.13030": "|**2025-12-15**|**Motus: A Unified Latent Action World Model**|Hongzhe Bi,...Jun Zhu|[2512.13030](http://arxiv.org/abs/2512.13030)|null|\n", "2512.13019": "|**2025-12-15**|**SneakPeek: Future-Guided Instructional Streaming Video Generation**|Cheeun Hong,...Albert Pumarola|[2512.13019](http://arxiv.org/abs/2512.13019)|null|\n", "2512.12751": "|**2025-12-14**|**GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation**|Zhenya Yang,...Hengshuang Zhao|[2512.12751](http://arxiv.org/abs/2512.12751)|**[link](https://huster-yzy.github.io/geniedrive_project_page/)**|\n", "2512.12548": "|**2025-12-14**|**World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents**|Yesid Fonseca,...Luis F. Giraldo|[2512.12548](http://arxiv.org/abs/2512.12548)|null|\n", "2512.12091": "|**2025-12-12**|**GraphPerf-RT: A Graph-Driven Performance Model for Hardware-Aware Scheduling of OpenMP Codes**|Mohammad Pivezhandi,...Ali Jannesari|[2512.12091](http://arxiv.org/abs/2512.12091)|null|\n", "2512.12080": "|**2025-12-12**|**BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models**|Ryan Po,...Gordon Wetzstein|[2512.12080](http://arxiv.org/abs/2512.12080)|**[link](https://ryanpo.com/bagger)**|\n"}, "VLM": {"2509.21301": "|**2025-09-25**|**Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive Cross-Stage Parallelization**|Yuhang Xu,...Guihai Chen|[2509.21301](http://arxiv.org/abs/2509.21301)|null|\n", "2509.21287": "|**2025-09-25**|**DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding**|Kin Ian Lo,...Mehrnoosh Sadrzadeh|[2509.21287](http://arxiv.org/abs/2509.21287)|null|\n", "2509.21262": "|**2025-09-25**|**Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication**|Evgeny Kaskov,...Alexander Nagaev|[2509.21262](http://arxiv.org/abs/2509.21262)|null|\n", "2509.21257": "|**2025-09-25**|**Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation**|Seyed Amir Kasaei,...Mohammad Hossein Rohban|[2509.21257](http://arxiv.org/abs/2509.21257)|null|\n", "2509.21247": "|**2025-09-25**|**Learning to Look: Cognitive Attention Alignment with Vision-Language Models**|Ryan L. Yang,...Nidhi Rastogi|[2509.21247](http://arxiv.org/abs/2509.21247)|null|\n", "2509.21205": "|**2025-09-25**|**TABLET: A Large-Scale Dataset for Robust Visual Table Understanding**|I\u00f1igo Alonso,...Mirella Lapata|[2509.21205](http://arxiv.org/abs/2509.21205)|null|\n", "2509.21189": "|**2025-09-25**|**Human-like Navigation in a World Built for Humans**|Bhargav Chandaka,...Shenlong Wang|[2509.21189](http://arxiv.org/abs/2509.21189)|**[link](https://reasonnav.github.io/)**|\n", "2509.21173": "|**2025-09-25**|**Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy**|Aymen Bouguerra,...Chokri Mraidha|[2509.21173](http://arxiv.org/abs/2509.21173)|null|\n", "2509.21126": "|**2025-09-25**|**Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning**|Xiefeng Wu,...Mingyu Hu|[2509.21126](http://arxiv.org/abs/2509.21126)|null|\n", "2509.21107": "|**2025-09-25**|**Cross-Modal Instructions for Robot Motion Generation**|William Barron,...Weiming Zhi|[2509.21107](http://arxiv.org/abs/2509.21107)|null|\n", "2509.21102": "|**2025-09-25**|**Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models**|Suaiba Amina Salahuddin,...Robert Jenssen|[2509.21102](http://arxiv.org/abs/2509.21102)|null|\n", "2509.21079": "|**2025-09-25**|**SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials**|Qixin Wan,...Lu Cheng|[2509.21079](http://arxiv.org/abs/2509.21079)|null|\n", "2509.20961": "|**2025-09-25**|**Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos**|Sarmistha Das,...Alka Maurya|[2509.20961](http://arxiv.org/abs/2509.20961)|null|\n", "2509.20941": "|**2025-09-25**|**Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery**|Angelo Henriques,...M. Ali Nasseri|[2509.20941](http://arxiv.org/abs/2509.20941)|null|\n", "2509.20843": "|**2025-09-25**|**MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases**|Ziang Luo,...Diange Yang|[2509.20843](http://arxiv.org/abs/2509.20843)|null|\n", "2509.20792": "|**2025-09-25**|**DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation**|Ved Umrajkar,...Ved Umrajkar|[2509.20792](http://arxiv.org/abs/2509.20792)|null|\n", "2509.20769": "|**2025-09-25**|**Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems**|Tuo Zhang,...Ruiliang Liu|[2509.20769](http://arxiv.org/abs/2509.20769)|null|\n", "2509.20751": "|**2025-09-25**|**Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models**|Zoe Wanying He,...Meenakshi Khosla|[2509.20751](http://arxiv.org/abs/2509.20751)|null|\n", "2509.20628": "|**2025-09-25**|**Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery**|Yiming Xiao,...Ali Mostafavi|[2509.20628](http://arxiv.org/abs/2509.20628)|null|\n", "2509.20524": "|**2025-09-24**|**InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On**|Julien Han,...Karim Bouyarmane|[2509.20524](http://arxiv.org/abs/2509.20524)|null|\n", "2509.22653": "|**2025-09-26**|**See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation**|Chih Yao Hu,...Yu-Lun Liu|[2509.22653](http://arxiv.org/abs/2509.22653)|**[link](https://spf-web.pages.dev)**|\n", "2509.22647": "|**2025-09-26**|**CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning**|Long Xing,...Dahua Lin|[2509.22647](http://arxiv.org/abs/2509.22647)|**[link](https://github.com/InternLM/CapRL)**|\n", "2509.22645": "|**2025-09-26**|**Hierarchical Representation Matching for CLIP-based Class-Incremental Learning**|Zhen-Hao Wen,...Da-Wei Zhou|[2509.22645](http://arxiv.org/abs/2509.22645)|null|\n", "2509.22642": "|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Xiaowei Chi,...Jian Tang|[2509.22642](http://arxiv.org/abs/2509.22642)|null|\n", "2509.22624": "|**2025-09-26**|**SPARK: Synergistic Policy And Reward Co-Evolving Framework**|Ziyu Liu,...Jiaqi Wang|[2509.22624](http://arxiv.org/abs/2509.22624)|**[link](https://github.com/InternLM/Spark)**|\n", "2509.22524": "|**2025-09-26**|**Color Names in Vision-Language Models**|Alexandra Gomez-Villa,...Javier Vazquez-Corral|[2509.22524](http://arxiv.org/abs/2509.22524)|null|\n", "2509.22447": "|**2025-09-26**|**Guiding Evolution of Artificial Life Using Vision-Language Models**|Nikhil Baid,...Frederico Wieser|[2509.22447](http://arxiv.org/abs/2509.22447)|null|\n", "2509.22437": "|**2025-09-26**|**Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding**|Ziheng Chi,...Mrinmaya Sachan|[2509.22437](http://arxiv.org/abs/2509.22437)|**[link](https://github.com/CHIzhP/Chimera))**|\n", "2509.22404": "|**2025-09-26**|**RAU: Reference-based Anatomical Understanding with Vision Language Models**|Yiwei Li,...Shanhui Sun|[2509.22404](http://arxiv.org/abs/2509.22404)|null|\n", "2509.22378": "|**2025-09-26**|**Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach**|Zijian Zhao,...Zijing Zhou|[2509.22378](http://arxiv.org/abs/2509.22378)|null|\n", "2509.22283": "|**2025-09-26**|**Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models**|Michael Jungo,...Andreas Fischer|[2509.22283](http://arxiv.org/abs/2509.22283)|**[link](https://github.com/jungomi/vision-finetune)**|\n", "2509.22258": "|**2025-09-26**|**Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks**|Miao Jing,...Shangyang Li|[2509.22258](http://arxiv.org/abs/2509.22258)|null|\n", "2509.22229": "|**2025-09-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu,...Cheng Deng|[2509.22229](http://arxiv.org/abs/2509.22229)|null|\n", "2509.22225": "|**2025-09-26**|**Polysemous Language Gaussian Splatting via Matching-based Mask Lifting**|Jiayu Ding,...Ge Li|[2509.22225](http://arxiv.org/abs/2509.22225)|null|\n", "2509.22221": "|**2025-09-26**|**Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models**|Jiaqi Liu,...Bo Yang|[2509.22221](http://arxiv.org/abs/2509.22221)|null|\n", "2509.22195": "|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Asher J. Hancock,...Anirudha Majumdar|[2509.22195](http://arxiv.org/abs/2509.22195)|null|\n", "2509.22186": "|**2025-09-26**|**MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing**|Junbo Niu,...Conghui He|[2509.22186](http://arxiv.org/abs/2509.22186)|**[link](https://github.com/opendatalab/MinerU)**|\n", "2509.22123": "|**2025-09-26**|**Multilingual Vision-Language Models, A Survey**|Andrei-Alexandru Manea,...Jind\u0159ich Libovick\u00fd|[2509.22123](http://arxiv.org/abs/2509.22123)|null|\n", "2509.22014": "|**2025-09-26**|**Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics**|Saurav Jha,...Stefan K. Ehrlich|[2509.22014](http://arxiv.org/abs/2509.22014)|null|\n", "2509.22010": "|**2025-09-26**|**CoFFT: Chain of Foresight-Focus Thought for Visual Language Models**|Xinyu Zhang,...Mike Zheng Shou|[2509.22010](http://arxiv.org/abs/2509.22010)|null|\n", "2509.25143": "|**2025-09-29**|**TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models**|Junyi Zhang,...Nanyun Peng|[2509.25143](http://arxiv.org/abs/2509.25143)|null|\n", "2509.25142": "|**2025-09-29**|**Visual serial processing deficits explain divergences in human and VLM reasoning**|Nicholas Budny,...Thomas L. Griffiths|[2509.25142](http://arxiv.org/abs/2509.25142)|null|\n", "2509.25026": "|**2025-09-29**|**GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning**|Mustansar Fiaz,...Salman Khan|[2509.25026](http://arxiv.org/abs/2509.25026)|**[link](https://mustansarfiaz.github.io/GeoVLM-R1/)**|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24917": "|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Markus Peschl,...Daniel Dijkman|[2509.24917](http://arxiv.org/abs/2509.24917)|null|\n", "2509.24837": "|**2025-09-29**|**Training-Free Token Pruning via Zeroth-Order Gradient Estimation in Vision-Language Models**|Youngeun Kim,...Sungeun Hong|[2509.24837](http://arxiv.org/abs/2509.24837)|null|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Eric Hannus,...Ville Kyrki|[2509.24768](http://arxiv.org/abs/2509.24768)|null|\n", "2509.24709": "|**2025-09-29**|**IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?**|Yang Chen,...Botian Shi|[2509.24709](http://arxiv.org/abs/2509.24709)|null|\n", "2509.24640": "|**2025-09-29**|**Can you SPLICE it together? A Human Curated Benchmark for Probing Visual Reasoning in VLMs**|Mohamad Ballout,...Elia Bruni|[2509.24640](http://arxiv.org/abs/2509.24640)|null|\n", "2509.24597": "|**2025-09-30**|**Inducing Dyslexia in Vision Language Models**|Melika Honarmand,...Martin Schrimpf|[2509.24597](http://arxiv.org/abs/2509.24597)|null|\n", "2509.24566": "|**2025-09-29**|**TokenSwap: Backdoor Attack on the Compositional Understanding of Large Vision-Language Models**|Zhifang Zhang,...Joey Tianyi Zhou|[2509.24566](http://arxiv.org/abs/2509.24566)|null|\n", "2509.24528": "|**2025-09-29**|**CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D**|Mohamad Amin Mirzaei,...Matin Mirzababaei|[2509.24528](http://arxiv.org/abs/2509.24528)|null|\n", "2509.24524": "|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Zhihao Wang,...Xianyuan Zhan|[2509.24524](http://arxiv.org/abs/2509.24524)|null|\n", "2509.24494": "|**2025-09-29**|**GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training**|Hongcheng Wang,...Hao Dong|[2509.24494](http://arxiv.org/abs/2509.24494)|null|\n", "2509.24473": "|**2025-09-29**|**Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks**|Shijie Lian,...Kai Chen|[2509.24473](http://arxiv.org/abs/2509.24473)|null|\n", "2509.24378": "|**2025-09-29**|**AXIS: Explainable Time Series Anomaly Detection with Large Language Models**|Tian Lan,...Chen Zhang|[2509.24378](http://arxiv.org/abs/2509.24378)|null|\n", "2509.24321": "|**2025-09-29**|**SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm**|Yao Wang,...Jiankun Wang|[2509.24321](http://arxiv.org/abs/2509.24321)|null|\n", "2509.24304": "|**2025-09-30**|**FrameThinker: Learning to Think with Long Videos via Multi-Turn Frame Spotlighting**|Zefeng He,...Yu Cheng|[2509.24304](http://arxiv.org/abs/2509.24304)|null|\n", "2509.24219": "|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Tomoyuki Kagaya,...Yang You|[2509.24219](http://arxiv.org/abs/2509.24219)|null|\n", "2509.24192": "|**2025-09-29**|**Talk in Pieces, See in Whole: Disentangling and Hierarchical Aggregating Representations for Language-based Object Detection**|Sojung An,...Donghyun Kim|[2509.24192](http://arxiv.org/abs/2509.24192)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.26641": "|**2025-09-30**|**Query-Kontext: An Unified Multimodal Model for Image Generation and Editing**|Yuxin Song,...Jingdong Wang|[2509.26641](http://arxiv.org/abs/2509.26641)|null|\n", "2509.26594": "|**2025-09-30**|**Clarification as Supervision: Reinforcement Learning for Vision-Language Interfaces**|John Gkountouras,...Ivan Titov|[2509.26594](http://arxiv.org/abs/2509.26594)|null|\n", "2509.26557": "|**2025-09-30**|**The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows**|Litao Yan,...Emerson Murphy-Hill|[2509.26557](http://arxiv.org/abs/2509.26557)|null|\n", "2509.26555": "|**2025-09-30**|**Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation**|Agneet Chatterjee,...Varun Jampani|[2509.26555](http://arxiv.org/abs/2509.26555)|**[link](https://stable-cinemetrics.github.io/)**|\n", "2509.26462": "|**2025-09-30**|**Zero-Shot Decentralized Federated Learning**|Alessio Masano,...Giovanni Bellitto|[2509.26462](http://arxiv.org/abs/2509.26462)|**[link](https://github.com/perceivelab/ZeroDFL)**|\n", "2509.26330": "|**2025-09-30**|**SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval**|Ren-Di Wu,...Huei-Fang Yang|[2509.26330](http://arxiv.org/abs/2509.26330)|null|\n", "2509.26278": "|**2025-09-30**|**ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation**|Edoardo Bianchi,...Antonio Liotta|[2509.26278](http://arxiv.org/abs/2509.26278)|null|\n", "2509.26235": "|**2025-09-30**|**Interpret, prune and distill Donut : towards lightweight VLMs for VQA on document**|Adnan Ben Mansour,...David Naccache|[2509.26235](http://arxiv.org/abs/2509.26235)|null|\n", "2509.26208": "|**2025-09-30**|**TSalV360: A Method and Dataset for Text-driven Saliency Detection in 360-Degrees Videos**|Ioannis Kontostathis,...Vasileios Mezaris|[2509.26208](http://arxiv.org/abs/2509.26208)|**[link](https://ieeexplore.ieee.org/)**|\n", "2509.26039": "|**2025-09-30**|**SGS: Segmentation-Guided Scoring for Global Scene Inconsistencies**|Gagandeep Singh,...Xue Li|[2509.26039](http://arxiv.org/abs/2509.26039)|null|\n", "2509.26006": "|**2025-10-01**|**AgenticIQA: An Agentic Framework for Adaptive and Interpretable Image Quality Assessment**|Hanwei Zhu,...Weisi Lin|[2509.26006](http://arxiv.org/abs/2509.26006)|null|\n", "2509.26004": "|**2025-09-30**|**Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations**|Nicola Messina,...Antonino Furnari|[2509.26004](http://arxiv.org/abs/2509.26004)|null|\n", "2509.25991": "|**2025-09-30**|**Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline**|Haiyang Li,...Zhun Zhong|[2509.25991](http://arxiv.org/abs/2509.25991)|null|\n", "2509.25944": "|**2025-09-30**|**NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving**|Yuan Gao,...Johannes Betz|[2509.25944](http://arxiv.org/abs/2509.25944)|null|\n", "2509.25916": "|**2025-09-30**|**VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs**|Peng Liu,...Tiancheng Zhao|[2509.25916](http://arxiv.org/abs/2509.25916)|null|\n", "2509.25896": "|**2025-10-01**|**LLaVAShield: Safeguarding Multimodal Multi-Turn Dialogues in Vision-Language Models**|Guolei Huang,...Yongjun Shen|[2509.25896](http://arxiv.org/abs/2509.25896)|null|\n", "2509.25866": "|**2025-09-30**|**DeepSketcher: Internalizing Visual Manipulation for Multimodal Reasoning**|Chi Zhang,...Jing Zhang|[2509.25866](http://arxiv.org/abs/2509.25866)|null|\n", "2509.25863": "|**2025-09-30**|**MAPLE: Multi-scale Attribute-enhanced Prompt Learning for Few-shot Whole Slide Image Classification**|Junjie Zhou,...Daoqiang Zhang|[2509.25863](http://arxiv.org/abs/2509.25863)|null|\n", "2509.25852": "|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Zitong Bo,...Hao Chen|[2509.25852](http://arxiv.org/abs/2509.25852)|null|\n", "2510.02292": "|**2025-10-02**|**From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens**|Hala Sheta,...Freda Shi|[2510.02292](http://arxiv.org/abs/2510.02292)|**[link](https://github.com/compling-wat/vlm-lens)**|\n", "2510.02270": "|**2025-10-02**|**microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification**|Sathira Silva,...Muhammad Haris Khan|[2510.02270](http://arxiv.org/abs/2510.02270)|null|\n", "2510.02204": "|**2025-10-02**|**Say One Thing, Do Another? Diagnosing Reasoning-Execution Gaps in VLM-Powered Mobile-Use Agents**|Lingzhong Dong,...Zhuosheng Zhang|[2510.02204](http://arxiv.org/abs/2510.02204)|null|\n", "2510.02186": "|**2025-10-02**|**GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation**|Weijia Dou,...Heng Tao Shen|[2510.02186](http://arxiv.org/abs/2510.02186)|null|\n", "2510.02155": "|**2025-10-02**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Shu Zou,...Jing Zhang|[2510.02155](http://arxiv.org/abs/2510.02155)|null|\n", "2510.01795": "|**2025-10-02**|**Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving**|Haibo Hu,...Chun Jason Xue|[2510.01795](http://arxiv.org/abs/2510.01795)|null|\n", "2510.01718": "|**2025-10-02**|**Accelerating Attention with Basis Decomposition**|Jialin Zhao,...Jialin Zhao|[2510.01718](http://arxiv.org/abs/2510.01718)|null|\n", "2510.01711": "|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim,...Jinwoo Shin|[2510.01711](http://arxiv.org/abs/2510.01711)|null|\n", "2510.01700": "|**2025-10-02**|**VaPR -- Vision-language Preference alignment for Reasoning**|Rohan Wadhawan,...Nanyun Peng|[2510.01700](http://arxiv.org/abs/2510.01700)|null|\n", "2510.01681": "|**2025-10-02**|**Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning**|Xuchen Li,...Wentao Zhang|[2510.01681](http://arxiv.org/abs/2510.01681)|null|\n", "2510.01649": "|**2025-10-02**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon,...Kutluyil Dogancay|[2510.01649](http://arxiv.org/abs/2510.01649)|null|\n", "2510.01642": "|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin,...Bihan Wen|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|\n", "2510.01582": "|**2025-10-02**|**ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models**|Krishna Teja Chitty-Venkata,...Murali Emani|[2510.01582](http://arxiv.org/abs/2510.01582)|null|\n", "2510.01494": "|**2025-10-03**|**Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed**|Isha Gupta,...Sanmi Koyejo|[2510.01494](http://arxiv.org/abs/2510.01494)|null|\n", "2510.01483": "|**2025-10-01**|**VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs**|Mohamad Al Mdfaa,...Gonzalo Ferrer|[2510.01483](http://arxiv.org/abs/2510.01483)|null|\n", "2510.01454": "|**2025-10-01**|**Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories**|Nilay Naharas,...Baharan Mirzasoleiman|[2510.01454](http://arxiv.org/abs/2510.01454)|**[link](https://bigml-cs-ucla.github.io/XMAS-project-page/)**|\n", "2510.01448": "|**2025-10-01**|**GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings**|Angel Daruna,...Rakesh Kumar|[2510.01448](http://arxiv.org/abs/2510.01448)|null|\n", "2510.01388": "|**2025-10-01**|**VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation**|Arthur Zhang,...Amirreza Shaban|[2510.01388](http://arxiv.org/abs/2510.01388)|null|\n", "2510.01185": "|**2025-10-01**|**Dirichlet-Prior Shaping: Guiding Expert Specialization in Upcycled MoEs**|Leyla Mirvakhabova,...Paul Whatmough|[2510.01185](http://arxiv.org/abs/2510.01185)|null|\n", "2510.01304": "|**2025-10-01**|**Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models**|Yu Zeng,...Feng Zhao|[2510.01304](http://arxiv.org/abs/2510.01304)|null|\n", "2510.03182": "|**2025-10-03**|**Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning**|Yilun Hao,...Yang Zhang|[2510.03182](http://arxiv.org/abs/2510.03182)|null|\n", "2510.03160": "|**2025-10-03**|**SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus**|Ming Zhao,...Caifeng Shan|[2510.03160](http://arxiv.org/abs/2510.03160)|null|\n", "2510.02922": "|**2025-10-03**|**Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights**|Daphne Tsolissou,...Konstantina Nikita|[2510.02922](http://arxiv.org/abs/2510.02922)|null|\n", "2510.02913": "|**2025-10-03**|**Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting**|Nikoo Naghavian,...Mostafa Tavassolipour|[2510.02913](http://arxiv.org/abs/2510.02913)|null|\n", "2510.02815": "|**2025-10-03**|**Med-K2N: Flexible K-to-N Modality Translation for Medical Image Synthesis**|Feng Yuan,...Xin Gao|[2510.02815](http://arxiv.org/abs/2510.02815)|null|\n", "2510.02790": "|**2025-10-03**|**MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding**|Jingyuan Deng,...Yujiu Yang|[2510.02790](http://arxiv.org/abs/2510.02790)|null|\n", "2510.02787": "|**2025-10-03**|**OTR: Synthesizing Overlay Text Dataset for Text Removal**|Jan Zdenek,...Kota Yamaguchi|[2510.02787](http://arxiv.org/abs/2510.02787)|**[link](https://doi.org/10.1145/3746027.3758297)**|\n", "2510.02780": "|**2025-10-03**|**Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models**|Prahitha Movva,...Prahitha Movva|[2510.02780](http://arxiv.org/abs/2510.02780)|null|\n", "2510.02778": "|**2025-10-03**|**AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding**|Xian Zhang,...Mohammed Bennamoun|[2510.02778](http://arxiv.org/abs/2510.02778)|null|\n", "2510.02750": "|**2025-10-03**|**Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models**|Lihua Zhou,...Zhen Lei|[2510.02750](http://arxiv.org/abs/2510.02750)|null|\n", "2510.02728": "|**2025-10-03**|**Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4**|Lingfeng Zhang,...Xiaoshuai Hao|[2510.02728](http://arxiv.org/abs/2510.02728)|null|\n", "2510.02677": "|**2025-10-03**|**ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks**|Zhaorun Chen,...Bo Li|[2510.02677](http://arxiv.org/abs/2510.02677)|null|\n", "2510.02543": "|**2025-10-02**|**Exploring OCR-augmented Generation for Bilingual VQA**|JoonHo Lee,...Sunho Park|[2510.02543](http://arxiv.org/abs/2510.02543)|null|\n", "2510.02528": "|**2025-10-02**|**Multimodal Function Vectors for Spatial Relations**|Shuhao Fu,...Hongjing Lu|[2510.02528](http://arxiv.org/abs/2510.02528)|null|\n", "2510.05038": "|**2025-10-06**|**Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization**|Omri Uzan,...Ariel Gera|[2510.05038](http://arxiv.org/abs/2510.05038)|null|\n", "2510.04991": "|**2025-10-06**|**Efficient Navigation in Unknown Indoor Environments with Vision-Language Models**|D. Schwartz,...J. P. How|[2510.04991](http://arxiv.org/abs/2510.04991)|null|\n", "2510.04710": "|**2025-10-06**|**ViTs: Teaching Machines to See Time Series Anomalies Like Human Experts**|Zexin Wang,...Dan Pei|[2510.04710](http://arxiv.org/abs/2510.04710)|null|\n", "2510.04564": "|**2025-10-06**|**Conditional Representation Learning for Customized Tasks**|Honglin Liu,...Xi Peng|[2510.04564](http://arxiv.org/abs/2510.04564)|null|\n", "2510.04532": "|**2025-10-06**|**More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models**|Xurui Song,...Jun Luo|[2510.04532](http://arxiv.org/abs/2510.04532)|null|\n", "2510.04479": "|**2025-10-06**|**VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery**|Nonghai Zhang,...Hao Tang|[2510.04479](http://arxiv.org/abs/2510.04479)|null|\n", "2510.04477": "|**2025-10-06**|**MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models**|Soo Yong Kim,...Gyeongyeon Hwang|[2510.04477](http://arxiv.org/abs/2510.04477)|null|\n", "2510.04428": "|**2025-10-06**|**A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering**|Yuanhao Zou,...Chen Chen|[2510.04428](http://arxiv.org/abs/2510.04428)|null|\n", "2510.04401": "|**2025-10-06**|**Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting**|Xuyang Guo,...Jiahao Zhang|[2510.04401](http://arxiv.org/abs/2510.04401)|null|\n", "2510.04257": "|**2025-10-05**|**AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents**|Yanjie Li,...Bin Xiao|[2510.04257](http://arxiv.org/abs/2510.04257)|null|\n", "2510.04246": "|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Huiwon Jang,...Jinwoo Shin|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|\n", "2510.04225": "|**2025-10-05**|**Zoom-In to Sort AI-Generated Images Out**|Yikun Ji,...Jianfu Zhang|[2510.04225](http://arxiv.org/abs/2510.04225)|null|\n", "2510.04145": "|**2025-10-05**|**Automating construction safety inspections using a multi-modal vision-language RAG framework**|Chenxin Wang,...Daniel Dias-da-Costa|[2510.04145](http://arxiv.org/abs/2510.04145)|null|\n", "2510.04002": "|**2025-10-07**|**AgriGPT-VL: Agricultural Vision-Language Understanding Suite**|Bo Yang,...Shijian Li|[2510.04002](http://arxiv.org/abs/2510.04002)|null|\n", "2510.03978": "|**2025-10-04**|**No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models**|Min Woo Sun,...Serena Yeung-Levy|[2510.03978](http://arxiv.org/abs/2510.03978)|null|\n", "2510.03903": "|**2025-10-04**|**Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models**|Md. Atabuzzaman,...Chris Thomas|[2510.03903](http://arxiv.org/abs/2510.03903)|null|\n", "2510.03896": "|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Mingyu Liu,...Chunhua Shen|[2510.03896](http://arxiv.org/abs/2510.03896)|null|\n", "2510.03840": "|**2025-10-04**|**Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models**|Pranav Sharma,...Durga Toshniwal|[2510.03840](http://arxiv.org/abs/2510.03840)|null|\n", "2510.03721": "|**2025-10-04**|**Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models**|Leander Girrbach,...Zeynep Akata|[2510.03721](http://arxiv.org/abs/2510.03721)|null|\n", "2510.03666": "|**2025-10-04**|**MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations**|Jiang Wu,...Jingliang Duan|[2510.03666](http://arxiv.org/abs/2510.03666)|null|\n", "2510.06067": "|**2025-10-07**|**Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA**|Python Song,...Junfeng Yang|[2510.06067](http://arxiv.org/abs/2510.06067)|null|\n", "2510.06064": "|**2025-10-07**|**Medical Vision Language Models as Policies for Robotic Surgery**|Akshay Muppidi,...Martin Radfar|[2510.06064](http://arxiv.org/abs/2510.06064)|null|\n", "2510.05722": "|**2025-10-07**|**Data Factory with Minimal Human Effort Using VLMs**|Jiaojiao Ye,...Andrew Markham|[2510.05722](http://arxiv.org/abs/2510.05722)|null|\n", "2510.05544": "|**2025-10-07**|**Activation-Informed Pareto-Guided Low-Rank Compression for Efficient LLM/VLM**|Ryan Solgi,...Zheng Zhang|[2510.05544](http://arxiv.org/abs/2510.05544)|null|\n", "2510.07181": "|**2025-10-09**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Yi Han,...Shanghang Zhang|[2510.07181](http://arxiv.org/abs/2510.07181)|null|\n", "2510.07135": "|**2025-10-08**|**Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models**|Karim El Khoury,...Benoit Macq|[2510.07135](http://arxiv.org/abs/2510.07135)|null|\n", "2510.07098": "|**2025-10-08**|**TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription**|Guo Yutong,...Haoyu Wang|[2510.07098](http://arxiv.org/abs/2510.07098)|null|\n", "2510.07077": "|**2025-10-08**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Kento Kawaharazuka,...Yuke Zhu|[2510.07077](http://arxiv.org/abs/2510.07077)|**[link](https://vla-survey.github.io)**|\n", "2510.07035": "|**2025-10-08**|**Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration**|Tengwei Song,...Yuan Fang|[2510.07035](http://arxiv.org/abs/2510.07035)|null|\n", "2510.06790": "|**2025-10-08**|**Get RICH or Die Scaling: Profitably Trading Inference Compute for Robustness**|Tavish McDonald,...Brian Bartoldson|[2510.06790](http://arxiv.org/abs/2510.06790)|null|\n", "2510.06783": "|**2025-10-08**|**TTRV: Test-Time Reinforcement Learning for Vision Language Models**|Akshit Singh,...M. Jehanzeb Mirza|[2510.06783](http://arxiv.org/abs/2510.06783)|null|\n", "2510.06664": "|**2025-10-08**|**ToolMem: Enhancing Multimodal Agents with Learnable Tool Capability Memory**|Yunzhong Xiao,...Zora Zhiruo Wang|[2510.06664](http://arxiv.org/abs/2510.06664)|null|\n", "2510.06529": "|**2025-10-08**|**VUGEN: Visual Understanding priors for GENeration**|Xiangyi Chen,...Jakob Verbeek|[2510.06529](http://arxiv.org/abs/2510.06529)|null|\n", "2510.06292": "|**2025-10-07**|**ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations**|Yike Wu,...Yujun Cai|[2510.06292](http://arxiv.org/abs/2510.06292)|null|\n", "2510.06280": "|**2025-10-06**|**Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals**|Zohaib Hasan Siddiqui,...Beenish Moalla Chaudhry|[2510.06280](http://arxiv.org/abs/2510.06280)|null|\n", "2510.08567": "|**2025-10-09**|**MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning**|Tajamul Ashraf,...Salman Khan|[2510.08567](http://arxiv.org/abs/2510.08567)|null|\n", "2510.08531": "|**2025-10-09**|**SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models**|Hongxing Li,...Yueting Zhuang|[2510.08531](http://arxiv.org/abs/2510.08531)|**[link](https://zju-real.github.io/SpatialLadder/)**|\n", "2510.08510": "|**2025-10-09**|**To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models**|Jiayun Luo,...Leonid Sigal|[2510.08510](http://arxiv.org/abs/2510.08510)|**[link](https://davidhalladay.github.io/diysink_demo)**|\n", "2510.08508": "|**2025-10-09**|**MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration**|Lu Liu,...Guangtao Zhai|[2510.08508](http://arxiv.org/abs/2510.08508)|null|\n", "2510.08482": "|**2025-10-09**|**The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping**|Onur Kele\u015f,...Esam Ghaleb|[2510.08482](http://arxiv.org/abs/2510.08482)|null|\n", "2510.08470": "|**2025-10-09**|**Looking to Learn: Token-wise Dynamic Gating for Low-Resource Vision-Language Modelling**|Bianca-Mihaela Ganescu,...Paula Buttery|[2510.08470](http://arxiv.org/abs/2510.08470)|null|\n", "2510.08398": "|**2025-10-09**|**VideoVerse: How Far is Your T2V Generator from a World Model?**|Zeqing Wang,...Lei Zhang|[2510.08398](http://arxiv.org/abs/2510.08398)|null|\n", "2510.08352": "|**2025-10-09**|**Evaluating Small Vision-Language Models on Distance-Dependent Traffic Perception**|Nikos Theodoridis,...Ciaran Eising|[2510.08352](http://arxiv.org/abs/2510.08352)|null|\n", "2510.08238": "|**2025-10-09**|**Chain-of-Trigger: An Agentic Backdoor that Paradoxically Enhances Agentic Robustness**|Jiyang Qiu,...Hai Zhao|[2510.08238](http://arxiv.org/abs/2510.08238)|null|\n", "2510.08132": "|**2025-10-09**|**Approximate Domain Unlearning for Vision-Language Models**|Kodai Kawamura,...Go Irie|[2510.08132](http://arxiv.org/abs/2510.08132)|null|\n", "2510.08003": "|**2025-10-09**|**CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning**|Weihuang Lin,...Rongrong Ji|[2510.08003](http://arxiv.org/abs/2510.08003)|null|\n", "2510.07975": "|**2025-10-09**|**Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation**|Mingyang Sun,...Jianhua Sun|[2510.07975](http://arxiv.org/abs/2510.07975)|null|\n", "2510.07809": "|**2025-10-09**|**Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents**|Renhua Ding,...Jun Zhu|[2510.07809](http://arxiv.org/abs/2510.07809)|null|\n", "2510.07791": "|**2025-10-09**|**GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models**|Qinghongbing Xie,...Long Zeng|[2510.07791](http://arxiv.org/abs/2510.07791)|null|\n", "2510.07778": "|**2025-10-09**|**IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction**|Yandu Chen,...Liqiang Nie|[2510.07778](http://arxiv.org/abs/2510.07778)|null|\n", "2510.07709": "|**2025-10-09**|**Multimodal Safety Evaluation in Generative Agent Social Simulations**|Alhim Vera,...Bernard Ghanem|[2510.07709](http://arxiv.org/abs/2510.07709)|null|\n", "2510.07632": "|**2025-10-09**|**Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models**|Yinglun Zhu,...Fuzhi Tang|[2510.07632](http://arxiv.org/abs/2510.07632)|null|\n", "2510.07567": "|**2025-10-08**|**Cross-Modal Attention Guided Unlearning in Vision-Language Models**|Karuna Bhaila,...Xintao Wu|[2510.07567](http://arxiv.org/abs/2510.07567)|null|\n", "2510.07545": "|**2025-10-08**|**Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices**|Md Tahmid Rahman Laskar,...Jimmy Huang|[2510.07545](http://arxiv.org/abs/2510.07545)|null|\n", "2510.09608": "|**2025-10-10**|**StreamingVLM: Real-Time Understanding for Infinite Video Streams**|Ruyi Xu,...Song Han|[2510.09608](http://arxiv.org/abs/2510.09608)|null|\n", "2510.09607": "|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Shaoqi Dong,...Caifeng Shan|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|\n", "2510.09586": "|**2025-10-10**|**Vision Language Models: A Survey of 26K Papers**|Fengming Lin,...Fengming Lin|[2510.09586](http://arxiv.org/abs/2510.09586)|null|\n", "2510.09473": "|**2025-10-10**|**D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models**|Jisu Han,...Wonjun Hwang|[2510.09473](http://arxiv.org/abs/2510.09473)|null|\n", "2510.09358": "|**2025-10-10**|**Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models**|Qihang Ma,...Jiao Ran|[2510.09358](http://arxiv.org/abs/2510.09358)|**[link](https://github.com/bytedance/DynamicCoT)**|\n", "2510.09285": "|**2025-10-10**|**Spotlight on Token Perception for Multimodal Reinforcement Learning**|Siyuan Huang,...Yu Cheng|[2510.09285](http://arxiv.org/abs/2510.09285)|**[link](https://github.com/huaixuheqing/VPPO-RL)**|\n", "2510.09256": "|**2025-10-10**|**Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy**|Patrick Wienholt,...Daniel Truhn|[2510.09256](http://arxiv.org/abs/2510.09256)|**[link](https://github.com/TruhnLab/VisionSemanticEntropy)**|\n", "2510.09253": "|**2025-10-10**|**Zero-shot image privacy classification with Vision-Language Models**|Alina Elena Baia,...Andrea Cavallaro|[2510.09253](http://arxiv.org/abs/2510.09253)|null|\n", "2510.09228": "|**2025-10-10**|**Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation**|Vijay M. Galshetwar,...Subrahmanyam Murala|[2510.09228](http://arxiv.org/abs/2510.09228)|null|\n", "2510.09078": "|**2025-10-10**|**MCMC: Bridging Rendering, Optimization and Generative AI**|Gurprit Singh,...Wenzel Jakob|[2510.09078](http://arxiv.org/abs/2510.09078)|null|\n", "2510.09008": "|**2025-10-10**|**On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models**|Hoigi Seo,...Se Young Chun|[2510.09008](http://arxiv.org/abs/2510.09008)|null|\n", "2510.08964": "|**2025-10-10**|**Unleashing Perception-Time Scaling to Multimodal Reasoning Models**|Yifan Li,...Minghui Qiu|[2510.08964](http://arxiv.org/abs/2510.08964)|null|\n", "2510.08919": "|**2025-10-10**|**PHyCLIP: $\\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning**|Daiki Yoshikawa,...Takashi Matsubara|[2510.08919](http://arxiv.org/abs/2510.08919)|null|\n", "2510.08851": "|**2025-10-09**|**CDE: Concept-Driven Exploration for Reinforcement Learning**|Le Mao,...Joseph Campbell|[2510.08851](http://arxiv.org/abs/2510.08851)|null|\n", "2510.08849": "|**2025-10-09**|**FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation**|Hongrui Wu,...Zhihua Wei|[2510.08849](http://arxiv.org/abs/2510.08849)|null|\n", "2510.08818": "|**2025-10-09**|**D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition**|Yiyang Huang,...Yun Fu|[2510.08818](http://arxiv.org/abs/2510.08818)|null|\n", "2510.08789": "|**2025-10-09**|**Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization**|Shuo Xing,...Zhengzhong Tu|[2510.08789](http://arxiv.org/abs/2510.08789)|null|\n", "2510.11718": "|**2025-10-13**|**CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images**|Chengqi Duan,...Xihui Liu|[2510.11718](http://arxiv.org/abs/2510.11718)|null|\n", "2510.11689": "|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Maggie Wang,...Mac Schwager|[2510.11689](http://arxiv.org/abs/2510.11689)|null|\n", "2510.11631": "|**2025-10-13**|**EvoCAD: Evolutionary CAD Code Generation with Vision Language Models**|Tobias Preintner,...Niki van Stein|[2510.11631](http://arxiv.org/abs/2510.11631)|null|\n", "2510.11520": "|**2025-10-13**|**mmWalk: Towards Multi-modal Multi-view Walking Assistance**|Kedi Ying,...Rainer Stiefelhagen|[2510.11520](http://arxiv.org/abs/2510.11520)|**[link](https://github.com/KediYing/mmWalk)**|\n", "2510.11456": "|**2025-10-13**|**Coupled Degradation Modeling and Fusion: A VLM-Guided Degradation-Coupled Network for Degradation-Aware Infrared and Visible Image Fusion**|Tianpei Zhang,...Guangmang Cui|[2510.11456](http://arxiv.org/abs/2510.11456)|null|\n", "2510.11314": "|**2025-10-13**|**Template-Based Text-to-Image Alignment for Language Accessibility: A Study on Visualizing Text Simplifications**|Belkiss Souayed,...Yingqiang Gao|[2510.11314](http://arxiv.org/abs/2510.11314)|null|\n", "2510.11302": "|**2025-10-13**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani,...Samer Al-Hamadani|[2510.11302](http://arxiv.org/abs/2510.11302)|null|\n", "2510.11296": "|**2025-10-13**|**$\u0394\\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization**|Lin Zhu,...Nanyang Ye|[2510.11296](http://arxiv.org/abs/2510.11296)|null|\n", "2510.11295": "|**2025-10-13**|**Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering**|Jian Lan,...Thomas Seidl|[2510.11295](http://arxiv.org/abs/2510.11295)|null|\n", "2510.11196": "|**2025-10-13**|**Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations**|Johannes Moll,...Keno K. Bressem|[2510.11196](http://arxiv.org/abs/2510.11196)|null|\n", "2510.11178": "|**2025-10-13**|**BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models**|Bryan Chen Zhengyu Tan,...Roy Ka-Wei Lee|[2510.11178](http://arxiv.org/abs/2510.11178)|null|\n", "2510.11027": "|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Ganlin Yang,...Zhi Hou|[2510.11027](http://arxiv.org/abs/2510.11027)|null|\n", "2510.11020": "|**2025-10-13**|**GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation**|Shasha Guo,...Jing Zhang|[2510.11020](http://arxiv.org/abs/2510.11020)|null|\n", "2510.11012": "|**2025-10-13**|**COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models**|Sanchit Sinha,...Aidong Zhang|[2510.11012](http://arxiv.org/abs/2510.11012)|null|\n", "2510.10982": "|**2025-10-13**|**Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization**|Zihan Wang,...Guangdong Bai|[2510.10982](http://arxiv.org/abs/2510.10982)|null|\n", "2510.10973": "|**2025-10-13**|**Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning**|Sanchit Sinha,...Aidong Zhang|[2510.10973](http://arxiv.org/abs/2510.10973)|null|\n", "2510.10969": "|**2025-10-13**|**IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation**|Zeteng Lin,...Jing Tang|[2510.10969](http://arxiv.org/abs/2510.10969)|null|\n", "2510.10962": "|**2025-10-13**|**MC#: Mixture Compressor for Mixture-of-Experts Large Models**|Wei Huang,...Xiaojuan Qi|[2510.10962](http://arxiv.org/abs/2510.10962)|null|\n", "2510.10921": "|**2025-10-13**|**FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model**|Chunyu Xie,...Yuhui Yin|[2510.10921](http://arxiv.org/abs/2510.10921)|null|\n", "2510.10889": "|**2025-10-13**|**Topological Alignment of Shared Vision-Language Embedding Space**|Junwon You,...Jae-Hun Jung|[2510.10889](http://arxiv.org/abs/2510.10889)|null|\n", "2510.12789": "|**2025-10-14**|**UniFusion: Vision-Language Model as Unified Encoder in Image Generation**|Kevin Li,...Ajinkya Kale|[2510.12789](http://arxiv.org/abs/2510.12789)|**[link](https://thekevinli.github.io/unifusion/)**|\n", "2510.12709": "|**2025-10-15**|**SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model**|Lin Lin,...Chao Feng|[2510.12709](http://arxiv.org/abs/2510.12709)|null|\n", "2510.12693": "|**2025-10-14**|**ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning**|Hanyang Chen,...Tong Zhang|[2510.12693](http://arxiv.org/abs/2510.12693)|null|\n", "2510.12548": "|**2025-10-14**|**VISaGE: Understanding Visual Generics and Exceptions**|Stella Frank,...Emily Allaway|[2510.12548](http://arxiv.org/abs/2510.12548)|null|\n", "2510.12444": "|**2025-10-14**|**A Review of Longitudinal Radiology Report Generation: Dataset Composition, Methods, and Performance Evaluation**|Shaoyang Zhou,...Luping Zhou|[2510.12444](http://arxiv.org/abs/2510.12444)|null|\n", "2510.12400": "|**2025-10-14**|**Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda**|Andr\u00e9 Torneiro,...Nuno F. Rodrigues|[2510.12400](http://arxiv.org/abs/2510.12400)|null|\n", "2510.12287": "|**2025-10-14**|**Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector**|Sifan Li,...Yiwei Wang|[2510.12287](http://arxiv.org/abs/2510.12287)|null|\n", "2510.12276": "|**2025-10-14**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Fuhao Li,...Haoang Li|[2510.12276](http://arxiv.org/abs/2510.12276)|null|\n", "2510.12225": "|**2025-10-14**|**HoneyBee: Data Recipes for Vision-Language Reasoners**|Hritik Bansal,...Ramakanth Pasunuru|[2510.12225](http://arxiv.org/abs/2510.12225)|null|\n", "2510.12190": "|**2025-10-14**|**Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos**|Shingo Yokoi,...Yu Yamaguchi|[2510.12190](http://arxiv.org/abs/2510.12190)|null|\n", "2510.12119": "|**2025-10-14**|**ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation**|Ziyuan Luo,...Renjie Wan|[2510.12119](http://arxiv.org/abs/2510.12119)|null|\n", "2510.12014": "|**2025-10-13**|**Embedding the Teacher: Distilling vLLM Preferences for Scalable Image Retrieval**|Eric He,...Vyas Raina|[2510.12014](http://arxiv.org/abs/2510.12014)|null|\n", "2510.11978": "|**2025-10-13**|**Learning Dynamics of VLM Finetuning**|Jusheng Zhang,...Keze Wang|[2510.11978](http://arxiv.org/abs/2510.11978)|null|\n", "2510.11852": "|**2025-10-13**|**Evaluating Open-Source Vision-Language Models for Multimodal Sarcasm Detection**|Saroj Basnet,...Marcos Zampieri|[2510.11852](http://arxiv.org/abs/2510.11852)|**[link](https://icdmw25mmai.github.io/)**|\n", "2510.11835": "|**2025-10-13**|**Data or Language Supervision: What Makes CLIP Better than DINO?**|Yiming Liu,...Serena Yeung-Levy|[2510.11835](http://arxiv.org/abs/2510.11835)|null|\n", "2510.13808": "|**2025-10-15**|**VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models**|Dominick Reilly,...Srijan Das|[2510.13808](http://arxiv.org/abs/2510.13808)|null|\n", "2510.13804": "|**2025-10-15**|**Generative Universal Verifier as Multimodal Meta-Reasoner**|Xinchen Zhang,...Yujiu Yang|[2510.13804](http://arxiv.org/abs/2510.13804)|null|\n", "2510.13394": "|**2025-10-15**|**Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models**|Xinmiao Huang,...Xiaowei Huang|[2510.13394](http://arxiv.org/abs/2510.13394)|null|\n", "2510.13375": "|**2025-10-15**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Tianyuan Yuan,...Hang Zhao|[2510.13375](http://arxiv.org/abs/2510.13375)|null|\n", "2510.13364": "|**2025-10-15**|**Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity**|MingZe Tang,...Jubal Chandy Jacob|[2510.13364](http://arxiv.org/abs/2510.13364)|null|\n", "2510.13359": "|**2025-10-15**|**Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models**|Yuki Yada,...Andre Rusli|[2510.13359](http://arxiv.org/abs/2510.13359)|null|\n", "2510.13315": "|**2025-10-15**|**Self-Augmented Visual Contrastive Decoding**|Eun Woo Im,...Vivek Gupta|[2510.13315](http://arxiv.org/abs/2510.13315)|null|\n", "2510.13276": "|**2025-10-15**|**MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models**|Keyan Zhou,...Min Zhang|[2510.13276](http://arxiv.org/abs/2510.13276)|null|\n", "2510.13251": "|**2025-10-15**|**Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs**|Minji Kim,...Bohyung Han|[2510.13251](http://arxiv.org/abs/2510.13251)|null|\n", "2510.13232": "|**2025-10-15**|**What \"Not\" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging**|Inha Kang,...Hyunjung Shim|[2510.13232](http://arxiv.org/abs/2510.13232)|null|\n", "2510.13190": "|**2025-10-15**|**SHIELD: Classifier-Guided Prompting for Robust and Safer LVLMs**|Juan Ren,...Usman Naseem|[2510.13190](http://arxiv.org/abs/2510.13190)|null|\n", "2510.13108": "|**2025-10-15**|**DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models**|Jingyu Song,...Jose M. Alvarez|[2510.13108](http://arxiv.org/abs/2510.13108)|null|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Ankit Goyal,...Fabio Ramos|[2510.13054](http://arxiv.org/abs/2510.13054)|null|\n", "2510.13016": "|**2025-10-14**|**SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding**|Tanveer Hannan,...Thomas Seidl|[2510.13016](http://arxiv.org/abs/2510.13016)|null|\n", "2510.12992": "|**2025-10-14**|**UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles**|Neel P. Bhatt,...Ufuk Topcu|[2510.12992](http://arxiv.org/abs/2510.12992)|null|\n", "2510.12974": "|**2025-10-14**|**Scope: Selective Cross-modal Orchestration of Visual Perception Experts**|Tianyu Zhang,...Perouz Taslakian|[2510.12974](http://arxiv.org/abs/2510.12974)|null|\n", "2510.12953": "|**2025-10-14**|**Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation**|Xiao He,...Bo Du|[2510.12953](http://arxiv.org/abs/2510.12953)|null|\n", "2510.12931": "|**2025-10-14**|**Unifying Vision-Language Latents for Zero-label Image Caption Enhancement**|Sanghyun Byun,...Woo Seong Chung|[2510.12931](http://arxiv.org/abs/2510.12931)|null|\n", "2510.14979": "|**2025-10-16**|**From Pixels to Words -- Towards Native Vision-Language Primitives at Scale**|Haiwen Diao,...Ziwei Liu|[2510.14979](http://arxiv.org/abs/2510.14979)|null|\n", "2510.14978": "|**2025-10-16**|**Learning an Image Editing Model without Image Editing Pairs**|Nupur Kumari,...Xun Huang|[2510.14978](http://arxiv.org/abs/2510.14978)|**[link](https://nupurkmr9.github.io/npedit/)**|\n", "2510.14968": "|**2025-10-16**|**RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks**|Mingxuan Yan,...Jiachen Li|[2510.14968](http://arxiv.org/abs/2510.14968)|null|\n", "2510.14828": "|**2025-10-16**|**RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning**|Jinrui Liu,...Haoran Li|[2510.14828](http://arxiv.org/abs/2510.14828)|null|\n", "2510.14792": "|**2025-10-16**|**CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection**|Hojun Choi,...Hyunjung Shim|[2510.14792](http://arxiv.org/abs/2510.14792)|null|\n", "2510.14737": "|**2025-10-16**|**Free-Grained Hierarchical Recognition**|Seulki Park,...Stella X. Yu|[2510.14737](http://arxiv.org/abs/2510.14737)|null|\n", "2510.14624": "|**2025-10-16**|**Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference**|Natan Bagrov,...Andrew Tao|[2510.14624](http://arxiv.org/abs/2510.14624)|null|\n", "2510.14583": "|**2025-10-16**|**Talking Points: Describing and Localizing Pixels**|Matan Rusanovsky,...Shai Avidan|[2510.14583](http://arxiv.org/abs/2510.14583)|null|\n", "2510.14543": "|**2025-10-16**|**Exploring Cross-Modal Flows for Few-Shot Learning**|Ziqi Jiang,...Long Chen|[2510.14543](http://arxiv.org/abs/2510.14543)|null|\n", "2510.14528": "|**2025-10-17**|**PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model**|Cheng Cui,...Yanjun Ma|[2510.14528](http://arxiv.org/abs/2510.14528)|**[link](https://github.com/PaddlePaddle/PaddleOCR)**|\n", "2510.14526": "|**2025-10-16**|**Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models**|Yunze Tong,...Ziyu Zhao|[2510.14526](http://arxiv.org/abs/2510.14526)|null|\n", "2510.14388": "|**2025-10-16**|**Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control**|Zhe Wu,...Yuanchun Shi|[2510.14388](http://arxiv.org/abs/2510.14388)|null|\n", "2510.14304": "|**2025-10-16**|**Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding**|Kyungryul Back,...Jinkyu Kim|[2510.14304](http://arxiv.org/abs/2510.14304)|**[link](https://github.com/KR-0822/TCD)**|\n", "2510.13993": "|**2025-10-15**|**Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models**|Jia Yun Chua,...Miguel Arana-Catania|[2510.13993](http://arxiv.org/abs/2510.13993)|null|\n", "2510.15866": "|**2025-10-17**|**BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models**|Kaushitha Silva,...Damayanthi Herath|[2510.15866](http://arxiv.org/abs/2510.15866)|null|\n", "2510.15841": "|**2025-10-17**|**Neuro-Symbolic Spatial Reasoning in Segmentation**|Jiayi Lin,...Shaogang Gong|[2510.15841](http://arxiv.org/abs/2510.15841)|null|\n", "2510.15430": "|**2025-10-17**|**Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models**|Shuang Liang,...Xiting Wang|[2510.15430](http://arxiv.org/abs/2510.15430)|null|\n", "2510.15418": "|**2025-10-17**|**Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs**|Lee Qi Zun,...Goh Man Fye|[2510.15418](http://arxiv.org/abs/2510.15418)|null|\n", "2510.15349": "|**2025-10-17**|**Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing**|Baode Wang,...Yuan Qi|[2510.15349](http://arxiv.org/abs/2510.15349)|null|\n", "2510.17800": "|**2025-10-21**|**Glyph: Scaling Context Windows via Visual-Text Compression**|Jiale Cheng,...Minlie Huang|[2510.17800](http://arxiv.org/abs/2510.17800)|null|\n", "2510.17777": "|**2025-10-20**|**SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference**|Samir Khaki,...Zhijian Liu|[2510.17777](http://arxiv.org/abs/2510.17777)|null|\n", "2510.17771": "|**2025-10-20**|**Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs**|Zhining Liu,...Hanghang Tong|[2510.17771](http://arxiv.org/abs/2510.17771)|null|\n", "2510.17759": "|**2025-10-20**|**VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models**|Qilin Liao,...Ruqi Zhang|[2510.17759](http://arxiv.org/abs/2510.17759)|null|\n", "2510.17651": "|**2025-10-20**|**Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs**|S\u00e9bastien Thuau,...Rachid Chelouah|[2510.17651](http://arxiv.org/abs/2510.17651)|null|\n", "2510.17633": "|**2025-10-20**|**SARSteer: Safeguarding Large Audio Language Models via Safe-Ablated Refusal Steering**|Weilin Lin,...Li Liu|[2510.17633](http://arxiv.org/abs/2510.17633)|null|\n", "2510.17590": "|**2025-10-20**|**MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning**|Mir Nafis Sharear Shopnil,...Adiba Mahbub Proma|[2510.17590](http://arxiv.org/abs/2510.17590)|null|\n", "2510.17354": "|**2025-10-20**|**Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation**|Chenghao Zhang,...Zhicheng Dou|[2510.17354](http://arxiv.org/abs/2510.17354)|null|\n", "2510.17313": "|**2025-10-20**|**Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations**|Tal Barami,...Omri Azencot|[2510.17313](http://arxiv.org/abs/2510.17313)|null|\n", "2510.17269": "|**2025-10-20**|**FineVision: Open Data Is All You Need**|Luis Wiedmann,...Andr\u00e9s Marafioti|[2510.17269](http://arxiv.org/abs/2510.17269)|null|\n", "2510.17197": "|**2025-10-20**|**ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models**|Pu Zhang,...Guoming Tang|[2510.17197](http://arxiv.org/abs/2510.17197)|null|\n", "2510.17191": "|**2025-10-20**|**SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving**|Peiru Zheng,...Shaohua Wu|[2510.17191](http://arxiv.org/abs/2510.17191)|null|\n", "2510.17150": "|**2025-10-20**|**OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation**|Heng Zhang,...Arash Ajoudani|[2510.17150](http://arxiv.org/abs/2510.17150)|**[link](https://sites.google.com/view/omni-vic})**|\n", "2510.17111": "|**2025-10-20**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Weifan Guan,...Jian Cheng|[2510.17111](http://arxiv.org/abs/2510.17111)|null|\n", "2510.17034": "|**2025-10-19**|**Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding**|Yutong Zhong,...Yutong Zhong|[2510.17034](http://arxiv.org/abs/2510.17034)|null|\n", "2510.16924": "|**2025-10-19**|**Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?**|Zhihui Yang,...Renfen Hu|[2510.16924](http://arxiv.org/abs/2510.16924)|null|\n", "2510.16907": "|**2025-10-19**|**VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents**|Kangrui Wang,...Manling Li|[2510.16907](http://arxiv.org/abs/2510.16907)|null|\n", "2510.16870": "|**2025-10-19**|**Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding**|Yudan Ren,...Xiaowei He|[2510.16870](http://arxiv.org/abs/2510.16870)|null|\n", "2510.16772": "|**2025-10-19**|**Region in Context: Text-condition Image editing with Human-like semantic reasoning**|Thuy Phuong Vu,...Phan Xuan Tan|[2510.16772](http://arxiv.org/abs/2510.16772)|null|\n", "2510.16769": "|**2025-10-19**|**See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models**|Shuo Han,...Xike Xie|[2510.16769](http://arxiv.org/abs/2510.16769)|null|\n", "2510.18873": "|**2025-10-21**|**DSI-Bench: A Benchmark for Dynamic Spatial Intelligence**|Ziang Zhang,...Zhou Zhao|[2510.18873](http://arxiv.org/abs/2510.18873)|null|\n", "2510.18837": "|**2025-10-21**|**FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning**|Yubin Zheng,...Jagath C. Rajapakse|[2510.18837](http://arxiv.org/abs/2510.18837)|null|\n", "2510.18751": "|**2025-10-21**|**Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation**|Patterson Hsieh,...Elvis Hsieh|[2510.18751](http://arxiv.org/abs/2510.18751)|null|\n", "2510.18703": "|**2025-10-21**|**Exploring a Unified Vision-Centric Contrastive Alternatives on Multi-Modal Web Documents**|Yiqi Lin,...Mike Zheng Shou|[2510.18703](http://arxiv.org/abs/2510.18703)|**[link](https://linyq17.github.io/VC2L/)**|\n", "2510.18632": "|**2025-10-21**|**Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views**|Zhangquan Chen,...Ruqi Huang|[2510.18632](http://arxiv.org/abs/2510.18632)|null|\n", "2510.18596": "|**2025-10-21**|**CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent**|Haojia Lin,...Xing Sun|[2510.18596](http://arxiv.org/abs/2510.18596)|null|\n", "2510.18583": "|**2025-10-21**|**CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder**|Yongmin Lee,...Hye Won Chung|[2510.18583](http://arxiv.org/abs/2510.18583)|null|\n", "2510.18502": "|**2025-10-21**|**Zero-Shot Vehicle Model Recognition via Text-Based Retrieval-Augmented Generation**|Wei-Chia Chang,...Yan-Ann Chen|[2510.18502](http://arxiv.org/abs/2510.18502)|null|\n", "2510.18483": "|**2025-10-21**|**StarBench: A Turn-Based RPG Benchmark for Agentic Multimodal Decision-Making and Information Seeking**|Haoran Zhang,...Donglin Yu|[2510.18483](http://arxiv.org/abs/2510.18483)|null|\n", "2510.18439": "|**2025-10-21**|**Grounding or Guessing? Visual Signals for Detecting Hallucinations in Sign Language Translation**|Yasser Hamidullah,...Cristina Espa\u00f1a-Bonet|[2510.18439](http://arxiv.org/abs/2510.18439)|null|\n", "2510.18433": "|**2025-10-21**|**ImageGem: In-the-wild Generative Image Interaction Dataset for Generative Model Personalization**|Yuanhe Guo,...Hongyi Wen|[2510.18433](http://arxiv.org/abs/2510.18433)|null|\n", "2510.18321": "|**2025-10-21**|**Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding**|Jinlin Li,...Xian Wu|[2510.18321](http://arxiv.org/abs/2510.18321)|null|\n", "2510.18269": "|**2025-10-21**|**StreamingTOM: Streaming Token Compression for Efficient Video Understanding**|Xueyi Chen,...Huan Wang|[2510.18269](http://arxiv.org/abs/2510.18269)|null|\n", "2510.18262": "|**2025-10-21**|**UWBench: A Comprehensive Vision-Language Benchmark for Underwater Understanding**|Da Zhang,...Xuelong Li|[2510.18262](http://arxiv.org/abs/2510.18262)|null|\n", "2510.18188": "|**2025-10-21**|**RadDiagSeg-M: A Vision Language Model for Joint Diagnosis and Multi-Target Segmentation in Radiology**|Chengrun Li,...Bjoern Menze|[2510.18188](http://arxiv.org/abs/2510.18188)|null|\n", "2510.18117": "|**2025-10-20**|**Online In-Context Distillation for Low-Resource Vision Language Models**|Zhiqi Kang,...Karteek Alahari|[2510.18117](http://arxiv.org/abs/2510.18117)|null|\n", "2510.18054": "|**2025-10-20**|**HouseTour: A Virtual Real Estate A(I)gent**|Ata \u00c7elen,...Iro Armeni|[2510.18054](http://arxiv.org/abs/2510.18054)|null|\n", "2510.18034": "|**2025-10-20**|**SAVANT: Semantic Analysis with Vision-Augmented Anomaly deTection**|Roberto Brusnicki,...Johannes Betz|[2510.18034](http://arxiv.org/abs/2510.18034)|null|\n", "2510.19818": "|**2025-10-22**|**Semantic World Models**|Jacob Berg,...Abhishek Gupta|[2510.19818](http://arxiv.org/abs/2510.19818)|null|\n", "2510.19817": "|**2025-10-22**|**olmOCR 2: Unit Test Rewards for Document OCR**|Jake Poznanski,...Kyle Lo|[2510.19817](http://arxiv.org/abs/2510.19817)|**[link](https://olmocr.allen.ai/)**|\n", "2510.19802": "|**2025-10-22**|**Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models**|Xiaozhen Qiao,...Xuelong Li|[2510.19802](http://arxiv.org/abs/2510.19802)|null|\n", "2510.19626": "|**2025-10-22**|**MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom**|Yifan Li,...Shaohua Kevin Zhou|[2510.19626](http://arxiv.org/abs/2510.19626)|**[link](https://github.com/Leevan001/MedReason-R1)**|\n", "2510.19599": "|**2025-10-22**|**XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography**|Haozhe Luo,...Mauricio Reyes|[2510.19599](http://arxiv.org/abs/2510.19599)|null|\n", "2510.19574": "|**2025-10-22**|**Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection**|Ariana Yi,...Qiben Yan|[2510.19574](http://arxiv.org/abs/2510.19574)|null|\n", "2510.19559": "|**2025-10-22**|**A Matter of Time: Revealing the Structure of Time in Vision-Language Models**|Nidham Tekaya,...Matthias Zeppelzauer|[2510.19559](http://arxiv.org/abs/2510.19559)|null|\n", "2510.19555": "|**2025-10-22**|**[De|Re]constructing VLMs' Reasoning in Counting**|Simone Alghisi,...Giuseppe Riccardi|[2510.19555](http://arxiv.org/abs/2510.19555)|null|\n", "2510.19496": "|**2025-10-22**|**CARES: Context-Aware Resolution Selector for VLMs**|Moshe Kimhi,...Eli Schwartz|[2510.19496](http://arxiv.org/abs/2510.19496)|null|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Zhiyuan Feng,...Baining Guo|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|\n", "2510.19333": "|**2025-10-22**|**A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP**|Ying Dai,...Wei Yu Chen|[2510.19333](http://arxiv.org/abs/2510.19333)|null|\n", "2510.19307": "|**2025-10-22**|**Unified Reinforcement and Imitation Learning for Vision-Language Models**|Byung-Kwan Lee,...Yueh-Hua Wu|[2510.19307](http://arxiv.org/abs/2510.19307)|**[link](https://byungkwanlee.github.io/RIL-page)**|\n", "2510.19268": "|**2025-10-22**|**Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models**|Mingen Li,...Changhyun Choi|[2510.19268](http://arxiv.org/abs/2510.19268)|null|\n", "2510.19160": "|**2025-10-22**|**Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression**|Paimon Goulart,...Evangelos E. Papalexakis|[2510.19160](http://arxiv.org/abs/2510.19160)|null|\n", "2510.19060": "|**2025-10-21**|**PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions**|Amith Ananthram,...Kathleen McKeown|[2510.19060](http://arxiv.org/abs/2510.19060)|**[link](https://github.com/amith-ananthram/posh)**|\n", "2510.19001": "|**2025-10-21**|**Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts**|Seungjun Yu,...Hyunjung Shim|[2510.19001](http://arxiv.org/abs/2510.19001)|null|\n", "2510.20812": "|**2025-10-23**|**Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation**|Yuhan Liu,...Shengjie Wang|[2510.20812](http://arxiv.org/abs/2510.20812)|null|\n", "2510.20707": "|**2025-10-23**|**Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models**|Xuyang Liu,...Linfeng Zhang|[2510.20707](http://arxiv.org/abs/2510.20707)|**[link](https://github.com/xuyang-liu16/MixKV)**|\n", "2510.20696": "|**2025-10-23**|**Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward**|Jing Bi,...Chenliang Xu|[2510.20696](http://arxiv.org/abs/2510.20696)|null|\n", "2510.20639": "|**2025-10-23**|**Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging**|Ibrahim Ethem Hamamci,...Bjoern Menze|[2510.20639](http://arxiv.org/abs/2510.20639)|null|\n", "2510.20477": "|**2025-10-23**|**Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models**|Rui Zhu,...Lan-Zhe Guo|[2510.20477](http://arxiv.org/abs/2510.20477)|null|\n", "2510.20333": "|**2025-10-23**|**GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?**|Chiyu Chen,...Yingchun Wang|[2510.20333](http://arxiv.org/abs/2510.20333)|null|\n", "2510.20287": "|**2025-10-23**|**Breakdance Video classification in the age of Generative AI**|Sauptik Dhar,...Michelle Munson|[2510.20287](http://arxiv.org/abs/2510.20287)|null|\n", "2510.20244": "|**2025-10-23**|**Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding**|Minseok Kang,...Sangyoun Lee|[2510.20244](http://arxiv.org/abs/2510.20244)|null|\n", "2510.20229": "|**2025-10-23**|**Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context**|Ge Zheng,...Sibei Yang|[2510.20229](http://arxiv.org/abs/2510.20229)|null|\n", "2510.19949": "|**2025-10-24**|**Surfer 2: The Next Generation of Cross-Platform Computer Use Agents**|Mathieu Andreux,...Jevgenij Zubovskij|[2510.19949](http://arxiv.org/abs/2510.19949)|null|\n", "2510.21679": "|**2025-10-24**|**A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection**|Gaku Morio,...Peter Henderson|[2510.21679](http://arxiv.org/abs/2510.21679)|null|\n", "2510.21606": "|**2025-10-24**|**Modest-Align: Data-Efficient Alignment for Vision-Language Models**|Jiaxiang Liu,...Zuozhu Liu|[2510.21606](http://arxiv.org/abs/2510.21606)|null|\n", "2510.21518": "|**2025-10-24**|**Head Pursuit: Probing Attention Specialization in Multimodal Transformers**|Lorenzo Basile,...Alberto Cazzaniga|[2510.21518](http://arxiv.org/abs/2510.21518)|null|\n", "2510.21449": "|**2025-10-24**|**MoniTor: Exploiting Large Language Models with Instruction for Online Video Anomaly Detection**|Shengtian Yang,...Jie Qin|[2510.21449](http://arxiv.org/abs/2510.21449)|null|\n", "2510.21424": "|**2025-10-24**|**Vision Language Models for Dynamic Human Activity Recognition in Healthcare Settings**|Abderrazek Abid,...Fakhri Karray|[2510.21424](http://arxiv.org/abs/2510.21424)|null|\n", "2510.21412": "|**2025-10-24**|**Bridging the gap to real-world language-grounded visual concept learning**|Whie Jung,...Seunghoon Hong|[2510.21412](http://arxiv.org/abs/2510.21412)|null|\n", "2510.21323": "|**2025-10-24**|**VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set**|Shufan Shen,...Shuhui Wang|[2510.21323](http://arxiv.org/abs/2510.21323)|null|\n", "2510.21175": "|**2025-10-24**|**Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models**|Yujin Jo,...Taesup Kim|[2510.21175](http://arxiv.org/abs/2510.21175)|null|\n", "2510.21121": "|**2025-10-24**|**Generalizable Hierarchical Skill Learning via Object-Centric Representation**|Haibo Zhao,...Robert Platt|[2510.21121](http://arxiv.org/abs/2510.21121)|null|\n", "2510.21120": "|**2025-10-24**|**SafetyPairs: Isolating Safety Critical Image Features with Counterfactual Image Generation**|Alec Helbling,...Joseph Yitan Cheng|[2510.21120](http://arxiv.org/abs/2510.21120)|null|\n", "2510.21093": "|**2025-10-24**|**MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning**|Siyong Chen,...Dong In Kim|[2510.21093](http://arxiv.org/abs/2510.21093)|null|\n", "2510.21083": "|**2025-10-24**|**Knowledge-Driven Vision-Language Model for Plexus Detection in Hirschsprung's Disease**|Youssef Megahed,...Adrian D. C. Chan|[2510.21083](http://arxiv.org/abs/2510.21083)|null|\n", "2510.21069": "|**2025-10-24**|**ZING-3D: Zero-shot Incremental 3D Scene Graphs via Vision-Language Models**|Pranav Saxena,...Jimmy Chiun|[2510.21069](http://arxiv.org/abs/2510.21069)|null|\n", "2510.20967": "|**2025-10-23**|**3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models**|Sraavya Sambara,...Pranav Rajpurkar|[2510.20967](http://arxiv.org/abs/2510.20967)|null|\n", "2510.23571": "|**2025-10-27**|**RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation**|Yash Jangir,...Katerina Fragkiadaki|[2510.23571](http://arxiv.org/abs/2510.23571)|**[link](https://robotarenainf.github.io)**|\n", "2510.23497": "|**2025-10-28**|**VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation**|Walid Bousselham,...Cordelia Schmid|[2510.23497](http://arxiv.org/abs/2510.23497)|null|\n", "2510.23482": "|**2025-10-27**|**On the Faithfulness of Visual Thinking: Measurement and Enhancement**|Zujing Liu,...Guisong Xia|[2510.23482](http://arxiv.org/abs/2510.23482)|null|\n", "2510.23253": "|**2025-10-27**|**A Video Is Not Worth a Thousand Words**|Sam Pollard,...Michael Wray|[2510.23253](http://arxiv.org/abs/2510.23253)|null|\n", "2510.23217": "|**2025-10-27**|**Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports**|Alois Thomas,...Curtis P. Langlotz|[2510.23217](http://arxiv.org/abs/2510.23217)|null|\n", "2510.23203": "|**2025-10-27**|**DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification**|Lukas Bierling,...Angelo Broere|[2510.23203](http://arxiv.org/abs/2510.23203)|null|\n", "2510.23190": "|**2025-10-27**|**Evaluation of Vision-LLMs in Surveillance Video**|Pascal Benschop,...Jelte P. Mense|[2510.23190](http://arxiv.org/abs/2510.23190)|null|\n", "2510.23184": "|**2025-10-27**|**Finding 3D Scene Analogies with Multimodal Foundation Models**|Junho Kim,...Young Min Kim|[2510.23184](http://arxiv.org/abs/2510.23184)|null|\n", "2510.23095": "|**2025-10-27**|**Revisiting Multimodal Positional Encoding in Vision-Language Models**|Jie Huang,...Shuai Bai|[2510.23095](http://arxiv.org/abs/2510.23095)|null|\n", "2510.23066": "|**2025-10-27**|**Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models**|Yichao Jin,...Donald MacDonald|[2510.23066](http://arxiv.org/abs/2510.23066)|null|\n", "2510.22975": "|**2025-10-27**|**VoMP: Predicting Volumetric Mechanical Property Fields**|Rishit Dagli,...Maria Shugrina|[2510.22975](http://arxiv.org/abs/2510.22975)|**[link](https://research.nvidia.com/labs/sil/projects/vomp)**|\n", "2510.22917": "|**2025-10-28**|**HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment**|Zecheng Yin,...Zhen Li|[2510.22917](http://arxiv.org/abs/2510.22917)|null|\n", "2510.22868": "|**2025-10-26**|**Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models**|Yang Zhang,...Jiong Tang|[2510.22868](http://arxiv.org/abs/2510.22868)|null|\n", "2510.22838": "|**2025-10-26**|**Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models**|Aya Nakayama,...Kaito Tanaka|[2510.22838](http://arxiv.org/abs/2510.22838)|null|\n", "2510.22798": "|**2025-10-26**|**VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions**|Thu Phuong Nguyen,...Taehwan Kim|[2510.22798](http://arxiv.org/abs/2510.22798)|**[link](https://vehme.github.io/)**|\n", "2510.22785": "|**2025-10-26**|**Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models**|Jiaxiang Liu,...Mingkun Xu|[2510.22785](http://arxiv.org/abs/2510.22785)|null|\n", "2510.22768": "|**2025-10-26**|**MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion**|Haoyi Qiu,...Chien-Sheng Wu|[2510.22768](http://arxiv.org/abs/2510.22768)|null|\n", "2510.22765": "|**2025-10-26**|**Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval**|Binxiao Xu,...Wentao Zhang|[2510.22765](http://arxiv.org/abs/2510.22765)|null|\n", "2510.22728": "|**2025-10-26**|**S-Chain: Structured Visual Chain-of-Thought For Medicine**|Khai Le-Duc,...Anh Totti Nguyen|[2510.22728](http://arxiv.org/abs/2510.22728)|null|\n", "2510.22702": "|**2025-10-26**|**Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring**|Mithul Chander,...Prathamesh Mayekar|[2510.22702](http://arxiv.org/abs/2510.22702)|null|\n", "2510.24650": "|**2025-10-28**|**Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning**|Nitin Rai,...Arnold W. Schumann|[2510.24650](http://arxiv.org/abs/2510.24650)|null|\n", "2510.24411": "|**2025-10-28**|**OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows**|Qiushi Sun,...Lingpeng Kong|[2510.24411](http://arxiv.org/abs/2510.24411)|null|\n", "2510.24331": "|**2025-10-28**|**What do vision-language models see in the context? Investigating multimodal in-context learning**|Gabriel O. dos Santos,...Sandra Avila|[2510.24331](http://arxiv.org/abs/2510.24331)|null|\n", "2510.24321": "|**2025-10-28**|**Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning**|Ivica Dimitrovski,...Ivan Kitanovski|[2510.24321](http://arxiv.org/abs/2510.24321)|null|\n", "2510.24285": "|**2025-10-28**|**ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model**|Juntian Zhang,...Rui Yan|[2510.24285](http://arxiv.org/abs/2510.24285)|null|\n", "2510.24242": "|**2025-10-28**|**Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models**|Zihan Li,...Yue Gao|[2510.24242](http://arxiv.org/abs/2510.24242)|null|\n", "2510.24180": "|**2025-10-28**|**V-SAT: Video Subtitle Annotation Tool**|Arpita Kundu,...Vishwanathan Raman|[2510.24180](http://arxiv.org/abs/2510.24180)|null|\n", "2510.24152": "|**2025-10-28**|**Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning**|Aodi Wu,...Xubo Luo|[2510.24152](http://arxiv.org/abs/2510.24152)|null|\n", "2510.24133": "|**2025-10-28**|**Compositional Image Synthesis with Inference-Time Scaling**|Minsuk Ji,...Namhyuk Ahn|[2510.24133](http://arxiv.org/abs/2510.24133)|**[link](https://github.com/gcl-inha/ReFocus)**|\n", "2510.24115": "|**2025-10-28**|**HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology**|Sandeep Vissapragada,...Vandita Singh|[2510.24115](http://arxiv.org/abs/2510.24115)|null|\n", "2510.24109": "|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Wenbin Ding,...Philip Dames|[2510.24109](http://arxiv.org/abs/2510.24109)|null|\n", "2510.24038": "|**2025-10-28**|**Enhancing CLIP Robustness via Cross-Modality Alignment**|Xingyu Zhu,...Hanwang Zhang|[2510.24038](http://arxiv.org/abs/2510.24038)|null|\n", "2510.24010": "|**2025-10-28**|**Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks**|Mirali Purohit,...Hannah Kerner|[2510.24010](http://arxiv.org/abs/2510.24010)|null|\n", "2510.23968": "|**2025-10-28**|**Reasoning Visual Language Model for Chest X-Ray Analysis**|Andriy Myronenko,...Daguang Xu|[2510.23968](http://arxiv.org/abs/2510.23968)|null|\n", "2510.23925": "|**2025-10-27**|**Latent Chain-of-Thought for Visual Reasoning**|Guohao Sun,...Zhiqiang Tao|[2510.23925](http://arxiv.org/abs/2510.23925)|null|\n", "2510.23775": "|**2025-10-27**|**Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices**|Aryan Mathur,...Madesh Kuppusamy|[2510.23775](http://arxiv.org/abs/2510.23775)|null|\n", "2510.25682": "|**2025-10-30**|**PairUni: Pairwise Training for Unified Multimodal Language Models**|Jiani Zheng,...Zhuochen Wang|[2510.25682](http://arxiv.org/abs/2510.25682)|null|\n", "2510.25668": "|**2025-10-29**|**ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents**|Tianyu Yang,...Bela Gipp|[2510.25668](http://arxiv.org/abs/2510.25668)|null|\n", "2510.25616": "|**2025-10-29**|**Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization**|Nikita Kachaev,...Aleksandr I. Panov|[2510.25616](http://arxiv.org/abs/2510.25616)|null|\n", "2510.25548": "|**2025-10-29**|**Using VLM Reasoning to Constrain Task and Motion Planning**|Muyang Yan,...Zachary Kingston|[2510.25548](http://arxiv.org/abs/2510.25548)|null|\n", "2510.25413": "|**2025-10-29**|**Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline for Sign Language Data Acquisition and Curation from Social Media**|Shakib Yazdani,...Josef van Genabith|[2510.25413](http://arxiv.org/abs/2510.25413)|null|\n", "2510.25191": "|**2025-10-29**|**SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning**|Hongyu Song,...Wei Pan|[2510.25191](http://arxiv.org/abs/2510.25191)|null|\n", "2510.25179": "|**2025-10-29**|**Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models**|Juan Ren,...Usman Naseem|[2510.25179](http://arxiv.org/abs/2510.25179)|null|\n", "2510.25138": "|**2025-10-29**|**Learning Spatial-Aware Manipulation Ordering**|Yuxiang Yan,...Jian Pu|[2510.25138](http://arxiv.org/abs/2510.25138)|null|\n", "2510.25122": "|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jiahong Chen,...Jinghui Lu|[2510.25122](http://arxiv.org/abs/2510.25122)|null|\n", "2510.25094": "|**2025-10-29**|**Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection**|Chanhyeong Yang,...Hyunwoo J. Kim|[2510.25094](http://arxiv.org/abs/2510.25094)|null|\n", "2510.25067": "|**2025-10-29**|**DRIP: Dynamic patch Reduction via Interpretable Pooling**|Yusen Peng,...Sachin Kumar|[2510.25067](http://arxiv.org/abs/2510.25067)|null|\n", "2510.25032": "|**2025-10-28**|**Efficient License Plate Recognition via Pseudo-Labeled Supervision with Grounding DINO and YOLOv8**|Zahra Ebrahimi Vargoorani,...Ching Yee Suen|[2510.25032](http://arxiv.org/abs/2510.25032)|null|\n", "2510.24949": "|**2025-10-28**|**SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving**|Anil Yildiz,...Mykel J. Kochenderfer|[2510.24949](http://arxiv.org/abs/2510.24949)|null|\n", "2510.24942": "|**2025-10-28**|**Finding Culture-Sensitive Neurons in Vision-Language Models**|Xiutian Zhao,...Ivan Titov|[2510.24942](http://arxiv.org/abs/2510.24942)|null|\n", "2510.26781": "|**2025-11-03**|**ChartAB: A Benchmark for Chart Grounding & Dense Alignment**|Aniruddh Bansal,...Tianyi Zhou|[2510.26781](http://arxiv.org/abs/2510.26781)|null|\n", "2510.26769": "|**2025-10-30**|**SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models**|Anushka Sivakumar,...Chris Thomas|[2510.26769](http://arxiv.org/abs/2510.26769)|null|\n", "2510.26641": "|**2025-10-30**|**All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles**|Sayed Pedram Haeri Boroujeni,...Abolfazl Razi|[2510.26641](http://arxiv.org/abs/2510.26641)|null|\n", "2510.26474": "|**2025-10-30**|**Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing**|Xin Guo,...Xuanjing Huang|[2510.26474](http://arxiv.org/abs/2510.26474)|null|\n", "2510.26466": "|**2025-11-03**|**Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition**|Pei Peng,...ShengJun Huang|[2510.26466](http://arxiv.org/abs/2510.26466)|null|\n", "2510.26464": "|**2025-10-30**|**Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection**|Yuanting Fan,...Chengjie Wang|[2510.26464](http://arxiv.org/abs/2510.26464)|null|\n", "2510.26441": "|**2025-10-30**|**A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models**|Shihab Aaqil Ahamed,...Muhammad Haris Khan|[2510.26441](http://arxiv.org/abs/2510.26441)|null|\n", "2510.26411": "|**2025-10-30**|**MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders**|Riccardo Renzulli,...Marco Grangetto|[2510.26411](http://arxiv.org/abs/2510.26411)|null|\n", "2510.26271": "|**2025-10-30**|**Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual**|Sukrit Sriratanawilai,...Peerat Limkonchotiwat|[2510.26271](http://arxiv.org/abs/2510.26271)|null|\n", "2510.26241": "|**2025-10-30**|**Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models**|Shiho Matta,...Shigeru Kitazawa|[2510.26241](http://arxiv.org/abs/2510.26241)|null|\n", "2510.26151": "|**2025-10-30**|**MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction**|Shunjie-Fabian Zheng,...Ali Diba|[2510.26151](http://arxiv.org/abs/2510.26151)|null|\n", "2510.26098": "|**2025-10-30**|**GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks**|Chenrui Shi,...Qing Li|[2510.26098](http://arxiv.org/abs/2510.26098)|null|\n", "2510.26052": "|**2025-10-30**|**Dynamic VLM-Guided Negative Prompting for Diffusion Models**|Hoyeon Chang,...Yoonseok Choi|[2510.26052](http://arxiv.org/abs/2510.26052)|null|\n", "2510.26006": "|**2025-10-29**|**CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments**|Rishika Bhagwatkar,...Antoine Bosselut|[2510.26006](http://arxiv.org/abs/2510.26006)|null|\n", "2510.27680": "|**2025-10-31**|**PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting**|Danyal Maqbool,...Tyler J. Bradshaw|[2510.27680](http://arxiv.org/abs/2510.27680)|null|\n", "2510.27606": "|**2025-10-31**|**Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning**|Yuhong Liu,...Jiaqi Wang|[2510.27606](http://arxiv.org/abs/2510.27606)|null|\n", "2510.27452": "|**2025-10-31**|**From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration**|Jianwen Sun,...Kaipeng Zhang|[2510.27452](http://arxiv.org/abs/2510.27452)|null|\n", "2510.27391": "|**2025-10-31**|**Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds**|Wu Wei,...Mehrtash Harandi|[2510.27391](http://arxiv.org/abs/2510.27391)|null|\n", "2510.27280": "|**2025-10-31**|**FOCUS: Efficient Keyframe Selection for Long Video Understanding**|Zirui Zhu,...Yang You|[2510.27280](http://arxiv.org/abs/2510.27280)|null|\n", "2510.27265": "|**2025-10-31**|**T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis**|Raza Imam,...Mohammad Yaqub|[2510.27265](http://arxiv.org/abs/2510.27265)|null|\n", "2510.27256": "|**2025-10-31**|**ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models**|Xin Tang,...Tengxiang Zhang|[2510.27256](http://arxiv.org/abs/2510.27256)|null|\n", "2510.27255": "|**2025-11-03**|**Enhancing Spatio-Temporal Zero-shot Action Recognition with Language-driven Description Attributes**|Yehna Kim,...Seong-Whan Lee|[2510.27255](http://arxiv.org/abs/2510.27255)|null|\n", "2510.27164": "|**2025-10-31**|**Generating Accurate and Detailed Captions for High-Resolution Images**|Hankyeol Lee,...Jiyoung Jung|[2510.27164](http://arxiv.org/abs/2510.27164)|null|\n", "2510.26996": "|**2025-10-30**|**MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation**|Arghavan Rezvani,...Xiaohui Xie|[2510.26996](http://arxiv.org/abs/2510.26996)|null|\n", "2510.26937": "|**2025-10-30**|**MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models**|Zimeng Huang,...Ziliang Chen|[2510.26937](http://arxiv.org/abs/2510.26937)|null|\n", "2510.26909": "|**2025-10-30**|**NaviTrace: Evaluating Embodied Navigation of Vision-Language Models**|Tim Windecker,...Jonas Frey|[2510.26909](http://arxiv.org/abs/2510.26909)|null|\n", "2510.26905": "|**2025-10-30**|**Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations**|Pedro Antonio Alarc\u00f3n Granadeno,...Jane Cleland-Huang|[2510.26905](http://arxiv.org/abs/2510.26905)|null|\n", "2510.26865": "|**2025-10-30**|**Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench**|Fenfen Lin,...Xi Yang|[2510.26865](http://arxiv.org/abs/2510.26865)|**[link](https://flageval-baai.github.io/MeasureBenchPage/)**|\n", "2511.02776": "|**2025-11-04**|**XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations**|Shichao Fan,...Jian Tang|[2511.02776](http://arxiv.org/abs/2511.02776)|null|\n", "2511.02503": "|**2025-11-04**|**Adapting General-Purpose Foundation Models for X-ray Ptychography in Low-Data Regimes**|Robinson Umeike,...Yi Jiang|[2511.02503](http://arxiv.org/abs/2511.02503)|null|\n", "2511.02384": "|**2025-11-04**|**RxnCaption: Reformulating Reaction Diagram Parsing as Visual Prompt Guided Captioning**|Jiahe Song,...Conghui He|[2511.02384](http://arxiv.org/abs/2511.02384)|null|\n", "2511.02367": "|**2025-11-04**|**The Pervasive Blind Spot: Benchmarking VLM Inference Risks on Everyday Personal Videos**|Shuning Zhang,...Hewu Li|[2511.02367](http://arxiv.org/abs/2511.02367)|null|\n", "2511.02360": "|**2025-11-04**|**CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning**|Jizheng Ma,...Han Yan|[2511.02360](http://arxiv.org/abs/2511.02360)|null|\n", "2511.02239": "|**2025-11-04**|**LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation**|Youngjin Hong,...Changhyun Choi|[2511.02239](http://arxiv.org/abs/2511.02239)|**[link](https://vla2026.github.io/LACY/)**|\n", "2511.02162": "|**2025-11-04**|**Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models**|Alexander Htet Kyaw,...Randall Davis|[2511.02162](http://arxiv.org/abs/2511.02162)|null|\n", "2511.02113": "|**2025-11-03**|**Enhancing Multimodal Recommendations with Vision-Language Models and Information-Aware Fusion**|Hai-Dang Kieu,...Dung D. Le|[2511.02113](http://arxiv.org/abs/2511.02113)|null|\n", "2511.01999": "|**2025-11-03**|**TRACE: Textual Reasoning for Affordance Coordinate Extraction**|Sangyun Park,...Matthew S. Brown|[2511.01999](http://arxiv.org/abs/2511.01999)|null|\n", "2511.01831": "|**2025-11-04**|**Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models**|Jay Mohta,...Mingwei Shen|[2511.01831](http://arxiv.org/abs/2511.01831)|null|\n", "2511.01817": "|**2025-11-03**|**SciTextures: Collecting and Connecting Visual Patterns, Models, and Code Across Science and Art**|Sagi Eppel,...Alona Strugatski|[2511.01817](http://arxiv.org/abs/2511.01817)|null|\n", "2511.01791": "|**2025-11-03**|**GenDexHand: Generative Simulation for Dexterous Hands**|Feng Chen,...Yi Ma|[2511.01791](http://arxiv.org/abs/2511.01791)|null|\n", "2511.01755": "|**2025-11-03**|**3EED: Ground Everything Everywhere in 3D**|Rong Li,...Ziwei Liu|[2511.01755](http://arxiv.org/abs/2511.01755)|**[link](https://project-3eed.github.io/)**|\n", "2511.01678": "|**2025-11-03**|**UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback**|Ropeway Liu,...Fan Wang|[2511.01678](http://arxiv.org/abs/2511.01678)|null|\n", "2511.01617": "|**2025-11-03**|**Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers**|Mohamed Eltahir,...Naeemullah Khan|[2511.01617](http://arxiv.org/abs/2511.01617)|null|\n", "2511.01952": "|**2025-11-03**|**Black-Box Membership Inference Attack for LVLMs via Prior Knowledge-Calibrated Memory Probing**|Jinhua Yin,...Tao Qi|[2511.01952](http://arxiv.org/abs/2511.01952)|null|\n", "2511.01550": "|**2025-11-03**|**Analyzing Sustainability Messaging in Large-Scale Corporate Social Media**|Ujjwal Sharma,...Marcel Worring|[2511.01550](http://arxiv.org/abs/2511.01550)|null|\n", "2511.01472": "|**2025-11-03**|**AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models**|Sarthak Mishra,...Spandan Roy|[2511.01472](http://arxiv.org/abs/2511.01472)|null|\n", "2511.01463": "|**2025-11-03**|**HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA**|Lei Hu,...Shihong Xia|[2511.01463](http://arxiv.org/abs/2511.01463)|null|\n", "2511.01458": "|**2025-11-03**|**When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA**|Dennis Pierantozzi,...Mobarak I. Hoque|[2511.01458](http://arxiv.org/abs/2511.01458)|null|\n", "2511.03400": "|**2025-11-05**|**GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement**|Minquan Gao,...Jiachen Li|[2511.03400](http://arxiv.org/abs/2511.03400)|null|\n", "2511.03367": "|**2025-11-05**|**Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models**|Gahyeon Kim,...Seokju Lee|[2511.03367](http://arxiv.org/abs/2511.03367)|null|\n", "2511.03001": "|**2025-11-04**|**LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation**|Gyeom Hwangbo,...Jinyoung Yeo|[2511.03001](http://arxiv.org/abs/2511.03001)|null|\n", "2511.02996": "|**2025-11-04**|**SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics**|Ailar Mahdizadeh,...Leonid Sigal|[2511.02996](http://arxiv.org/abs/2511.02996)|null|\n", "2511.04664": "|**2025-11-06**|**SAFe-Copilot: Unified Shared Autonomy Framework**|Phat Nguyen,...Daniela Rus|[2511.04664](http://arxiv.org/abs/2511.04664)|null|\n", "2511.04570": "|**2025-11-06**|**Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm**|Jingqi Tong,...Xipeng Qiu|[2511.04570](http://arxiv.org/abs/2511.04570)|null|\n", "2511.04555": "|**2025-11-06**|**Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment**|Tao Lin,...Bo Zhao|[2511.04555](http://arxiv.org/abs/2511.04555)|**[link](https://github.com/MINT-SJTU/Evo-1)**|\n", "2511.04479": "|**2025-11-07**|**ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai**|Surapon Nonesung,...Kunat Pipatanakul|[2511.04479](http://arxiv.org/abs/2511.04479)|null|\n", "2511.04307": "|**2025-11-06**|**GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents**|Jian Mu,...Dongmei Zhang|[2511.04307](http://arxiv.org/abs/2511.04307)|null|\n", "2511.04247": "|**2025-11-07**|**On the Brittleness of CLIP Text Encoders**|Allie Tran,...Luca Rossetto|[2511.04247](http://arxiv.org/abs/2511.04247)|**[link](https://github.com/allie-tran/clip-brittleness)**|\n", "2511.04123": "|**2025-11-06**|**Text to Sketch Generation with Multi-Styles**|Tengjie Li,...Lei Xu|[2511.04123](http://arxiv.org/abs/2511.04123)|null|\n", "2511.03908": "|**2025-11-05**|**Context informs pragmatic interpretation in vision-language models**|Alvin Wei Ming Tan,...Michael C. Frank|[2511.03908](http://arxiv.org/abs/2511.03908)|null|\n", "2511.03774": "|**2025-11-05**|**Contamination Detection for VLMs using Multi-Modal Semantic Perturbation**|Jaden Park,...Yong Jae Lee|[2511.03774](http://arxiv.org/abs/2511.03774)|null|\n", "2511.05491": "|**2025-11-07**|**Visual Spatial Tuning**|Rui Yang,...Hengshuang Zhao|[2511.05491](http://arxiv.org/abs/2511.05491)|null|\n", "2511.05325": "|**2025-11-07**|**Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval**|Janet Jenq,...Hongda Shen|[2511.05325](http://arxiv.org/abs/2511.05325)|null|\n", "2511.05017": "|**2025-11-07**|**Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings**|Aakriti Agrawal,...Furong Huang|[2511.05017](http://arxiv.org/abs/2511.05017)|null|\n", "2511.04976": "|**2025-11-07**|**iFlyBot-VLM Technical Report**|Xin Nie,...Jia Pan|[2511.04976](http://arxiv.org/abs/2511.04976)|null|\n", "2511.04948": "|**2025-11-07**|**A benchmark multimodal oro-dental dataset for large vision-language models**|Haoxin Lv,...Muhammad Saqib|[2511.04948](http://arxiv.org/abs/2511.04948)|null|\n", "2511.04835": "|**2025-11-06**|**Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning**|Shubham Natraj,...Yiannis Kantaros|[2511.04835](http://arxiv.org/abs/2511.04835)|null|\n", "2511.04727": "|**2025-11-06**|**IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs**|Ali Faraz,...Shubham Agarwal|[2511.04727](http://arxiv.org/abs/2511.04727)|null|\n", "2511.04711": "|**2025-11-05**|**SWAP: Towards Copyright Auditing of Soft Prompts via Sequential Watermarking**|Wenyuan Yang,...Dacheng Tao|[2511.04711](http://arxiv.org/abs/2511.04711)|null|\n", "2511.07410": "|**2025-11-10**|**Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective**|Hao Wang,...Somil Bansal|[2511.07410](http://arxiv.org/abs/2511.07410)|null|\n", "2511.07290": "|**2025-11-10**|**CAMP-VQA: Caption-Embedded Multimodal Perception for No-Reference Quality Assessment of Compressed Video**|Xinyi Wang,...David Bull|[2511.07290](http://arxiv.org/abs/2511.07290)|null|\n", "2511.07238": "|**2025-11-10**|**Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation**|Seungheon Song,...Jaekoo Lee|[2511.07238](http://arxiv.org/abs/2511.07238)|null|\n", "2511.07171": "|**2025-11-10**|**Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use**|S\u00e9bastien Thuau,...Rachid Chelouah|[2511.07171](http://arxiv.org/abs/2511.07171)|null|\n", "2511.07068": "|**2025-11-10**|**ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora**|Nikolas Adaloglou,...Markus Kollmann|[2511.07068](http://arxiv.org/abs/2511.07068)|**[link](https://github.com/HHU-MMBS/clustermine_wacv_official)**|\n", "2511.06991": "|**2025-11-10**|**CoLM: Collaborative Large Models via A Client-Server Paradigm**|Siqi Huang,...Hongyuan Zhang|[2511.06991](http://arxiv.org/abs/2511.06991)|null|\n", "2511.06899": "|**2025-11-10**|**RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation**|Haofeng Wang,...Yu Zhang|[2511.06899](http://arxiv.org/abs/2511.06899)|null|\n", "2511.06678": "|**2025-11-10**|**Flexible Concept Bottleneck Model**|Xingbo Du,...Rui Zhang|[2511.06678](http://arxiv.org/abs/2511.06678)|null|\n", "2511.06653": "|**2025-11-10**|**HiMo-CLIP: Modeling Semantic Hierarchy and Monotonicity in Vision-Language Alignment**|Ruijia Wu,...Shiguo Lian|[2511.06653](http://arxiv.org/abs/2511.06653)|null|\n", "2511.06651": "|**2025-11-10**|**NOVO: Bridging LLaVA and SAM with Visual-only Prompts for Reasoning Segmentation**|Kyung-Yoon Yoon,...Yeong-Jun Cho|[2511.06651](http://arxiv.org/abs/2511.06651)|null|\n", "2511.06619": "|**2025-11-10**|**How Do VLAs Effectively Inherit from VLMs?**|Chuheng Zhang,...Jiang Bian|[2511.06619](http://arxiv.org/abs/2511.06619)|null|\n", "2511.06496": "|**2025-11-09**|**A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving**|Keke Long,...Xiaopeng Li|[2511.06496](http://arxiv.org/abs/2511.06496)|null|\n", "2511.06490": "|**2025-11-09**|**Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models**|Yule Chen,...Sabine S\u00fcsstrunk|[2511.06490](http://arxiv.org/abs/2511.06490)|null|\n", "2511.06348": "|**2025-11-09**|**GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding**|Athul M. Mathew,...Riad Souissi|[2511.06348](http://arxiv.org/abs/2511.06348)|null|\n", "2511.06316": "|**2025-11-09**|**ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning**|MD Thamed Bin Zaman Chowdhury,...Moazzem Hossain|[2511.06316](http://arxiv.org/abs/2511.06316)|null|\n", "2511.06283": "|**2025-11-09**|**TinyChemVL: Advancing Chemical Vision-Language Models via Efficient Visual Token Reduction and Complex Reaction Tasks**|Xuanle Zhao,...Bo Xu|[2511.06283](http://arxiv.org/abs/2511.06283)|null|\n", "2511.06251": "|**2025-11-09**|**WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation**|Mingde Xu,...Jie Tang|[2511.06251](http://arxiv.org/abs/2511.06251)|null|\n", "2511.06240": "|**2025-11-09**|**Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation**|Tzu-Jung Lin,...Winston H. Hsu|[2511.06240](http://arxiv.org/abs/2511.06240)|null|\n", "2511.06225": "|**2025-11-09**|**MoRA: Missing Modality Low-Rank Adaptation for Visual Recognition**|Shu Zhao,...Vijaykrishnan Narayanan|[2511.06225](http://arxiv.org/abs/2511.06225)|null|\n", "2511.06201": "|**2025-11-09**|**Scene-Aware Urban Design: A Human-AI Recommendation Framework Using Co-Occurrence Embeddings and Vision-Language Models**|Rodrigo Gallardo,...Alexander Htet Kyaw|[2511.06201](http://arxiv.org/abs/2511.06201)|null|\n", "2508.19294": "|**2025-10-01**|**Object Detection with Multimodal Large Vision-Language Models: An In-depth Review**|Ranjan Sapkota,...Manoj Karkee|[2508.19294](http://arxiv.org/abs/2508.19294)|null|\n", "2307.03135": "|**2023-10-13**|**Distilling Large Vision-Language Model with Out-of-Distribution Generalizability**|Xuanlin Li,...Hao Su|[2307.03135](http://arxiv.org/abs/2307.03135)|**[link](https://xuanlinli17.github.io/pdfs/iccv23_large_vlm_distillation_poster.pdf)**|\n", "2506.05429": "|**2025-06-09**|**Coordinated Robustness Evaluation Framework for Vision-Language Models**|Ashwin Ramesh Babu,...Soumyendu Sarkar|[2506.05429](http://arxiv.org/abs/2506.05429)|null|\n", "2504.09480": "|**2025-04-15**|**Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation**|Yongchao Feng,...Yunhong Wang|[2504.09480](http://arxiv.org/abs/2504.09480)|null|\n", "2507.07104": "|**2025-07-14**|**Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models**|Tiezheng Zhang,...Junfei Xiao|[2507.07104](http://arxiv.org/abs/2507.07104)|**[link](https://lambert-x.github.io/Vision-Language-Vision/)**|\n", "2404.07214": "|**2025-10-15**|**Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions**|Akash Ghosh,...Aman Chadha|[2404.07214](http://arxiv.org/abs/2404.07214)|null|\n", "2411.19103": "|**2024-12-02**|**VARCO-VISION: Expanding Frontiers in Korean Vision-Language Models**|Jeongho Ju,...Youngjune Kim|[2411.19103](http://arxiv.org/abs/2411.19103)|**[link](https://huggingface.co/NCSOFT/VARCO-VISION-14B.)**|\n", "2409.15256": "|**2024-09-24**|**Behavioral Bias of Vision-Language Models: A Behavioral Finance View**|Yuhang Xiao,...Ming-Chang Chiu|[2409.15256](http://arxiv.org/abs/2409.15256)|null|\n", "2411.18711": "|**2025-05-19**|**Evaluating Vision-Language Models as Evaluators in Path Planning**|Mohamed Aghzal,...Ziyu Yao|[2411.18711](http://arxiv.org/abs/2411.18711)|null|\n", "2504.11108": "|**2025-06-30**|**Benchmarking Vision Language Models on German Factual Data**|Ren\u00e9 Peinl,...Vincent Tischler|[2504.11108](http://arxiv.org/abs/2504.11108)|null|\n", "2309.04041": "|**2024-01-17**|**Evaluation and Enhancement of Semantic Grounding in Large Vision-Language Models**|Jiaying Lu,...Jie Yang|[2309.04041](http://arxiv.org/abs/2309.04041)|null|\n", "2109.01134": "|**2022-10-07**|**Learning to Prompt for Vision-Language Models**|Kaiyang Zhou,...Ziwei Liu|[2109.01134](http://arxiv.org/abs/2109.01134)|null|\n", "2306.09265": "|**2023-06-16**|**LVLM-eHub: A Comprehensive Evaluation Benchmark for Large Vision-Language Models**|Peng Xu,...Ping Luo|[2306.09265](http://arxiv.org/abs/2306.09265)|null|\n", "2303.10093": "|**2023-11-08**|**Investigating the Role of Attribute Context in Vision-Language Models for Object Recognition and Detection**|Kyle Buettner,...Adriana Kovashka|[2303.10093](http://arxiv.org/abs/2303.10093)|null|\n", "2506.11595": "|**2025-06-16**|**EasyARC: Evaluating Vision Language Models on True Visual Reasoning**|Mert Unsal,...Aylin Akkus|[2506.11595](http://arxiv.org/abs/2506.11595)|null|\n", "2503.18013": "|**2025-03-25**|**Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning**|Yufei Zhan,...Jinqiao Wang|[2503.18013](http://arxiv.org/abs/2503.18013)|**[link](https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1)**|\n", "2202.09061": "|**2024-04-19**|**VLP: A Survey on Vision-Language Pre-training**|Feilong Chen,...Bo Xu|[2202.09061](http://arxiv.org/abs/2202.09061)|null|\n", "2403.19838": "|**2024-05-10**|**Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving**|Akshay Gopalkrishnan,...Mohan Trivedi|[2403.19838](http://arxiv.org/abs/2403.19838)|null|\n", "2407.21788": "|**2024-08-01**|**Vision-Language Model Based Handwriting Verification**|Mihir Chauhan,...Sargur Srihari|[2407.21788](http://arxiv.org/abs/2407.21788)|null|\n", "2410.00982": "|**2025-03-11**|**ScVLM: Enhancing Vision-Language Model for Safety-Critical Event Understanding**|Liang Shi,...Feng Guo|[2410.00982](http://arxiv.org/abs/2410.00982)|null|\n", "2511.10648": "|**2025-11-13**|**Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling**|Jiahao Wang,...Jinguo Zhu|[2511.10648](http://arxiv.org/abs/2511.10648)|null|\n", "2511.10627": "|**2025-11-13**|**Querying Labeled Time Series Data with Scenario Programs**|Edward Kim,...Sanjit A Seshia|[2511.10627](http://arxiv.org/abs/2511.10627)|null|\n", "2511.10615": "|**2025-11-13**|**Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals**|Shruti Singh Baghel,...Pawan Goyal|[2511.10615](http://arxiv.org/abs/2511.10615)|null|\n", "2511.10566": "|**2025-11-13**|**Impact of Layer Norm on Memorization and Generalization in Transformers**|Rishi Singhal,...Jung-Eun Kim|[2511.10566](http://arxiv.org/abs/2511.10566)|null|\n", "2511.10560": "|**2025-11-13**|**OmniVGGT: Omni-Modality Driven Visual Geometry Grounded**|Haosong Peng,...Ziwei Liu|[2511.10560](http://arxiv.org/abs/2511.10560)|**[link](https://livioni.github.io/OmniVGGT-offcial/)**|\n", "2511.10518": "|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Wei Li,...Liqiang Nie|[2511.10518](http://arxiv.org/abs/2511.10518)|**[link](https://github.com/JiuTian-VL/SemanticVLA)**|\n", "2511.10394": "|**2025-11-13**|**LLM-YOLOMS: Large Language Model-based Semantic Interpretation and Fault Diagnosis for Wind Turbine Components**|Yaru Li,...Jianbo Feng|[2511.10394](http://arxiv.org/abs/2511.10394)|null|\n", "2511.10390": "|**2025-11-13**|**MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns**|Jiarui Zhang,...Xiang Bai|[2511.10390](http://arxiv.org/abs/2511.10390)|null|\n", "2511.10301": "|**2025-11-13**|**Rethinking Visual Information Processing in Multimodal LLMs**|Dongwan Kim,...Amit Kumar K C|[2511.10301](http://arxiv.org/abs/2511.10301)|null|\n", "2511.10292": "|**2025-11-13**|**Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models**|Zhengtao Zou,...Pekka Marttinen|[2511.10292](http://arxiv.org/abs/2511.10292)|null|\n", "2511.10279": "|**2025-11-13**|**PROPA: Toward Process-level Optimization in Visual Reasoning via Reinforcement Learning**|Yanbei Jiang,...Jey Han Lau|[2511.10279](http://arxiv.org/abs/2511.10279)|null|\n", "2511.10268": "|**2025-11-13**|**Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention**|Zhe Xu,...Xiang Wang|[2511.10268](http://arxiv.org/abs/2511.10268)|null|\n", "2511.10254": "|**2025-11-13**|**Facial-R1: Aligning Reasoning and Recognition for Facial Emotion Analysis**|Jiulong Wu,...Min Cao|[2511.10254](http://arxiv.org/abs/2511.10254)|null|\n", "2511.10241": "|**2025-11-13**|**TubeRMC: Tube-conditioned Reconstruction with Mutual Constraints for Weakly-supervised Spatio-Temporal Video Grounding**|Jinxuan Li,...Beihao Xia|[2511.10241](http://arxiv.org/abs/2511.10241)|null|\n", "2511.10119": "|**2025-11-13**|**Intilligence Foundation Model: A New Perspective to Approach Artificial General Intelligence**|Borui Cai,...Yao Zhao|[2511.10119](http://arxiv.org/abs/2511.10119)|null|\n", "2511.10098": "|**2025-11-13**|**MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models**|Zihan Wang,...Xiao Bai|[2511.10098](http://arxiv.org/abs/2511.10098)|null|\n", "2511.10094": "|**2025-11-13**|**How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders**|Yiming Tang,...Dianbo Liu|[2511.10094](http://arxiv.org/abs/2511.10094)|null|\n", "2511.10091": "|**2025-11-13**|**SUGAR: Learning Skeleton Representation with Visual-Motion Knowledge for Action Recognition**|Qilang Ye,...Zitong Yu|[2511.10091](http://arxiv.org/abs/2511.10091)|null|\n", "2511.10081": "|**2025-11-13**|**GridPrune: From \"Where to Look\" to \"What to Select\" in Visual Token Pruning for MLLMs**|Yuxiang Duan,...Pengwei Wang|[2511.10081](http://arxiv.org/abs/2511.10081)|null|\n", "2511.10074": "|**2025-11-13**|**VLF-MSC: Vision-Language Feature-Based Multimodal Semantic Communication System**|Gwangyeon Ahn,...Joonhyuk Kang|[2511.10074](http://arxiv.org/abs/2511.10074)|null|\n", "2511.11552": "|**2025-11-14**|**DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding**|Dawei Zhu,...Jinsung Yoon|[2511.11552](http://arxiv.org/abs/2511.11552)|null|\n", "2511.11526": "|**2025-11-14**|**Bridging Hidden States in Vision-Language Models**|Benjamin Fein-Ashley,...Jacob Fein-Ashley|[2511.11526](http://arxiv.org/abs/2511.11526)|null|\n", "2511.11512": "|**2025-11-14**|**Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities**|Yiyun Zhou,...Jingyuan Chen|[2511.11512](http://arxiv.org/abs/2511.11512)|null|\n", "2511.11502": "|**2025-11-14**|**PAS : Prelim Attention Score for Detecting Object Hallucinations in Large Vision--Language Models**|Nhat Hoang-Xuan,...Manish Bhattarai|[2511.11502](http://arxiv.org/abs/2511.11502)|null|\n", "2511.11478": "|**2025-11-14**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Nhat Chung,...Ngan Le|[2511.11478](http://arxiv.org/abs/2511.11478)|null|\n", "2511.11468": "|**2025-11-14**|**Benchmarking Visual LLMs Resilience to Unanswerable Questions on Visually Rich Documents**|Davide Napolitano,...Fabrizio Battiloro|[2511.11468](http://arxiv.org/abs/2511.11468)|null|\n", "2511.11450": "|**2025-11-14**|**VoxTell: Free-Text Promptable Universal 3D Medical Image Segmentation**|Maximilian Rokuss,...Klaus Maier-Hein|[2511.11450](http://arxiv.org/abs/2511.11450)|null|\n", "2511.11440": "|**2025-11-14**|**From Synthetic Scenes to Real Performance: Enhancing Spatial Reasoning in VLMs**|Massimo Rizzoli,...Giuseppe Riccardi|[2511.11440](http://arxiv.org/abs/2511.11440)|null|\n", "2511.11438": "|**2025-11-14**|**VP-Bench: A Comprehensive Benchmark for Visual Prompting in Multimodal Large Language Models**|Mingjie Xu,...Wenqiang Lei|[2511.11438](http://arxiv.org/abs/2511.11438)|null|\n", "2511.11427": "|**2025-11-14**|**Comprehension of Multilingual Expressions Referring to Target Objects in Visual Inputs**|Francisco Nogueira,...Bruno Martins|[2511.11427](http://arxiv.org/abs/2511.11427)|null|\n", "2511.11421": "|**2025-11-14**|**BOFA: Bridge-Layer Orthogonal Low-Rank Fusion for CLIP-Based Class-Incremental Learning**|Lan Li,...De-Chuan Zhan|[2511.11421](http://arxiv.org/abs/2511.11421)|null|\n", "2511.11410": "|**2025-11-14**|**Q-Doc: Benchmarking Document Image Quality Assessment Capabilities in Multi-modal Large Language Models**|Jiaxi Huang,...Baoliang Chen|[2511.11410](http://arxiv.org/abs/2511.11410)|null|\n", "2511.11407": "|**2025-11-14**|**MicroVQA++: High-Quality Microscopy Reasoning Dataset with Weakly Supervised Graphs for Multimodal Large Language Model**|Manyu Li,...Bo Yan|[2511.11407](http://arxiv.org/abs/2511.11407)|null|\n", "2511.11313": "|**2025-11-14**|**DocSLM: A Small Vision-Language Model for Long Multimodal Document Understanding**|Tanveer Hannan,...Sunando Sengupta|[2511.11313](http://arxiv.org/abs/2511.11313)|null|\n", "2511.11301": "|**2025-11-14**|**EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment**|Ruoxi Cheng,...Hongyi Zhang|[2511.11301](http://arxiv.org/abs/2511.11301)|null|\n", "2511.11299": "|**2025-11-14**|**AUVIC: Adversarial Unlearning of Visual Concepts for Multi-modal Large Language Models**|Haokun Chen,...Volker Tresp|[2511.11299](http://arxiv.org/abs/2511.11299)|**[link](https://github.com/HaokunChen245/AUVIC)**|\n", "2511.11298": "|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Yihao Zhang,...Xi Zheng|[2511.11298](http://arxiv.org/abs/2511.11298)|null|\n", "2511.11266": "|**2025-11-14**|**GraphPilot: Grounded Scene Graph Conditioning for Language-Based Autonomous Driving**|Fabian Schmidt,...Abhinav Valada|[2511.11266](http://arxiv.org/abs/2511.11266)|null|\n", "2511.11262": "|**2025-11-14**|**Discovering Meaningful Units with Visually Grounded Semantics from Image Captions**|Melika Behjati,...James Henderson|[2511.11262](http://arxiv.org/abs/2511.11262)|null|\n", "2511.11253": "|**2025-11-14**|**CountSteer: Steering Attention for Object Counting in Diffusion Models**|Hyemin Boo,...Hyunsoo Cho|[2511.11253](http://arxiv.org/abs/2511.11253)|null|\n", "2511.13719": "|**2025-11-17**|**Scaling Spatial Intelligence with Multimodal Foundation Models**|Zhongang Cai,...Lei Yang|[2511.13719](http://arxiv.org/abs/2511.13719)|**[link](https://huggingface.co/collections/sensenova/sensenova-si)**|\n", "2511.13704": "|**2025-11-17**|**TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models**|Harold Haodong Chen,...Ying-Cong Chen|[2511.13704](http://arxiv.org/abs/2511.13704)|**[link](https://haroldchen19.github.io/TiViBench-Page/)**|\n", "2511.13689": "|**2025-11-17**|**Crossing Borders: A Multimodal Challenge for Indian Poetry Translation and Image Generation**|Sofia Jamil,...Joseph K J|[2511.13689](http://arxiv.org/abs/2511.13689)|null|\n", "2511.13684": "|**2025-11-17**|**Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting**|Jiangnan Ye,...Haoji Hu|[2511.13684](http://arxiv.org/abs/2511.13684)|null|\n", "2511.13647": "|**2025-11-17**|**Part-X-MLLM: Part-aware 3D Multimodal Large Language Model**|Chunshi Wang,...Chunchao Guo|[2511.13647](http://arxiv.org/abs/2511.13647)|null|\n", "2511.13644": "|**2025-11-17**|**CacheFlow: Compressive Streaming Memory for Efficient Long-Form Video Understanding**|Shrenik Patel,...Daivik Patel|[2511.13644](http://arxiv.org/abs/2511.13644)|null|\n", "2511.13626": "|**2025-11-17**|**CreBench: Human-Aligned Creativity Evaluation from Idea to Process to Product**|Kaiwen Xue,...Jiayi Cen|[2511.13626](http://arxiv.org/abs/2511.13626)|null|\n", "2511.13524": "|**2025-11-17**|**FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI**|Yuhang Peng,...Jiangtao Gong|[2511.13524](http://arxiv.org/abs/2511.13524)|null|\n", "2511.13494": "|**2025-11-17**|**Language-Guided Invariance Probing of Vision-Language Models**|Jae Joong Lee,...Jae Joong Lee|[2511.13494](http://arxiv.org/abs/2511.13494)|null|\n", "2511.13478": "|**2025-11-17**|**Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling**|Adam Hazimeh,...Pascal Frossard|[2511.13478](http://arxiv.org/abs/2511.13478)|null|\n", "2511.13458": "|**2025-11-17**|**Trust in Vision-Language Models: Insights from a Participatory User Workshop**|Agnese Chiatti,...Viola Schiaffonati|[2511.13458](http://arxiv.org/abs/2511.13458)|null|\n", "2511.13442": "|**2025-11-17**|**Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline**|Rui Zuo,...Ziqian Lu|[2511.13442](http://arxiv.org/abs/2511.13442)|null|\n", "2511.13420": "|**2025-11-17**|**VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task**|Xingming Long,...Xilin Chen|[2511.13420](http://arxiv.org/abs/2511.13420)|null|\n", "2511.13415": "|**2025-11-17**|**Attention Grounded Enhancement for Visual Document Retrieval**|Wanqing Cui,...Keping Bi|[2511.13415](http://arxiv.org/abs/2511.13415)|null|\n", "2511.13397": "|**2025-11-17**|**Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)**|Nikos Theodoridis,...Ciaran Eising|[2511.13397](http://arxiv.org/abs/2511.13397)|null|\n", "2511.13387": "|**2025-11-17**|**Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model**|Fei Kong,...Fei Kong|[2511.13387](http://arxiv.org/abs/2511.13387)|null|\n", "2511.13378": "|**2025-11-17**|**Moving Pictures of Thought: Extracting Visual Knowledge in Charles S. Peirce's Manuscripts with Vision-Language Models**|Carlo Teo Pedretti,...Dario Rodighiero|[2511.13378](http://arxiv.org/abs/2511.13378)|null|\n", "2511.13338": "|**2025-11-17**|**Tab-PET: Graph-Based Positional Encodings for Tabular Transformers**|Yunze Leng,...Mehul Motani|[2511.13338](http://arxiv.org/abs/2511.13338)|null|\n", "2511.13283": "|**2025-11-17**|**TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing**|Jongha Kim,...Hyunwoo J. Kim|[2511.13283](http://arxiv.org/abs/2511.13283)|null|\n", "2511.13269": "|**2025-11-17**|**Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation**|Lingfeng Zhang,...Wenbo Ding|[2511.13269](http://arxiv.org/abs/2511.13269)|null|\n", "2511.14761": "|**2025-11-18**|**ARC Is a Vision Problem!**|Keya Hu,...Kaiming He|[2511.14761](http://arxiv.org/abs/2511.14761)|**[link](https://github.com/lillian039/VARC)**|\n", "2511.14760": "|**2025-11-18**|**UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning**|Rui Tian,...Afshin Dehghan|[2511.14760](http://arxiv.org/abs/2511.14760)|null|\n", "2511.14759": "|**2025-11-18**|**$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience**|Ali Amin,...Zhiyuan Zhou|[2511.14759](http://arxiv.org/abs/2511.14759)|null|\n", "2511.14749": "|**2025-11-18**|**Vision Large Language Models Are Good Noise Handlers in Engagement Analysis**|Alexander Vedernikov,...Xiaobai Li|[2511.14749](http://arxiv.org/abs/2511.14749)|null|\n", "2511.14744": "|**2025-11-18**|**Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge**|Antonia Ebner,...G\u00fcnter Klambauer|[2511.14744](http://arxiv.org/abs/2511.14744)|null|\n", "2511.14691": "|**2025-11-18**|**Attention via Synaptic Plasticity is All You Need: A Biologically Inspired Spiking Neuromorphic Transformer**|Kallol Mondal,...Ankush Kumar|[2511.14691](http://arxiv.org/abs/2511.14691)|null|\n", "2511.14659": "|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung,...Soujanya Poria|[2511.14659](http://arxiv.org/abs/2511.14659)|**[link](https://declare-lab.github.io/nora-1.5)**|\n", "2511.14631": "|**2025-11-18**|**Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities**|Kahaan Gandhi,...Inigo Zubeldia|[2511.14631](http://arxiv.org/abs/2511.14631)|null|\n", "2511.14592": "|**2025-11-18**|**Is Your VLM for Autonomous Driving Safety-Ready? A Comprehensive Benchmark for Evaluating External and In-Cabin Risks**|Xianhui Meng,...Xiaoshuai Hao|[2511.14592](http://arxiv.org/abs/2511.14592)|null|\n", "2511.14582": "|**2025-11-18**|**OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models**|Keda Tao,...Huan Wang|[2511.14582](http://arxiv.org/abs/2511.14582)|**[link](https://github.com/KD-TAO/OmniZip)**|\n", "2511.14569": "|**2025-11-18**|**Task Addition and Weight Disentanglement in Closed-Vocabulary Models**|Adam Hazimeh,...Pascal Frossard|[2511.14569](http://arxiv.org/abs/2511.14569)|null|\n", "2511.14499": "|**2025-11-18**|**Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM**|Jack Qin,...Siyuan Cheng|[2511.14499](http://arxiv.org/abs/2511.14499)|null|\n", "2511.14446": "|**2025-11-18**|**Agentic Video Intelligence: A Flexible Framework for Advanced Video Exploration and Understanding**|Hong Gao,...Min-Ling Zhang|[2511.14446](http://arxiv.org/abs/2511.14446)|null|\n", "2511.14435": "|**2025-11-18**|**Watchdogs and Oracles: Runtime Verification Meets Large Language Models for Autonomous Systems**|Angelo Ferrando,...Angelo Ferrando|[2511.14435](http://arxiv.org/abs/2511.14435)|null|\n", "2511.14391": "|**2025-11-18**|**Enhancing LLM-based Autonomous Driving with Modular Traffic Light and Sign Recognition**|Fabian Schmidt,...Abhinav Valada|[2511.14391](http://arxiv.org/abs/2511.14391)|null|\n", "2511.14368": "|**2025-11-18**|**O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model**|Rishi Gupta,...Anirban Chakraborty|[2511.14368](http://arxiv.org/abs/2511.14368)|null|\n", "2511.14336": "|**2025-11-18**|**ArchMap: Arch-Flattening and Knowledge-Guided Vision Language Model for Tooth Counting and Structured Dental Understanding**|Bohan Zhang,...Jionglong Su|[2511.14336](http://arxiv.org/abs/2511.14336)|null|\n", "2511.14334": "|**2025-11-18**|**When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling**|Alessio Pellegrino,...Jacopo Mauro|[2511.14334](http://arxiv.org/abs/2511.14334)|null|\n", "2511.14329": "|**2025-11-18**|**Step by Step Network**|Dongchen Han,...Gao Huang|[2511.14329](http://arxiv.org/abs/2511.14329)|null|\n", "2511.14293": "|**2025-11-18**|**Segmentwise Pruning in Audio-Language Models**|Marcel Gibier,...Jean-Fran\u00e7ois Bonastre|[2511.14293](http://arxiv.org/abs/2511.14293)|null|\n", "2511.15703": "|**2025-11-19**|**Think Visually, Reason Textually: Vision-Language Synergy in ARC**|Beichen Zhang,...Jiaqi Wang|[2511.15703](http://arxiv.org/abs/2511.15703)|null|\n", "2511.15690": "|**2025-11-19**|**MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping**|Yushi Huang,...Jun Zhang|[2511.15690](http://arxiv.org/abs/2511.15690)|null|\n", "2511.15684": "|**2025-11-19**|**Walrus: A Cross-Domain Foundation Model for Continuum Dynamics**|Michael McCabe,...Shirley Ho|[2511.15684](http://arxiv.org/abs/2511.15684)|null|\n", "2511.15661": "|**2025-11-19**|**VisPlay: Self-Evolving Vision-Language Models from Images**|Yicheng He,...Yonghui Yang|[2511.15661](http://arxiv.org/abs/2511.15661)|null|\n", "2511.15633": "|**2025-11-19**|**Hierarchical Semantic Tree Anchoring for CLIP-Based Class-Incremental Learning**|Tao Hu,...Da-Wei Zhou|[2511.15633](http://arxiv.org/abs/2511.15633)|null|\n", "2511.15622": "|**2025-11-19**|**The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification**|Dante Francisco Wasmuht,...Didac Suris|[2511.15622](http://arxiv.org/abs/2511.15622)|null|\n", "2511.15613": "|**2025-11-19**|**When to Think and When to Look: Uncertainty-Guided Lookback**|Jing Bi,...Chenliang Xu|[2511.15613](http://arxiv.org/abs/2511.15613)|null|\n", "2511.15605": "|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Senyu Fei,...Xipeng Qiu|[2511.15605](http://arxiv.org/abs/2511.15605)|null|\n", "2511.15578": "|**2025-11-19**|**AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning**|Urjitkumar Patel,...Chinmay Gondhalekar|[2511.15578](http://arxiv.org/abs/2511.15578)|null|\n", "2511.15567": "|**2025-11-19**|**Computer-Use Agents as Judges for Generative User Interface**|Kevin Qinghong Lin,...Mike Zheng Shou|[2511.15567](http://arxiv.org/abs/2511.15567)|**[link](https://showlab.github.io/AUI)**|\n", "2511.15552": "|**2025-11-19**|**Multimodal Evaluation of Russian-language Architectures**|Artem Chervyakov,...Alena Fenogenova|[2511.15552](http://arxiv.org/abs/2511.15552)|null|\n", "2511.15499": "|**2025-11-19**|**Learning to Expand Images for Efficient Visual Autoregressive Modeling**|Ruiqing Yang,...Tao Huang|[2511.15499](http://arxiv.org/abs/2511.15499)|null|\n", "2511.15464": "|**2025-11-19**|**SIGMMA: Hierarchical Graph-Based Multi-Scale Multi-modal Contrastive Alignment of Histopathology Image and Spatial Transcriptome**|Dabin Jeong,...Mohammad Lotfollahi|[2511.15464](http://arxiv.org/abs/2511.15464)|null|\n", "2511.15411": "|**2025-11-19**|**D4C: Data-free Quantization for Contrastive Language-Image Pre-training Models**|Wenlun Zhang,...Kentaro Yoshioka|[2511.15411](http://arxiv.org/abs/2511.15411)|null|\n", "2511.15390": "|**2025-11-19**|**Breaking Expert Knowledge Limits: Self-Pruning for Large Language Models**|Haidong Kang,...Hao Wang|[2511.15390](http://arxiv.org/abs/2511.15390)|null|\n", "2511.15379": "|**2025-11-19**|**Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training**|Yunjiao Zhou,...Jianfei Yang|[2511.15379](http://arxiv.org/abs/2511.15379)|null|\n", "2511.15333": "|**2025-11-19**|**C2F-Space: Coarse-to-Fine Space Grounding for Spatial Instructions using Vision-Language Models**|Nayoung Oh,...Daehyung Park|[2511.15333](http://arxiv.org/abs/2511.15333)|null|\n", "2511.15316": "|**2025-11-19**|**What Your Features Reveal: Data-Efficient Black-Box Feature Inversion Attack for Split DNNs**|Zhihan Ren,...Fan Li|[2511.15316](http://arxiv.org/abs/2511.15316)|null|\n", "2511.15311": "|**2025-11-19**|**Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models**|Mehran Tamjidi,...Morteza Saberi|[2511.15311](http://arxiv.org/abs/2511.15311)|null|\n", "2511.15308": "|**2025-11-19**|**Text2Loc++: Generalizing 3D Point Cloud Localization from Natural Language**|Yan Xia,...Daniel Cremers|[2511.15308](http://arxiv.org/abs/2511.15308)|null|\n", "2511.16670": "|**2025-11-20**|**Learning to Think Fast and Slow for Visual Language Models**|Chenyu Lin,...Kaiyang Zhou|[2511.16670](http://arxiv.org/abs/2511.16670)|null|\n", "2511.16669": "|**2025-11-20**|**Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO**|Junhao Cheng,...Jing Liao|[2511.16669](http://arxiv.org/abs/2511.16669)|**[link](https://video-as-answer.github.io/)**|\n", "2511.16660": "|**2025-11-20**|**Cognitive Foundations for Reasoning and Their Manifestation in LLMs**|Priyanka Kargupta,...Yulia Tsvetkov|[2511.16660](http://arxiv.org/abs/2511.16660)|null|\n", "2511.16651": "|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Yang Tian,...Jiangmiao Pang|[2511.16651](http://arxiv.org/abs/2511.16651)|null|\n", "2511.16602": "|**2025-11-20**|**Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization**|Yi Zhang,...Xiaozhu Ju|[2511.16602](http://arxiv.org/abs/2511.16602)|null|\n", "2511.16595": "|**2025-11-20**|**TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding**|Boshen Xu,...Qin Jin|[2511.16595](http://arxiv.org/abs/2511.16595)|**[link](https://xuboshen.github.io/TimeViper)**|\n", "2511.16527": "|**2025-11-20**|**Contrastive vision-language learning with paraphrasing and negation**|Kwun Ho Ngan,...Artur d'Avila Garcez|[2511.16527](http://arxiv.org/abs/2511.16527)|null|\n", "2511.16518": "|**2025-11-20**|**MiMo-Embodied: X-Embodied Foundation Model Technical Report**|Xiaoshuai Hao,...Long Chen|[2511.16518](http://arxiv.org/abs/2511.16518)|**[link](https://github.com/XiaomiMiMo/MiMo-Embodied)**|\n", "2511.16470": "|**2025-11-20**|**Arctic-Extract Technical Report**|Mateusz Chili\u0144ski,...Wojciech Ja\u015bkowski|[2511.16470](http://arxiv.org/abs/2511.16470)|null|\n", "2511.16454": "|**2025-11-20**|**LLaVA$^3$: Representing 3D Scenes like a Cubist Painter to Boost 3D Scene Understanding of VLMs**|Doriand Petit,...Lo\u00efc Barthe|[2511.16454](http://arxiv.org/abs/2511.16454)|null|\n", "2511.16449": "|**2025-11-20**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Ziyan Liu,...Bo Zhao|[2511.16449](http://arxiv.org/abs/2511.16449)|null|\n", "2511.16435": "|**2025-11-20**|**Beyond Visual Cues: Leveraging General Semantics as Support for Few-Shot Segmentation**|Jin Wang,...Weifeng Liu|[2511.16435](http://arxiv.org/abs/2511.16435)|null|\n", "2511.16423": "|**2025-11-20**|**TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models**|Li Zhang,...Chaochao Chen|[2511.16423](http://arxiv.org/abs/2511.16423)|null|\n", "2511.16347": "|**2025-11-20**|**The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks**|Chunyang Li,...Jianfeng Ma|[2511.16347](http://arxiv.org/abs/2511.16347)|null|\n", "2511.16233": "|**2025-11-20**|**FT-NCFM: An Influence-Aware Data Distillation Framework for Efficient VLA Models**|Kewei Chen,...Mingsheng Shang|[2511.16233](http://arxiv.org/abs/2511.16233)|null|\n", "2511.16221": "|**2025-11-20**|**Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions**|Caixin Kang,...Yoichi Sato|[2511.16221](http://arxiv.org/abs/2511.16221)|null|\n", "2511.16216": "|**2025-11-20**|**FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks**|Zhen Hao Wong,...Wentao Zhang|[2511.16216](http://arxiv.org/abs/2511.16216)|null|\n", "2511.16203": "|**2025-11-20**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yuping Yan,...Yaochu Jin|[2511.16203](http://arxiv.org/abs/2511.16203)|null|\n", "2511.16201": "|**2025-11-20**|**From Performance to Understanding: A Vision for Explainable Automated Algorithm Design**|Niki van Stein,...Thomas B\u00e4ck|[2511.16201](http://arxiv.org/abs/2511.16201)|null|\n", "2511.16175": "|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Yi Yang,...Zhijie Deng|[2511.16175](http://arxiv.org/abs/2511.16175)|null|\n", "2511.17502": "|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Jun Cen,...Hao Chen|[2511.17502](http://arxiv.org/abs/2511.17502)|null|\n", "2511.17487": "|**2025-11-21**|**Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models**|Mark Endo,...Serena Yeung-Levy|[2511.17487](http://arxiv.org/abs/2511.17487)|**[link](https://web.stanford.edu/~markendo/projects/downscaling_intelligence)**|\n", "2511.17481": "|**2025-11-21**|**Counterfactual World Models via Digital Twin-conditioned Video Diffusion**|Yiqing Shen,...Mathias Unberath|[2511.17481](http://arxiv.org/abs/2511.17481)|null|\n", "2511.17448": "|**2025-11-21**|**MMT-ARD: Multimodal Multi-Teacher Adversarial Distillation for Robust Vision-Language Models**|Yuqi Li,...Yew-Soon Ong|[2511.17448](http://arxiv.org/abs/2511.17448)|null|\n", "2511.17442": "|**2025-11-21**|**REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing**|Binger Chen,...Beg\u00fcm Demir|[2511.17442](http://arxiv.org/abs/2511.17442)|**[link](https://github.com/be-chen/REMSA)**|\n", "2511.17432": "|**2025-11-21**|**SMILE: A Composite Lexical-Semantic Metric for Question-Answering Evaluation**|Shrikant Kendre,...Juan Carlos Niebles|[2511.17432](http://arxiv.org/abs/2511.17432)|null|\n", "2511.17411": "|**2025-11-21**|**SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding**|Nikolay Nikolov,...Danda Pani Paudel|[2511.17411](http://arxiv.org/abs/2511.17411)|null|\n", "2511.17384": "|**2025-11-21**|**IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation**|Yifan Li,...Yu Kong|[2511.17384](http://arxiv.org/abs/2511.17384)|null|\n", "2511.17366": "|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Yankai Fu,...Shanghang Zhang|[2511.17366](http://arxiv.org/abs/2511.17366)|null|\n", "2511.17355": "|**2025-11-21**|**UAM: A Unified Attention-Mamba Backbone of Multimodal Framework for Tumor Cell Classification**|Taixi Chen,...Nancy Guo|[2511.17355](http://arxiv.org/abs/2511.17355)|null|\n", "2511.17330": "|**2025-11-21**|**Agentic Program Verification**|Haoxin Tu,...Abhik Roychoudhury|[2511.17330](http://arxiv.org/abs/2511.17330)|null|\n", "2511.17308": "|**2025-11-21**|**SpatialGeo:Boosting Spatial Reasoning in Multimodal LLMs via Geometry-Semantics Fusion**|Jiajie Guo,...Weida Wang|[2511.17308](http://arxiv.org/abs/2511.17308)|null|\n", "2511.17300": "|**2025-11-21**|**MolSight: Optical Chemical Structure Recognition with SMILES Pretraining, Multi-Granularity Learning and Reinforcement Learning**|Wenrui Zhang,...Wenyu Liu|[2511.17300](http://arxiv.org/abs/2511.17300)|null|\n", "2511.17282": "|**2025-11-21**|**Where Culture Fades: Revealing the Cultural Gap in Text-to-Image Generation**|Chuancheng Shi,...Tat-Seng Chua|[2511.17282](http://arxiv.org/abs/2511.17282)|null|\n", "2511.17255": "|**2025-11-21**|**A Little More Like This: Text-to-Image Retrieval with Vision-Language Models Using Relevance Feedback**|Bulat Khaertdinov,...Nava Tintarev|[2511.17255](http://arxiv.org/abs/2511.17255)|null|\n", "2511.17254": "|**2025-11-21**|**Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats**|Jiaye Qian,...Sibei Yang|[2511.17254](http://arxiv.org/abs/2511.17254)|**[link](https://github.com/SooLab/AllPath)**|\n", "2511.17238": "|**2025-11-21**|**Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables**|Anshul Singh,...Abhay Kumary|[2511.17238](http://arxiv.org/abs/2511.17238)|null|\n", "2511.17209": "|**2025-11-21**|**Scaling Self-Supervised and Cross-Modal Pretraining for Volumetric CT Transformers**|Cris Claessens,...Fons van der Sommen|[2511.17209](http://arxiv.org/abs/2511.17209)|null|\n", "2511.17199": "|**2025-11-21**|**VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation**|Hanyu Zhou,...Gim Hee Lee|[2511.17199](http://arxiv.org/abs/2511.17199)|null|\n", "2511.17136": "|**2025-11-21**|**Device-Guided Music Transfer**|Manh Pham Hung,...Dong Ma|[2511.17136](http://arxiv.org/abs/2511.17136)|null|\n", "2511.21688": "|**2025-11-26**|**G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning**|Wenbo Hu,...Jiangmiao Pang|[2511.21688](http://arxiv.org/abs/2511.21688)|**[link](https://github.com/InternRobotics/G2VLM)**|\n", "2511.21663": "|**2025-11-26**|**Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models**|Naifu Zhang,...Nan Zhang|[2511.21663](http://arxiv.org/abs/2511.21663)|null|\n", "2511.21631": "|**2025-11-26**|**Qwen3-VL Technical Report**|Shuai Bai,...Ke Zhu|[2511.21631](http://arxiv.org/abs/2511.21631)|null|\n", "2511.21614": "|**2025-11-26**|**Automated Protein Motif Localization using Concept Activation Vectors in Protein Language Model Embedding Space**|Ahmad Shamail,...Claire D. McWhite|[2511.21614](http://arxiv.org/abs/2511.21614)|null|\n", "2511.21557": "|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Hui Zhou,...Shaoshuai Shi|[2511.21557](http://arxiv.org/abs/2511.21557)|null|\n", "2511.21542": "|**2025-11-26**|**$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Zhihao Zhan,...Guangrun Wang|[2511.21542](http://arxiv.org/abs/2511.21542)|null|\n", "2511.21541": "|**2025-11-26**|**Video Generation Models Are Good Latent Reward Models**|Xiaoyue Mi,...Fan Tang|[2511.21541](http://arxiv.org/abs/2511.21541)|null|\n", "2511.21523": "|**2025-11-26**|**EoS-FM: Can an Ensemble of Specialist Models act as a Generalist Feature Extractor?**|Pierre Adorni,...S\u00e9bastien Lef\u00e8vre|[2511.21523](http://arxiv.org/abs/2511.21523)|null|\n", "2511.21513": "|**2025-11-26**|**IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference**|Wanli Zhong,...Shiqi Yu|[2511.21513](http://arxiv.org/abs/2511.21513)|null|\n", "2511.21428": "|**2025-11-26**|**From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings**|Jiajie Zhang,...Alexander Kleiner|[2511.21428](http://arxiv.org/abs/2511.21428)|null|\n", "2511.21420": "|**2025-11-26**|**SAM Guided Semantic and Motion Changed Region Mining for Remote Sensing Change Captioning**|Futian Wang,...Jin Tang|[2511.21420](http://arxiv.org/abs/2511.21420)|null|\n", "2511.21397": "|**2025-11-26**|**Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis**|Jiyun Bae,...Jaeho Lee|[2511.21397](http://arxiv.org/abs/2511.21397)|null|\n", "2511.21395": "|**2025-11-26**|**Monet: Reasoning in Latent Visual Space Beyond Images and Language**|Qixun Wang,...Yisen Wang|[2511.21395](http://arxiv.org/abs/2511.21395)|null|\n", "2511.21375": "|**2025-11-26**|**Thinking With Bounding Boxes: Enhancing Spatio-Temporal Video Grounding via Reinforcement Fine-Tuning**|Xin Gu,...Sijie Zhu|[2511.21375](http://arxiv.org/abs/2511.21375)|null|\n", "2511.21339": "|**2025-11-26**|**SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding**|Tae-Min Choi,...Juyoun Park|[2511.21339](http://arxiv.org/abs/2511.21339)|null|\n", "2511.21272": "|**2025-11-26**|**Co-Training Vision Language Models for Remote Sensing Multi-task Learning**|Qingyun Li,...Junchi Yan|[2511.21272](http://arxiv.org/abs/2511.21272)|null|\n", "2511.21270": "|**2025-11-26**|**Multi-Reward GRPO for Stable and Prosodic Single-Codebook TTS LLMs at Scale**|Yicheng Zhong,...Zhisheng Wang|[2511.21270](http://arxiv.org/abs/2511.21270)|null|\n", "2511.21251": "|**2025-11-26**|**AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs**|Shuhan Xia,...Zekun Li|[2511.21251](http://arxiv.org/abs/2511.21251)|null|\n", "2511.21202": "|**2025-11-26**|**Towards an Effective Action-Region Tracking Framework for Fine-grained Video Action Recognition**|Baoli Sun,...Zhiyong Wang|[2511.21202](http://arxiv.org/abs/2511.21202)|null|\n", "2511.21192": "|**2025-11-26**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Hui Lu,...Xudong Jiang|[2511.21192](http://arxiv.org/abs/2511.21192)|null|\n", "2512.03043": "|**2025-12-02**|**OneThinker: All-in-one Reasoning Model for Image and Video**|Kaituo Feng,...Xiangyu Yue|[2512.03043](http://arxiv.org/abs/2512.03043)|**[link](https://github.com/tulerfeng/OneThinker)**|\n", "2512.02981": "|**2025-12-02**|**InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration**|Zhongyu Yang,...Wei Pang|[2512.02981](http://arxiv.org/abs/2512.02981)|null|\n", "2512.02973": "|**2025-12-02**|**Contextual Image Attack: How Visual Context Exposes Multimodal Safety Vulnerabilities**|Yuan Xiong,...Jing Shao|[2512.02973](http://arxiv.org/abs/2512.02973)|null|\n", "2512.02966": "|**2025-12-02**|**Lumos: Let there be Language Model System Certification**|Isha Chaudhary,...Gagandeep Singh|[2512.02966](http://arxiv.org/abs/2512.02966)|null|\n", "2512.02924": "|**2025-12-02**|**AutoNeural: Co-Designing Vision-Language Models for NPU Inference**|Wei Chen,...Han Yang|[2512.02924](http://arxiv.org/abs/2512.02924)|null|\n", "2512.02906": "|**2025-12-02**|**MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding**|Fan Yang,...Kaihao Zhang|[2512.02906](http://arxiv.org/abs/2512.02906)|null|\n", "2512.02902": "|**2025-12-02**|**VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling**|Weiqi Li,...Guangrun Wang|[2512.02902](http://arxiv.org/abs/2512.02902)|null|\n", "2512.02895": "|**2025-12-02**|**MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm**|Wei Chen,...Xuhan Zhu|[2512.02895](http://arxiv.org/abs/2512.02895)|null|\n", "2512.02846": "|**2025-12-02**|**Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?**|Manuel Benavent-Lledo,...Jose Garcia-Rodriguez|[2512.02846](http://arxiv.org/abs/2512.02846)|null|\n", "2512.02844": "|**2025-12-02**|**VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion**|Xinzheng Wu,...Yong Shen|[2512.02844](http://arxiv.org/abs/2512.02844)|null|\n", "2512.02835": "|**2025-12-02**|**ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning**|Yifan Li,...Yanwei Fu|[2512.02835](http://arxiv.org/abs/2512.02835)|null|\n", "2512.02834": "|**2025-12-02**|**Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**|Siyuan Yang,...Xuelong Li|[2512.02834](http://arxiv.org/abs/2512.02834)|null|\n", "2512.02814": "|**2025-12-02**|**Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control**|Yongrui Yu,...Xiaofan Zhang|[2512.02814](http://arxiv.org/abs/2512.02814)|null|\n", "2512.02787": "|**2025-12-02**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Xianchao Zeng,...Yong-Lu Li|[2512.02787](http://arxiv.org/abs/2512.02787)|null|\n", "2512.02743": "|**2025-12-02**|**Reasoning-Aware Multimodal Fusion for Hateful Video Detection**|Shuonan Yang,...Zeyu Fu|[2512.02743](http://arxiv.org/abs/2512.02743)|null|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Yuhong Zhang,...Haoqian Wang|[2512.02729](http://arxiv.org/abs/2512.02729)|null|\n", "2512.02719": "|**2025-12-02**|**Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs**|Julian Ma,...Zafeirios Fountas|[2512.02719](http://arxiv.org/abs/2512.02719)|null|\n", "2512.02715": "|**2025-12-02**|**GeoViS: Geospatially Rewarded Visual Search for Remote Sensing Visual Grounding**|Peirong Zhang,...Lei Wang|[2512.02715](http://arxiv.org/abs/2512.02715)|null|\n", "2512.02700": "|**2025-12-02**|**VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm**|Zhenkai Wu,...Xinghao Chen|[2512.02700](http://arxiv.org/abs/2512.02700)|null|\n", "2512.02697": "|**2025-12-02**|**GeoBridge: A Semantic-Anchored Multi-View Foundation Model Bridging Images and Text for Geo-Localization**|Zixuan Song,...Bo Du|[2512.02697](http://arxiv.org/abs/2512.02697)|null|\n", "2512.05112": "|**2025-12-04**|**DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation**|Dongzhi Jiang,...Hongsheng Li|[2512.05112](http://arxiv.org/abs/2512.05112)|**[link](https://github.com/CaraJ7/DraCo)**|\n", "2512.05111": "|**2025-12-04**|**ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning**|Shengyuan Ding,...Jiaqi Wang|[2512.05111](http://arxiv.org/abs/2512.05111)|null|\n", "2512.05107": "|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Feng Xu,...Benjamin Busam|[2512.05107](http://arxiv.org/abs/2512.05107)|null|\n", "2512.05103": "|**2025-12-04**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Xiaochuang Han,...Emily Dinan|[2512.05103](http://arxiv.org/abs/2512.05103)|null|\n", "2512.05091": "|**2025-12-04**|**Visual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark**|Haobo Yuan,...Ming-Hsuan Yang|[2512.05091](http://arxiv.org/abs/2512.05091)|**[link](https://harboryuan.github.io/visual-reasoning-tracer)**|\n", "2512.04981": "|**2025-12-04**|**Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models**|NaHyeon Park,...Hyunjung Shim|[2512.04981](http://arxiv.org/abs/2512.04981)|**[link](https://fairpro-t2i.github.io)**|\n", "2512.04952": "|**2025-12-04**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization**|Yicheng Liu,...Hang Zhao|[2512.04952](http://arxiv.org/abs/2512.04952)|null|\n", "2512.04895": "|**2025-12-04**|**Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems**|M Zeeshan,...Saud Satti|[2512.04895](http://arxiv.org/abs/2512.04895)|null|\n", "2512.04785": "|**2025-12-04**|**ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications**|Eranga Bandara,...Nilaan Loganathan|[2512.04785](http://arxiv.org/abs/2512.04785)|null|\n", "2512.04763": "|**2025-12-04**|**MemLoRA: Distilling Expert Adapters for On-Device Memory Systems**|Massimo Bini,...Taha Ceritli|[2512.04763](http://arxiv.org/abs/2512.04763)|null|\n", "2512.04733": "|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Yihong Tang,...Chengzhong Xu|[2512.04733](http://arxiv.org/abs/2512.04733)|null|\n", "2512.04728": "|**2025-12-04**|**Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild**|Yigui Feng,...Jie Liu|[2512.04728](http://arxiv.org/abs/2512.04728)|null|\n", "2512.04686": "|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Yipu Wang,...Xiaolong Zheng|[2512.04686](http://arxiv.org/abs/2512.04686)|null|\n", "2512.04678": "|**2025-12-04**|**Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation**|Yunhong Lu,...Min Zhang|[2512.04678](http://arxiv.org/abs/2512.04678)|null|\n", "2512.04643": "|**2025-12-04**|**SEASON: Mitigating Temporal Hallucination in Video Large Language Models via Self-Diagnostic Contrastive Decoding**|Chang-Hsun Wu,...Yu-Chiang Frank Wang|[2512.04643](http://arxiv.org/abs/2512.04643)|null|\n", "2512.04632": "|**2025-12-04**|**Turbo-Muon: Accelerating Orthogonality-Based Optimization with Pre-Conditioning**|Thibaut Boissin,...Mathieu Serrurier|[2512.04632](http://arxiv.org/abs/2512.04632)|null|\n", "2512.04618": "|**2025-12-04**|**Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning**|Mohamed Baha Ben Ticha,...Blaise Yvert|[2512.04618](http://arxiv.org/abs/2512.04618)|null|\n", "2512.04599": "|**2025-12-04**|**Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot**|Sheng Hang,...Shuo Wang|[2512.04599](http://arxiv.org/abs/2512.04599)|null|\n", "2512.04597": "|**2025-12-04**|**When Robots Should Say \"I Don't Know\": Benchmarking Abstention in Embodied Question Answering**|Tao Wu,...Jianfei Yang|[2512.04597](http://arxiv.org/abs/2512.04597)|null|\n", "2512.04585": "|**2025-12-04**|**SAM3-I: Segment Anything with Instructions**|Jingjing Li,...Li Cheng|[2512.04585](http://arxiv.org/abs/2512.04585)|null|\n", "2512.07833": "|**2025-12-08**|**Relational Visual Similarity**|Thao Nguyen,...Yuheng Li|[2512.07833](http://arxiv.org/abs/2512.07833)|**[link](https://thaoshibe.github.io/relsim)**|\n", "2512.07564": "|**2025-12-08**|**Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models**|Kassoum Sanogo,...Renzo Ardiccioni|[2512.07564](http://arxiv.org/abs/2512.07564)|**[link](https://github.com/kassoumsanogo1/self-correcting-vlm-re-Attention.git)**|\n", "2512.07452": "|**2025-12-08**|**From Show Programmes to Data: Designing a Workflow to Make Performing Arts Ephemera Accessible Through Language Models**|Clarisse Bardiot,...Jeanne Fras|[2512.07452](http://arxiv.org/abs/2512.07452)|null|\n", "2512.07360": "|**2025-12-08**|**Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation**|Qiming Huang,...Jianbo Jiao|[2512.07360](http://arxiv.org/abs/2512.07360)|null|\n", "2512.07344": "|**2025-12-08**|**Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding**|Shengyuan Ye,...Xu Chen|[2512.07344](http://arxiv.org/abs/2512.07344)|null|\n", "2512.07302": "|**2025-12-08**|**Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts**|Mingning Guo,...Chao Tao|[2512.07302](http://arxiv.org/abs/2512.07302)|null|\n", "2512.07276": "|**2025-12-08**|**Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery**|Mai Tsujimoto,...Naoto Yokoya|[2512.07276](http://arxiv.org/abs/2512.07276)|null|\n", "2512.07273": "|**2025-12-08**|**RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation**|Zhi Rao,...Jun Wan|[2512.07273](http://arxiv.org/abs/2512.07273)|null|\n", "2512.07245": "|**2025-12-08**|**Zero-Shot Textual Explanations via Translating Decision-Critical Features**|Toshinori Yamauchi,...Kazuhiko Kawamoto|[2512.07245](http://arxiv.org/abs/2512.07245)|null|\n", "2512.07234": "|**2025-12-08**|**Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models**|Biao Chen,...Yuchen Wang|[2512.07234](http://arxiv.org/abs/2512.07234)|null|\n", "2512.07222": "|**2025-12-08**|**Pay Less Attention to Function Words for Free Robustness of Vision-Language Models**|Qiwei Tian,...Chao Shen|[2512.07222](http://arxiv.org/abs/2512.07222)|null|\n", "2512.07215": "|**2025-12-08**|**VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation**|Md Selim Sarowar,...Sungho Kim|[2512.07215](http://arxiv.org/abs/2512.07215)|null|\n", "2512.07203": "|**2025-12-08**|**MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning**|Xuhui Zheng,...Yichao Wu|[2512.07203](http://arxiv.org/abs/2512.07203)|null|\n", "2512.07177": "|**2025-12-08**|**Using Vision-Language Models as Proxies for Social Intelligence in Human-Robot Interaction**|Fanjun Bu,...Wendy Ju|[2512.07177](http://arxiv.org/abs/2512.07177)|null|\n", "2512.07155": "|**2025-12-08**|**CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics**|Dahyeon Kye,...Jihyong Oh|[2512.07155](http://arxiv.org/abs/2512.07155)|**[link](https://cmlab-korea.github.io/CHIMERA/)**|\n", "2512.07141": "|**2025-12-08**|**Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models**|Fenghua Weng,...Wenjie Wang|[2512.07141](http://arxiv.org/abs/2512.07141)|null|\n", "2512.07136": "|**2025-12-08**|**A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning**|Siyang Jiang,...Guoliang Xing|[2512.07136](http://arxiv.org/abs/2512.07136)|null|\n", "2512.07132": "|**2025-12-08**|**DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning**|Nithin Sivakumaran,...Mohit Bansal|[2512.07132](http://arxiv.org/abs/2512.07132)|**[link](https://github.com/nsivaku/dart)**|\n", "2512.07128": "|**2025-12-08**|**MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP**|Chau Truong,...Dung D. Le|[2512.07128](http://arxiv.org/abs/2512.07128)|null|\n", "2512.06883": "|**2025-12-07**|**Structural and Disentangled Adaptation of Large Vision Language Models for Multimodal Recommendation**|Zhongtao Rao,...Nan Tang|[2512.06883](http://arxiv.org/abs/2512.06883)|null|\n", "2512.10942": "|**2025-12-11**|**VL-JEPA: Joint Embedding Predictive Architecture for Vision-language**|Delong Chen,...Pascale Fung|[2512.10942](http://arxiv.org/abs/2512.10942)|null|\n", "2512.10932": "|**2025-12-11**|**BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models**|Shengao Wang,...Boqing Gong|[2512.10932](http://arxiv.org/abs/2512.10932)|null|\n", "2512.10894": "|**2025-12-11**|**DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance**|Peiying Zhang,...Difan Liu|[2512.10894](http://arxiv.org/abs/2512.10894)|**[link](https://intchous.github.io/DuetSVG-site)**|\n", "2512.10888": "|**2025-12-11**|**PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction**|Brandon Smock,...Maury Courtland|[2512.10888](http://arxiv.org/abs/2512.10888)|null|\n", "2512.10867": "|**2025-12-12**|**From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models**|Zongzhao Li,...Wenbing Huang|[2512.10867](http://arxiv.org/abs/2512.10867)|null|\n", "2512.10719": "|**2025-12-11**|**SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving**|Peizheng Li,...Andreas Zell|[2512.10719](http://arxiv.org/abs/2512.10719)|null|\n", "2512.10691": "|**2025-12-11**|**Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning**|Benjamin Gundersen,...Michael Krauthammer|[2512.10691](http://arxiv.org/abs/2512.10691)|null|\n", "2512.10619": "|**2025-12-11**|**DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM**|Qintong Zhang,...Wentao Zhang|[2512.10619](http://arxiv.org/abs/2512.10619)|null|\n", "2512.10596": "|**2025-12-11**|**Beyond Pixels: A Training-Free, Text-to-Text Framework for Remote Sensing Image Retrieval**|J. Xiao,...M. Prasad|[2512.10596](http://arxiv.org/abs/2512.10596)|null|\n", "2512.10414": "|**2025-12-11**|**Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention**|Yang Yu,...Xiaomeng Li|[2512.10414](http://arxiv.org/abs/2512.10414)|null|\n", "2512.10384": "|**2025-12-11**|**Towards Fine-Grained Recognition with Large Visual Language Models: Benchmark and Optimization Strategies**|Cong Pang,...Xin Lou|[2512.10384](http://arxiv.org/abs/2512.10384)|null|\n", "2512.10342": "|**2025-12-11**|**CoSPlan: Corrective Sequential Planning via Scene Graph Incremental Updates**|Shresth Grover,...Yogesh S Rawat|[2512.10342](http://arxiv.org/abs/2512.10342)|null|\n", "2512.10336": "|**2025-12-11**|**Multilingual VLM Training: Adapting an English-Trained VLM to French**|Jules Lahmi,...Alexis Roger|[2512.10336](http://arxiv.org/abs/2512.10336)|null|\n", "2512.10316": "|**2025-12-11**|**ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation**|Khang Le,...Hien Van Nguyen|[2512.10316](http://arxiv.org/abs/2512.10316)|null|\n", "2512.10300": "|**2025-12-11**|**Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules**|Yanbei Jiang,...Krista A. Ehinger|[2512.10300](http://arxiv.org/abs/2512.10300)|null|\n", "2512.10244": "|**2025-12-11**|**Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective**|Tian Liu,...Shu Kong|[2512.10244](http://arxiv.org/abs/2512.10244)|**[link](https://tian1327.github.io/SWIFT)**|\n", "2512.10067": "|**2025-12-10**|**Independent Density Estimation**|Jiahao Liu,...Jiahao Liu|[2512.10067](http://arxiv.org/abs/2512.10067)|null|\n", "2512.10046": "|**2025-12-10**|**SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration**|Yan Zhuang,...Tianmin Shu|[2512.10046](http://arxiv.org/abs/2512.10046)|null|\n", "2512.09924": "|**2025-12-11**|**ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning**|Xinyu Liu,...Yike Guo|[2512.09924](http://arxiv.org/abs/2512.09924)|**[link](https://github.com/Liuxinyv/ReViSE))**|\n", "2512.09907": "|**2025-12-10**|**VisualActBench: Can VLMs See and Act like a Human?**|Daoan Zhang,...Jiebo Luo|[2512.09907](http://arxiv.org/abs/2512.09907)|null|\n", "2512.11567": "|**2025-12-12**|**Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet**|Mevl\u00fct Bagci,...Alexander Mehler|[2512.11567](http://arxiv.org/abs/2512.11567)|null|\n", "2512.11490": "|**2025-12-12**|**VLM2GeoVec: Toward Universal Multimodal Embeddings for Remote Sensing**|Emanuel S\u00e1nchez Aimar,...Michael Felsberg|[2512.11490](http://arxiv.org/abs/2512.11490)|null|\n", "2512.11399": "|**2025-12-12**|**Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction**|Galann Pennec,...Nancy F. Chen|[2512.11399](http://arxiv.org/abs/2512.11399)|null|\n", "2512.11393": "|**2025-12-12**|**The N-Body Problem: Parallel Execution from Single-Person Egocentric Video**|Zhifan Zhu,...Dima Damen|[2512.11393](http://arxiv.org/abs/2512.11393)|**[link](https://zhifanzhu.github.io/ego-nbody)**|\n", "2512.11350": "|**2025-12-12**|**Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture**|Tanu Singh,...Long T. Truong|[2512.11350](http://arxiv.org/abs/2512.11350)|null|\n", "2512.11315": "|**2025-12-12**|**Benchmarking the Generality of Vision-Language-Action Models**|Pranav Guruprasad,...Yangyue Wang|[2512.11315](http://arxiv.org/abs/2512.11315)|null|\n", "2512.11275": "|**2025-12-12**|**Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing**|Suchang Chen,...Daqiang Guo|[2512.11275](http://arxiv.org/abs/2512.11275)|null|\n", "2512.11218": "|**2025-12-12**|**Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy**|Kechun Xu,...Yue Wang|[2512.11218](http://arxiv.org/abs/2512.11218)|null|\n", "2512.11167": "|**2025-12-11**|**Image Tiling for High-Resolution Reasoning: Balancing Local Detail with Global Context**|Anatole Jacquin de Margerie,...Irina Rish|[2512.11167](http://arxiv.org/abs/2512.11167)|null|\n", "2512.11109": "|**2025-12-11**|**Limits and Gains of Test-Time Scaling in Vision-Language Reasoning**|Mohammadjavad Ahmadpour,...Mahdieh Soleymani Baghshah|[2512.11109](http://arxiv.org/abs/2512.11109)|null|\n", "2512.11098": "|**2025-12-11**|**Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing Scene Description**|Nazanin Mahjourian,...Vinh Nguyen|[2512.11098](http://arxiv.org/abs/2512.11098)|null|\n", "2512.11061": "|**2025-12-11**|**VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation**|Felix O'Mahony,...Ayush Tewari|[2512.11061](http://arxiv.org/abs/2512.11061)|**[link](https://felixomahony.github.io/vdaworld/)**|\n", "2512.11060": "|**2025-12-11**|**Synthetic Vasculature and Pathology Enhance Vision-Language Model Reasoning**|Chenjun Li,...Johannes C. Paetzold|[2512.11060](http://arxiv.org/abs/2512.11060)|null|\n", "2512.15713": "|**2025-12-17**|**DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models**|Lunbin Zeng,...Xinggang Wang|[2512.15713](http://arxiv.org/abs/2512.15713)|null|\n", "2512.15701": "|**2025-12-17**|**VLIC: Vision-Language Models As Perceptual Judges for Human-Aligned Image Compression**|Kyle Sargent,...Jason Zhang|[2512.15701](http://arxiv.org/abs/2512.15701)|null|\n", "2512.15649": "|**2025-12-17**|**VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?**|Hongbo Zhao,...Zhaoxiang Zhang|[2512.15649](http://arxiv.org/abs/2512.15649)|null|\n", "2512.15372": "|**2025-12-17**|**Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models**|Mikel Williams-Lekuona,...Georgina Cosma|[2512.15372](http://arxiv.org/abs/2512.15372)|null|\n", "2512.15310": "|**2025-12-17**|**SynthSeg-Agents: Multi-Agent Synthetic Data Generation for Zero-Shot Weakly Supervised Semantic Segmentation**|Wangyu Wu,...Jimin Xiao|[2512.15310](http://arxiv.org/abs/2512.15310)|null|\n", "2512.15254": "|**2025-12-17**|**Assessing the Visual Enumeration Abilities of Specialized Counting Architectures and Vision-Language Models**|Kuinan Hou,...Alberto Testolin|[2512.15254](http://arxiv.org/abs/2512.15254)|null|\n", "2512.15249": "|**2025-12-17**|**Intersectional Fairness in Vision-Language Models for Medical Image Disease Classification**|Yupeng Zhang,...Jinman Kim|[2512.15249](http://arxiv.org/abs/2512.15249)|null|\n", "2512.15160": "|**2025-12-17**|**EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence**|Jiaxu Wan,...Yifan Yang|[2512.15160](http://arxiv.org/abs/2512.15160)|null|\n", "2512.14944": "|**2025-12-16**|**Puzzle Curriculum GRPO for Vision-Centric Reasoning**|Ahmadreza Jeddi,...Radek Grzeszczuk|[2512.14944](http://arxiv.org/abs/2512.14944)|**[link](https://pcgrpo.github.io)**|\n", "2512.14926": "|**2025-12-16**|**Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models**|George-Andrei Dima,...Dumitru-Clementin Cercel|[2512.14926](http://arxiv.org/abs/2512.14926)|null|\n", "2512.14661": "|**2025-12-16**|**Focus: A Streaming Concentration Architecture for Efficient Vision-Language Models**|Chiyue Wei,...Yiran Chen|[2512.14661](http://arxiv.org/abs/2512.14661)|null|\n", "2512.14442": "|**2025-12-16**|**A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning**|Zixin Zhang,...Ying-Cong Chen|[2512.14442](http://arxiv.org/abs/2512.14442)|null|\n", "2512.14420": "|**2025-12-16**|**DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning**|Nakamasa Inoue,...Yusuke Sekikawa|[2512.14420](http://arxiv.org/abs/2512.14420)|null|\n", "2512.14336": "|**2025-12-16**|**Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure**|Jooyeol Yun,...Jaegul Choo|[2512.14336](http://arxiv.org/abs/2512.14336)|null|\n", "2512.14312": "|**2025-12-16**|**From YOLO to VLMs: Advancing Zero-Shot and Few-Shot Detection of Wastewater Treatment Plants Using Satellite Imagery in MENA Region**|Akila Premarathna,...Garcia Andarcia Mariangel|[2512.14312](http://arxiv.org/abs/2512.14312)|null|\n", "2512.14770": "|**2025-12-16**|**Improving VQA Reliability: A Dual-Assessment Approach with Self-Reflection and Cross-Model Verification**|Xixian Wu,...Longwen Gao|[2512.14770](http://arxiv.org/abs/2512.14770)|null|\n", "2512.14177": "|**2025-12-16**|**Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes**|Joseph Hoche,...Gianni Franchi|[2512.14177](http://arxiv.org/abs/2512.14177)|null|\n", "2512.14130": "|**2025-12-16**|**UIXPOSE: Mobile Malware Detection via Intention-Behaviour Discrepancy Analysis**|Amirmohammad Pasdar,...Van-Thuan Pham|[2512.14130](http://arxiv.org/abs/2512.14130)|null|\n", "2512.14102": "|**2025-12-16**|**Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries**|Emanuele Mezzi,...Maarten Kruithof|[2512.14102](http://arxiv.org/abs/2512.14102)|null|\n", "2512.14068": "|**2025-12-16**|**SDAR-VL: Stable and Efficient Block-wise Diffusion for Vision-Language Understanding**|Shuang Cheng,...Bowen Zhou|[2512.14068](http://arxiv.org/abs/2512.14068)|null|\n"}, "VLA": {"2509.21243": "|**2025-09-25**|**RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models**|Jiyeon Koo,...Andrew Jaeyong Choi|[2509.21243](http://arxiv.org/abs/2509.21243)|null|\n", "2509.20109": "|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Pengxiang Li,...Xianpeng Lang|[2509.20109](http://arxiv.org/abs/2509.20109)|null|\n", "2509.19870": "|**2025-09-24**|**FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models**|Xin Wang,...Yu-Gang Jiang|[2509.19870](http://arxiv.org/abs/2509.19870)|null|\n", "2509.19752": "|**2025-09-24**|**Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training**|Rushuai Yang,...Yi Chen|[2509.19752](http://arxiv.org/abs/2509.19752)|null|\n", "2509.19571": "|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Sacha Morin,...Liam Paull|[2509.19571](http://arxiv.org/abs/2509.19571)|**[link](https://montrealrobotics.ca/agentic-scene-policies.github.io/)**|\n", "2509.19480": "|**2025-09-23**|**OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation**|Noriaki Hirose,...Sergey Levine|[2509.19480](http://arxiv.org/abs/2509.19480)|null|\n", "2509.19012": "|**2025-09-25**|**Pure Vision Language Action (VLA) Models: A Comprehensive Survey**|Dapeng Zhang,...Qingguo Zhou|[2509.19012](http://arxiv.org/abs/2509.19012)|null|\n", "2509.18953": "|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Hanqing Liu,...Wen Yao|[2509.18953](http://arxiv.org/abs/2509.18953)|null|\n", "2509.18428": "|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Bahey Tharwat,...Ian Reid|[2509.18428](http://arxiv.org/abs/2509.18428)|null|\n", "2509.15968": "|**2025-09-19**|**CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine**|Shiyu Fang,...Jian Sun|[2509.15968](http://arxiv.org/abs/2509.15968)|null|\n", "2509.15937": "|**2025-09-19**|**A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning**|Shaopeng Zhai,...Jiangmiao Pang|[2509.15937](http://arxiv.org/abs/2509.15937)|null|\n", "2509.15212": "|**2025-09-18**|**RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation**|Yuming Jiang,...Xin Li|[2509.15212](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|\n", "2509.14932": "|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Tobias J\u00fclg,...Florian Walter|[2509.14932](http://arxiv.org/abs/2509.14932)|null|\n", "2509.14889": "|**2025-09-18**|**CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human**|Nan Sun,...Huaping Liu|[2509.14889](http://arxiv.org/abs/2509.14889)|null|\n", "2509.14687": "|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Cong Tai,...Tao Shen|[2509.14687](http://arxiv.org/abs/2509.14687)|null|\n", "2509.18183": "|**2025-09-18**|**VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation**|Jinyue Bian,...Anzhou Hou|[2509.18183](http://arxiv.org/abs/2509.18183)|null|\n", "2509.14630": "|**2025-09-18**|**Toward Embodiment Equivariant Vision-Language-Action Policy**|Anzhe Chen,...Yue Wang|[2509.14630](http://arxiv.org/abs/2509.14630)|null|\n", "2509.14143": "|**2025-09-17**|**CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping**|Zijian An,...Lifeng Zhou|[2509.14143](http://arxiv.org/abs/2509.14143)|null|\n", "2509.14138": "|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Ran Yang,...Yiming Feng|[2509.14138](http://arxiv.org/abs/2509.14138)|null|\n", "2509.14117": "|**2025-09-22**|**GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model**|Ali Abouzeid,...Dezhen Song|[2509.14117](http://arxiv.org/abs/2509.14117)|null|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo,...Ziwei Wang|[2509.22643](http://arxiv.org/abs/2509.22643)|null|\n", "2509.22441": "|**2025-09-26**|**UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation**|Zhangyuan Wang,...Dixia Fan|[2509.22441](http://arxiv.org/abs/2509.22441)|null|\n", "2509.22407": "|**2025-09-26**|**EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer**|Zhehao Dong,...Guan Huang|[2509.22407](http://arxiv.org/abs/2509.22407)|null|\n", "2509.22199": "|**2025-09-29**|**MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training**|Haoyun Li,...Xingang Wang|[2509.22199](http://arxiv.org/abs/2509.22199)|null|\n", "2509.22195": "|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Asher J. Hancock,...Anirudha Majumdar|[2509.22195](http://arxiv.org/abs/2509.22195)|null|\n", "2509.22093": "|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Xiaohuan Pei,...Chang Xu|[2509.22093](http://arxiv.org/abs/2509.22093)|null|\n", "2509.21986": "|**2025-09-26**|**Developing Vision-Language-Action Model from Egocentric Videos**|Tomoya Yoshida,...Shinsuke Mori|[2509.21986](http://arxiv.org/abs/2509.21986)|null|\n", "2509.21354": "|**2025-09-20**|**KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache**|Wanshun Xu,...Long Zhuang|[2509.21354](http://arxiv.org/abs/2509.21354)|null|\n", "2509.25032": "|**2025-09-29**|**AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation**|Ryosuke Takanami,...Tetsuya Ogata|[2509.25032](http://arxiv.org/abs/2509.25032)|null|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Eric Hannus,...Ville Kyrki|[2509.24768](http://arxiv.org/abs/2509.24768)|null|\n", "2509.24559": "|**2025-09-29**|**Emergent World Representations in OpenVLA**|Marco Molinari,...Omar G. Younis|[2509.24559](http://arxiv.org/abs/2509.24559)|null|\n", "2509.24524": "|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Zhihao Wang,...Xianyuan Zhan|[2509.24524](http://arxiv.org/abs/2509.24524)|null|\n", "2509.23931": "|**2025-09-28**|**AutoPrune: Each Complexity Deserves a Pruning Policy**|Hanshi Wang,...Zhipeng Zhang|[2509.23931](http://arxiv.org/abs/2509.23931)|null|\n", "2509.23823": "|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Tian Nian,...Bingshan Hu|[2509.23823](http://arxiv.org/abs/2509.23823)|**[link](https://github.com/Tian-Nian/control_your_robot)**|\n", "2509.23655": "|**2025-09-28**|**Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models**|Rokas Bendikas,...Pietro Mazzaglia|[2509.23655](http://arxiv.org/abs/2509.23655)|null|\n", "2509.23224": "|**2025-09-27**|**Leave No Observation Behind: Real-time Correction for VLA Action Chunks**|Kohei Sendai,...Yusuke Iwasawa|[2509.23224](http://arxiv.org/abs/2509.23224)|null|\n", "2509.23121": "|**2025-09-27**|**Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges**|Shuai Li,...Zhibo Pang|[2509.23121](http://arxiv.org/abs/2509.23121)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.25966": "|**2025-09-30**|**MUVLA: Learning to Explore Object Navigation via Map Understanding**|Peilong Han,...Jianye Hao|[2509.25966](http://arxiv.org/abs/2509.25966)|null|\n", "2509.25746": "|**2025-09-30**|**TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses**|Shuaijun Wang,...Yangwei You|[2509.25746](http://arxiv.org/abs/2509.25746)|null|\n", "2509.25718": "|**2025-09-30**|**VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning**|Si-Cheng Wang,...Zeng-Guang Hou|[2509.25718](http://arxiv.org/abs/2509.25718)|null|\n", "2509.25681": "|**2025-09-30**|**dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought**|Junjie Wen,...Yi Xu|[2509.25681](http://arxiv.org/abs/2509.25681)|null|\n", "2509.26251": "|**2025-09-30**|**Seeing Space and Motion: Enhancing Latent Actions with Spatial and Dynamic Awareness for VLA**|Zhejia Cai,...Ruqi Huang|[2509.26251](http://arxiv.org/abs/2509.26251)|null|\n", "2510.01711": "|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim,...Jinwoo Shin|[2510.01711](http://arxiv.org/abs/2510.01711)|null|\n", "2510.01642": "|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin,...Bihan Wen|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|\n", "2510.01623": "|**2025-10-02**|**VLA-R1: Enhancing Reasoning in Vision-Language-Action Models**|Angen Ye,...Zheng Zhu|[2510.01623](http://arxiv.org/abs/2510.01623)|null|\n", "2510.01389": "|**2025-10-01**|**INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models**|Ulas Berk Karli,...Tesca FItzgerald|[2510.01389](http://arxiv.org/abs/2510.01389)|null|\n", "2510.01068": "|**2025-10-01**|**Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition**|Jiahang Cao,...Andrew F. Luo|[2510.01068](http://arxiv.org/abs/2510.01068)|**[link](https://sagecao1125.github.io/GPC-Site/)**|\n", "2510.00695": "|**2025-10-02**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Myungkyu Koo,...Jinwoo Shin|[2510.00695](http://arxiv.org/abs/2510.00695)|**[link](https://myungkyukoo.github.io/hamlet/)**|\n", "2510.00600": "|**2025-10-01**|**Hybrid Training for Vision-Language-Action Models**|Pietro Mazzaglia,...Daniel Dijkman|[2510.00600](http://arxiv.org/abs/2510.00600)|null|\n", "2510.00406": "|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Hengtao Li,...Weihua Su|[2510.00406](http://arxiv.org/abs/2510.00406)|null|\n", "2510.03142": "|**2025-10-03**|**MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning**|Tianyu Xu,...He Wang|[2510.03142](http://arxiv.org/abs/2510.03142)|**[link](https://pku-epic.github.io/MM-Nav-Web/)**|\n", "2510.04898": "|**2025-10-06**|**HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks**|Zheng Xiong,...Shimon Whiteson|[2510.04898](http://arxiv.org/abs/2510.04898)|null|\n", "2510.04246": "|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Huiwon Jang,...Jinwoo Shin|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|\n", "2510.04041": "|**2025-10-05**|**SITCOM: Scaling Inference-Time COMpute for VLAs**|Ayudh Saxena,...Esha Pahwa|[2510.04041](http://arxiv.org/abs/2510.04041)|null|\n", "2510.03896": "|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Mingyu Liu,...Chunhua Shen|[2510.03896](http://arxiv.org/abs/2510.03896)|null|\n", "2510.03895": "|**2025-10-04**|**NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation**|Zheng Huang,...Chunhua Shen|[2510.03895](http://arxiv.org/abs/2510.03895)|null|\n", "2510.03827": "|**2025-10-04**|**LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization**|Xueyang Zhou,...Lichao Sun|[2510.03827](http://arxiv.org/abs/2510.03827)|null|\n", "2510.03342": "|**2025-10-02**|**Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer**|Abbas Abdolmaleki,...Yuxiang Zhou|[2510.03342](http://arxiv.org/abs/2510.03342)|null|\n", "2510.06207": "|**2025-10-07**|**EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model**|Zefu Lin,...Zhaoxiang Zhang|[2510.06207](http://arxiv.org/abs/2510.06207)|**[link](https://anonymous.4open.science/w/Embodied-Coder/)**|\n", "2510.05681": "|**2025-10-07**|**Verifier-free Test-Time Sampling for Vision Language Action Models**|Suhyeok Jang,...Jinwoo Shin|[2510.05681](http://arxiv.org/abs/2510.05681)|null|\n", "2510.05580": "|**2025-10-07**|**MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption**|Chen Li,...Marios Savvides|[2510.05580](http://arxiv.org/abs/2510.05580)|null|\n", "2510.07134": "|**2025-10-08**|**TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking**|Jiahang Liu,...He Wang|[2510.07134](http://arxiv.org/abs/2510.07134)|**[link](https://pku-epic.github.io/TrackVLA-plus-plus-Web/)**|\n", "2510.07077": "|**2025-10-08**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Kento Kawaharazuka,...Yuke Zhu|[2510.07077](http://arxiv.org/abs/2510.07077)|**[link](https://vla-survey.github.io)**|\n", "2510.07067": "|**2025-10-08**|**Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models**|Daria Pugacheva,...Elena Tutubalina|[2510.07067](http://arxiv.org/abs/2510.07067)|null|\n", "2510.06710": "|**2025-10-08**|**RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training**|Hongzhi Zang,...Yu Wang|[2510.06710](http://arxiv.org/abs/2510.06710)|**[link](https://github.com/RLinf/RLinf)**|\n", "2510.08464": "|**2025-10-09**|**Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered**|Jason Jabbour,...Shayegan Omidshafiei|[2510.08464](http://arxiv.org/abs/2510.08464)|null|\n", "2510.07869": "|**2025-10-15**|**USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots**|Junwen Gu,...Zhengxing Wu|[2510.07869](http://arxiv.org/abs/2510.07869)|**[link](https://vincentgu2000.github.io/u0project/)**|\n", "2510.07778": "|**2025-10-09**|**IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction**|Yandu Chen,...Liqiang Nie|[2510.07778](http://arxiv.org/abs/2510.07778)|null|\n", "2510.07730": "|**2025-10-09**|**DEAS: DEtached value learning with Action Sequence for Scalable Offline RL**|Changyeon Kim,...Yuke Zhu|[2510.07730](http://arxiv.org/abs/2510.07730)|**[link](https://changyeon.site/deas)**|\n", "2510.09607": "|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Shaoqi Dong,...Caifeng Shan|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|\n", "2510.09507": "|**2025-10-10**|**PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs**|Zixin Zhang,...Ying-Cong Chen|[2510.09507](http://arxiv.org/abs/2510.09507)|null|\n", "2510.09269": "|**2025-10-10**|**Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects**|Zirun Zhou,...Jingfeng Zhang|[2510.09269](http://arxiv.org/abs/2510.09269)|null|\n", "2510.11660": "|**2025-10-14**|**ManiAgent: An Agentic Framework for General Robotic Manipulation**|Yi Yang,...Xudong Liu|[2510.11660](http://arxiv.org/abs/2510.11660)|null|\n", "2510.11027": "|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Ganlin Yang,...Zhi Hou|[2510.11027](http://arxiv.org/abs/2510.11027)|null|\n", "2510.10975": "|**2025-10-14**|**RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model**|Mingtong Dai,...Xinyu Wu|[2510.10975](http://arxiv.org/abs/2510.10975)|null|\n", "2510.10932": "|**2025-10-13**|**TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models**|Zonghuan Xu,...Yu-Gang Jiang|[2510.10932](http://arxiv.org/abs/2510.10932)|null|\n", "2510.10274": "|**2025-10-11**|**X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model**|Jinliang Zheng,...Xianyuan Zhan|[2510.10274](http://arxiv.org/abs/2510.10274)|null|\n", "2510.10181": "|**2025-10-11**|**Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback**|Shaokai Wu,...Hongtao Lu|[2510.10181](http://arxiv.org/abs/2510.10181)|null|\n", "2510.09976": "|**2025-10-11**|**Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models**|Mingyang Lyu,...Yi Zeng|[2510.09976](http://arxiv.org/abs/2510.09976)|null|\n", "2510.09667": "|**2025-10-08**|**OmniSAT: Compact Action Token, Faster Auto Regression**|Huaihai Lyu,...Changsheng Xu|[2510.09667](http://arxiv.org/abs/2510.09667)|null|\n", "2510.12796": "|**2025-10-14**|**DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving**|Yingyan Li,...Zhaoxiang Zhang|[2510.12796](http://arxiv.org/abs/2510.12796)|null|\n", "2510.12710": "|**2025-10-14**|**Reflection-Based Task Adaptation for Self-Improving VLA**|Baicheng Li,...Hongbin Zha|[2510.12710](http://arxiv.org/abs/2510.12710)|null|\n", "2510.12276": "|**2025-10-17**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Fuhao Li,...Haoang Li|[2510.12276](http://arxiv.org/abs/2510.12276)|null|\n", "2510.13778": "|**2025-10-15**|**InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy**|Xinyi Chen,...Yangkun Zhu|[2510.13778](http://arxiv.org/abs/2510.13778)|null|\n", "2510.13626": "|**2025-10-15**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Senyu Fei,...Xipeng Qiu|[2510.13626](http://arxiv.org/abs/2510.13626)|null|\n", "2510.13375": "|**2025-10-15**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Tianyuan Yuan,...Hang Zhao|[2510.13375](http://arxiv.org/abs/2510.13375)|null|\n", "2510.13237": "|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Haochuan Xu,...Jingfeng Zhang|[2510.13237](http://arxiv.org/abs/2510.13237)|null|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Ankit Goyal,...Fabio Ramos|[2510.13054](http://arxiv.org/abs/2510.13054)|null|\n", "2510.14968": "|**2025-10-16**|**RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks**|Mingxuan Yan,...Jiachen Li|[2510.14968](http://arxiv.org/abs/2510.14968)|null|\n", "2510.14952": "|**2025-10-17**|**From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance**|Zhe Li,...Chang Xu|[2510.14952](http://arxiv.org/abs/2510.14952)|null|\n", "2510.14902": "|**2025-10-16**|**VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation**|Han Zhao,...Donglin Wang|[2510.14902](http://arxiv.org/abs/2510.14902)|null|\n", "2510.14836": "|**2025-10-16**|**QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models**|Yixuan Li,...Haoran Li|[2510.14836](http://arxiv.org/abs/2510.14836)|null|\n", "2510.14300": "|**2025-10-16**|**Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning**|Weijie Shen,...Yao Mu|[2510.14300](http://arxiv.org/abs/2510.14300)|null|\n", "2510.15446": "|**2025-10-17**|**VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving**|Ziang Guo,...Zufeng Zhang|[2510.15446](http://arxiv.org/abs/2510.15446)|null|\n", "2510.17640": "|**2025-10-24**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Yuquan Xue,...Ziwei Wang|[2510.17640](http://arxiv.org/abs/2510.17640)|null|\n", "2510.17439": "|**2025-10-20**|**From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors**|Zhengshen Zhang,...Pan Zhou|[2510.17439](http://arxiv.org/abs/2510.17439)|**[link](https://falcon-vla.github.io/)**|\n", "2510.17369": "|**2025-10-20**|**Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots**|Haochen Su,...Josie Hughes|[2510.17369](http://arxiv.org/abs/2510.17369)|null|\n", "2510.17148": "|**2025-10-21**|**DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment**|Yu Gao,...Wang Jijun|[2510.17148](http://arxiv.org/abs/2510.17148)|null|\n", "2510.17111": "|**2025-10-23**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Weifan Guan,...Jian Cheng|[2510.17111](http://arxiv.org/abs/2510.17111)|null|\n", "2510.16617": "|**2025-10-18**|**MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation**|Ruihan Zhao,...Ufuk Topcu|[2510.16617](http://arxiv.org/abs/2510.16617)|null|\n", "2510.16281": "|**2025-10-18**|**Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification**|Yilin Wu,...Claudia P'erez-D'Arpino|[2510.16281](http://arxiv.org/abs/2510.16281)|null|\n", "2510.16263": "|**2025-10-21**|**NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?**|Jierui Peng,...Yu Yin|[2510.16263](http://arxiv.org/abs/2510.16263)|**[link](https://vulab-ai.github.io/NEBULA-Alpha/)**|\n", "2510.16240": "|**2025-10-17**|**Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning**|Lukas Zbinden,...Sean Huver|[2510.16240](http://arxiv.org/abs/2510.16240)|null|\n", "2510.18337": "|**2025-10-23**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Wenhui Huang,...Heng Yang|[2510.18337](http://arxiv.org/abs/2510.18337)|null|\n", "2510.19752": "|**2025-10-22**|**Learning Affordances at Inference-Time for Vision-Language-Action Models**|Ameesh Shah,...Sergey Levine|[2510.19752](http://arxiv.org/abs/2510.19752)|null|\n", "2510.19430": "|**2025-10-22**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**|GigaBrain Team,...Zheng Zhu|[2510.19430](http://arxiv.org/abs/2510.19430)|**[link](https://gigabrain0.github.io/)**|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Zhiyuan Feng,...Baining Guo|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|\n", "2510.20818": "|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Mateo Guaman Castro,...Abhishek Gupta|[2510.20818](http://arxiv.org/abs/2510.20818)|null|\n", "2510.20328": "|**2025-10-23**|**MemER: Scaling Up Memory for Robot Control via Experience Retrieval**|Ajay Sridhar,...Chelsea Finn|[2510.20328](http://arxiv.org/abs/2510.20328)|**[link](https://jen-pan.github.io/memer/)**|\n", "2510.21571": "|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Qixiu Li,...Baining Guo|[2510.21571](http://arxiv.org/abs/2510.21571)|**[link](https://microsoft.github.io/VITRA/)**|\n", "2510.20965": "|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Jesse Haworth,...Axel Krieger|[2510.20965](http://arxiv.org/abs/2510.20965)|null|\n", "2510.23576": "|**2025-10-27**|**UrbanVLA: A Vision-Language-Action Model for Urban Micromobility**|Anqi Li,...He Wang|[2510.23576](http://arxiv.org/abs/2510.23576)|null|\n", "2510.23511": "|**2025-10-27**|**Dexbotic: Open-Source Vision-Language-Action Toolbox**|Bin Xie,...Ziyu Zhang|[2510.23511](http://arxiv.org/abs/2510.23511)|**[link](https://dexbotic.com/.)**|\n", "2510.22201": "|**2025-10-25**|**ACG: Action Coherence Guidance for Flow-based VLA models**|Minho Park,...Jaegul Choo|[2510.22201](http://arxiv.org/abs/2510.22201)|null|\n", "2510.21860": "|**2025-10-23**|**Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence**|Callum Sharrock,...Elias Aronsson|[2510.21860](http://arxiv.org/abs/2510.21860)|null|\n", "2510.21817": "|**2025-10-21**|**VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting**|Xiaoyu Liu,...Ran He|[2510.21817](http://arxiv.org/abs/2510.21817)|**[link](https://lxysl.github.io/VITA-E/)**|\n", "2510.24161": "|**2025-10-28**|**BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning**|Wentao Tan,...Heng Tao Shen|[2510.24161](http://arxiv.org/abs/2510.24161)|null|\n", "2510.23763": "|**2025-11-01**|**RoboOmni: Proactive Robot Manipulation in Omni-modal Context**|Siyin Wang,...Xipeng Qiu|[2510.23763](http://arxiv.org/abs/2510.23763)|null|\n", "2510.25713": "|**2025-10-29**|**Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models**|Boshi An,...Robert Katzschmann|[2510.25713](http://arxiv.org/abs/2510.25713)|null|\n", "2510.25616": "|**2025-10-29**|**Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization**|Nikita Kachaev,...Aleksandr I. Panov|[2510.25616](http://arxiv.org/abs/2510.25616)|null|\n", "2510.25122": "|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jiahong Chen,...Jinghui Lu|[2510.25122](http://arxiv.org/abs/2510.25122)|null|\n", "2510.24795": "|**2025-10-27**|**A Survey on Efficient Vision-Language-Action Models**|Zhaoshu Yu,...Heng Tao Shen|[2510.24795](http://arxiv.org/abs/2510.24795)|null|\n", "2510.26536": "|**2025-10-30**|**RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration**|Huajie Tan,...Shanghang Zhang|[2510.26536](http://arxiv.org/abs/2510.26536)|null|\n", "2510.26406": "|**2025-10-30**|**Human-in-the-loop Online Rejection Sampling for Robotic Manipulation**|Guanxing Lu,...Yansong Tang|[2510.26406](http://arxiv.org/abs/2510.26406)|null|\n", "2510.25889": "|**2025-10-29**|**$\u03c0_\\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models**|Kang Chen,...Chao Yu|[2510.25889](http://arxiv.org/abs/2510.25889)|null|\n", "2510.27607": "|**2025-11-04**|**Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model**|John Won,...Jinwoo Shin|[2510.27607](http://arxiv.org/abs/2510.27607)|null|\n", "2510.27545": "|**2025-10-31**|**EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities**|Travis Davies,...Luhui Hu|[2510.27545](http://arxiv.org/abs/2510.27545)|null|\n", "2511.02832": "|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|Yanjie Ze,...C. Karen Liu|[2511.02832](http://arxiv.org/abs/2511.02832)|**[link](https://yanjieze.com/TWIST2)**|\n", "2511.02776": "|**2025-11-04**|**XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations**|Shichao Fan,...Jian Tang|[2511.02776](http://arxiv.org/abs/2511.02776)|null|\n", "2511.01718": "|**2025-11-03**|**Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process**|Jiayi Chen,...Haoang Li|[2511.01718](http://arxiv.org/abs/2511.01718)|null|\n", "2511.01571": "|**2025-11-03**|**PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model**|Wenqi Liang,...Yang Cong|[2511.01571](http://arxiv.org/abs/2511.01571)|null|\n", "2511.01331": "|**2025-11-03**|**RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models**|Hongyin Zhang,...Donglin Wang|[2511.01331](http://arxiv.org/abs/2511.01331)|null|\n", "2511.01224": "|**2025-11-03**|**Embodiment Transfer Learning for Vision-Language-Action Models**|Chengmeng Li,...Yaxin Peng|[2511.01224](http://arxiv.org/abs/2511.01224)|null|\n", "2511.01210": "|**2025-11-06**|**OmniVLA: Physically-Grounded Multimodal VLA with Unified Multi-Sensor Perception for Robotic Manipulation**|Heyu Guo,...Lili Qiu|[2511.01210](http://arxiv.org/abs/2511.01210)|null|\n", "2511.01914": "|**2025-11-01**|**iFlyBot-VLA Technical Report**|Yuan Zhang,...Jia Pan|[2511.01914](http://arxiv.org/abs/2511.01914)|null|\n", "2511.00139": "|**2025-10-31**|**End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection**|Yu Cui,...Zhibin Li|[2511.00139](http://arxiv.org/abs/2511.00139)|null|\n", "2511.00091": "|**2025-10-30**|**Self-Improving Vision-Language-Action Models with Data Generation via Residual RL**|Wenli Xiao,...Yuke Zhu|[2511.00091](http://arxiv.org/abs/2511.00091)|null|\n", "2511.00088": "|**2025-10-30**|**Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail**|NVIDIA,...Marco Pavone|[2511.00088](http://arxiv.org/abs/2511.00088)|null|\n", "2511.04555": "|**2025-11-06**|**Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment**|Tao Lin,...Bo Zhao|[2511.04555](http://arxiv.org/abs/2511.04555)|**[link](https://github.com/MINT-SJTU/Evo-1)**|\n", "2511.04357": "|**2025-11-06**|**GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies**|Ma\u00eblic Neau,...C\u00e9dric Buche|[2511.04357](http://arxiv.org/abs/2511.04357)|null|\n", "2511.05491": "|**2025-11-07**|**Visual Spatial Tuning**|Rui Yang,...Hengshuang Zhao|[2511.05491](http://arxiv.org/abs/2511.05491)|null|\n", "2511.05397": "|**2025-11-07**|**EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation**|Samarth Chopra,...Samuel Dickerson|[2511.05397](http://arxiv.org/abs/2511.05397)|null|\n", "2511.05275": "|**2025-11-07**|**TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models**|Hokyun Im,...Youngwoon Lee|[2511.05275](http://arxiv.org/abs/2511.05275)|**[link](https://jellyho.github.io/TwinVLA/)**|\n", "2511.06619": "|**2025-11-10**|**How Do VLAs Effectively Inherit from VLMs?**|Chuheng Zhang,...Jiang Bian|[2511.06619](http://arxiv.org/abs/2511.06619)|null|\n", "2511.06202": "|**2025-11-09**|**ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval**|Shahram Najam Syed,...Jeff Ichnowski|[2511.06202](http://arxiv.org/abs/2511.06202)|null|\n", "2511.05936": "|**2025-11-08**|**10 Open Challenges Steering the Future of Vision-Language-Action Models**|Soujanya Poria,...David Hsu|[2511.05936](http://arxiv.org/abs/2511.05936)|null|\n", "2511.05642": "|**2025-11-07**|**Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots**|Justin Williams,...Mrinmoy Sarkar|[2511.05642](http://arxiv.org/abs/2511.05642)|null|\n", "1704.07129": "|**2017-04-25**|**An Analysis of Action Recognition Datasets for Language and Vision Tasks**|Spandana Gella,...Frank Keller|[1704.07129](http://arxiv.org/abs/1704.07129)|null|\n", "2202.02312": "|**2022-08-16**|**A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility**|Andrea Burns,...Bryan A. Plummer|[2202.02312](http://arxiv.org/abs/2202.02312)|null|\n", "2506.21586": "|**2025-08-08**|**Can Vision Language Models Understand Mimed Actions?**|Hyundong Cho,...Jonathan May|[2506.21586](http://arxiv.org/abs/2506.21586)|null|\n", "2408.10845": "|**2025-10-15**|**CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving**|Hidehisa Arai,...Issei Yamamoto|[2408.10845](http://arxiv.org/abs/2408.10845)|**[link](https://turingmotors.github.io/covla-ad/)**|\n", "2508.15201": "|**2025-11-13**|**Survey of Vision-Language-Action Models for Embodied Manipulation**|Haoran Li,...Dongbin Zhao|[2508.15201](http://arxiv.org/abs/2508.15201)|null|\n", "2506.19850": "|**2025-06-25**|**Unified Vision-Language-Action Model**|Yuqi Wang,...Zhaoxiang Zhang|[2506.19850](http://arxiv.org/abs/2506.19850)|null|\n", "2510.23190": "|**2025-10-28**|**Evaluation of Vision-LLMs in Surveillance Video**|Pascal Benschop,...Jelte P. Mense|[2510.23190](http://arxiv.org/abs/2510.23190)|null|\n", "2407.14834": "|**2024-07-23**|**Can VLMs be used on videos for action recognition? LLMs are Visual Reasoning Coordinators**|Harsh Lunia,...Harsh Lunia|[2407.14834](http://arxiv.org/abs/2407.14834)|null|\n", "2508.02917": "|**2025-08-06**|**Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces**|Vebj\u00f8rn Haug K\u00e5sene,...Pierre Lison|[2508.02917](http://arxiv.org/abs/2508.02917)|null|\n", "2205.15509": "|**2022-06-01**|**ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts**|Bingqian Lin,...Xiaodan Liang|[2205.15509](http://arxiv.org/abs/2205.15509)|null|\n", "2403.09631": "|**2024-03-15**|**3D-VLA: A 3D Vision-Language-Action Generative World Model**|Haoyu Zhen,...Chuang Gan|[2403.09631](http://arxiv.org/abs/2403.09631)|**[link](https://vis-www.cs.umass.edu/3dvla/)**|\n", "2505.04769": "|**2025-05-09**|**Vision-Language-Action Models: Concepts, Progress, Applications and Challenges**|Ranjan Sapkota,...Manoj Karkee|[2505.04769](http://arxiv.org/abs/2505.04769)|null|\n", "2509.06932": "|**2025-09-11**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Yuqing Wen,...Xiaoyan Sun|[2509.06932](http://arxiv.org/abs/2509.06932)|null|\n", "2207.08184": "|**2022-07-19**|**Zero-Shot Temporal Action Detection via Vision-Language Prompting**|Sauradip Nag,...Tao Xiang|[2207.08184](http://arxiv.org/abs/2207.08184)|**[link](https://github.com/sauradip/STALE)**|\n", "2503.09594": "|**2025-03-13**|**SimLingo: Vision-Only Closed-Loop Autonomous Driving with Language-Action Alignment**|Katrin Renz,...Oleg Sinavski|[2503.09594](http://arxiv.org/abs/2503.09594)|null|\n", "2503.06637": "|**2025-03-11**|**CLAD: Constrained Latent Action Diffusion for Vision-Language Procedure Planning**|Lei Shi,...Andreas Bulling|[2503.06637](http://arxiv.org/abs/2503.06637)|null|\n", "2508.21046": "|**2025-10-02**|**CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification**|Wei Li,...Liqiang Nie|[2508.21046](http://arxiv.org/abs/2508.21046)|**[link](https://jiutian-vl.github.io/CogVLA-page)**|\n", "2507.05116": "|**2025-10-06**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Juyi Lin,...Yanzhi Wang|[2507.05116](http://arxiv.org/abs/2507.05116)|null|\n", "2507.01925": "|**2025-07-03**|**A Survey on Vision-Language-Action Models: An Action Tokenization Perspective**|Yifan Zhong,...Yaodong Yang|[2507.01925](http://arxiv.org/abs/2507.01925)|null|\n", "2509.05695": "|**2025-09-09**|**Leveraging Vision-Language Large Models for Interpretable Video Action Recognition with Semantic Tokenization**|Jingwei Peng,...Surasakdi Siripong|[2509.05695](http://arxiv.org/abs/2509.05695)|null|\n", "2511.10615": "|**2025-11-13**|**Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals**|Shruti Singh Baghel,...Pawan Goyal|[2511.10615](http://arxiv.org/abs/2511.10615)|null|\n", "2511.10560": "|**2025-11-14**|**OmniVGGT: Omni-Modality Driven Visual Geometry Grounded Transformer**|Haosong Peng,...Ziwei Liu|[2511.10560](http://arxiv.org/abs/2511.10560)|**[link](https://livioni.github.io/OmniVGGT-official/)**|\n", "2511.10518": "|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Wei Li,...Liqiang Nie|[2511.10518](http://arxiv.org/abs/2511.10518)|**[link](https://github.com/JiuTian-VL/SemanticVLA)**|\n", "2511.10254": "|**2025-11-13**|**Facial-R1: Aligning Reasoning and Recognition for Facial Emotion Analysis**|Jiulong Wu,...Min Cao|[2511.10254](http://arxiv.org/abs/2511.10254)|null|\n", "2511.10091": "|**2025-11-13**|**SUGAR: Learning Skeleton Representation with Visual-Motion Knowledge for Action Recognition**|Qilang Ye,...Zitong Yu|[2511.10091](http://arxiv.org/abs/2511.10091)|null|\n", "2511.10008": "|**2025-11-13**|**Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks**|Xuancun Lu,...Wenyuan Xu|[2511.10008](http://arxiv.org/abs/2511.10008)|null|\n", "2511.09958": "|**2025-11-13**|**Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation**|Xiangyi Wei,...Changbo Wang|[2511.09958](http://arxiv.org/abs/2511.09958)|null|\n", "2511.09516": "|**2025-11-12**|**MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation**|Runhao Li,...Ziwei Wang|[2511.09516](http://arxiv.org/abs/2511.09516)|null|\n", "2511.09515": "|**2025-11-12**|**WMPO: World Model-based Policy Optimization for Vision-Language-Action Models**|Fangqi Zhu,...Song Guo|[2511.09515](http://arxiv.org/abs/2511.09515)|**[link](https://wm-po.github.io)**|\n", "2511.08942": "|**2025-11-12**|**Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning**|Mobin Habibpour,...Fatemeh Afghah|[2511.08942](http://arxiv.org/abs/2511.08942)|null|\n", "2511.08892": "|**2025-11-12**|**Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds**|Weihao Tan,...Guang Shi|[2511.08892](http://arxiv.org/abs/2511.08892)|null|\n", "2511.08865": "|**2025-11-12**|**MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror**|Cong Tai,...Tao Shen|[2511.08865](http://arxiv.org/abs/2511.08865)|null|\n", "2511.07820": "|**2025-11-11**|**SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control**|Zhengyi Luo,...Yuke Zhu|[2511.07820](http://arxiv.org/abs/2511.07820)|**[link](https://nvlabs.github.io/SONIC/)**|\n", "2511.07732": "|**2025-11-11**|**ViPRA: Video Prediction for Robot Actions**|Sandeep Routray,...Deepak Pathak|[2511.07732](http://arxiv.org/abs/2511.07732)|**[link](https://vipra-project.github.io)**|\n", "2511.07727": "|**2025-11-11**|**LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models**|Xiaohan Zhang,...Shiqi Zhang|[2511.07727](http://arxiv.org/abs/2511.07727)|null|\n", "2511.06182": "|**2025-11-09**|**OpenVLN: Open-world aerial Vision-Language Navigation**|Peican Lin,...Yang Cong|[2511.06182](http://arxiv.org/abs/2511.06182)|null|\n", "2511.05923": "|**2025-11-11**|**Causal Tracing of Object Representations in Large Vision Language Models: Mechanistic Interpretability and Hallucination Mitigation**|Qiming Li,...Xiachong Feng|[2511.05923](http://arxiv.org/abs/2511.05923)|null|\n", "2511.11478": "|**2025-11-18**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Nhat Chung,...Ngan Le|[2511.11478](http://arxiv.org/abs/2511.11478)|null|\n", "2511.11301": "|**2025-11-14**|**EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment**|Ruoxi Cheng,...Hongyi Zhang|[2511.11301](http://arxiv.org/abs/2511.11301)|null|\n", "2511.11298": "|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Yihao Zhang,...Xi Zheng|[2511.11298](http://arxiv.org/abs/2511.11298)|null|\n", "2511.11052": "|**2025-11-14**|**AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation**|Jinxuan Zhu,...Lin Shao|[2511.11052](http://arxiv.org/abs/2511.11052)|null|\n", "2511.10948": "|**2025-11-14**|**DEFT-LLM: Disentangled Expert Feature Tuning for Micro-Expression Recognition**|Ren Zhang,...Jianqin Yin|[2511.10948](http://arxiv.org/abs/2511.10948)|null|\n", "2511.13704": "|**2025-11-17**|**TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models**|Harold Haodong Chen,...Ying-Cong Chen|[2511.13704](http://arxiv.org/abs/2511.13704)|**[link](https://haroldchen19.github.io/TiViBench-Page/)**|\n", "2511.12937": "|**2025-11-17**|**Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models**|Guoyan Wang,...Yuxiang Sun|[2511.12937](http://arxiv.org/abs/2511.12937)|null|\n", "2511.12878": "|**2025-11-18**|**Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views**|Junyi Ma,...Hesheng Wang|[2511.12878](http://arxiv.org/abs/2511.12878)|null|\n", "2511.12676": "|**2025-11-16**|**BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections**|Subin Varghese,...Vedhus Hoskere|[2511.12676](http://arxiv.org/abs/2511.12676)|null|\n", "2511.12436": "|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Xiaoshuai Hao,...Long Chen|[2511.12436](http://arxiv.org/abs/2511.12436)|null|\n", "2511.12405": "|**2025-11-16**|**VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving**|Hyunki Seong,...David Hyunchul Shim|[2511.12405](http://arxiv.org/abs/2511.12405)|null|\n", "2511.12149": "|**2025-11-15**|**AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models**|Jiayu Li,...Yu-Gang Jiang|[2511.12149](http://arxiv.org/abs/2511.12149)|null|\n", "2511.12101": "|**2025-11-15**|**Decoupled Action Head: Confining Task Knowledge to Conditioning Layers**|Jian Zhou,...Qi WU|[2511.12101](http://arxiv.org/abs/2511.12101)|null|\n", "2511.14759": "|**2025-11-19**|**$\u03c0^{*}_{0.6}$: a VLA That Learns From Experience**|Physical Intelligence,...Zhiyuan Zhou|[2511.14759](http://arxiv.org/abs/2511.14759)|null|\n", "2511.14659": "|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Chia-Yu Hung,...Soujanya Poria|[2511.14659](http://arxiv.org/abs/2511.14659)|**[link](https://declare-lab.github.io/nora-1.5)**|\n", "2511.14499": "|**2025-11-18**|**Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM**|Jack Qin,...Siyuan Cheng|[2511.14499](http://arxiv.org/abs/2511.14499)|null|\n", "2511.14396": "|**2025-11-18**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Xiuxiu Qi,...Hongpeng Wang|[2511.14396](http://arxiv.org/abs/2511.14396)|**[link](https://qhemu.github.io/CCoL/)**|\n", "2511.14178": "|**2025-11-18**|**Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion**|Zhuo Li,...Fei Chen|[2511.14178](http://arxiv.org/abs/2511.14178)|null|\n", "2511.14161": "|**2025-11-19**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Xiaoquan Sun,...Jiayu Chen|[2511.14161](http://arxiv.org/abs/2511.14161)|null|\n", "2511.14159": "|**2025-11-18**|**MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs**|Huiyi Chen,...Lu Cheng|[2511.14159](http://arxiv.org/abs/2511.14159)|null|\n", "2511.14148": "|**2025-11-18**|**AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models**|Yuhua Jiang,...Biqing Qi|[2511.14148](http://arxiv.org/abs/2511.14148)|null|\n", "2511.14120": "|**2025-11-18**|**Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning Framework with Vision-Language Models**|Hao Zhen,...Jidong J. Yang|[2511.14120](http://arxiv.org/abs/2511.14120)|null|\n", "2511.14004": "|**2025-11-19**|**Searching in Space and Time: Unified Memory-Action Loops for Open-World Object Retrieval**|Taijing Chen,...Roberto Mart\u00edn-Mart\u00edn|[2511.14004](http://arxiv.org/abs/2511.14004)|null|\n", "2511.15605": "|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Senyu Fei,...Xipeng Qiu|[2511.15605](http://arxiv.org/abs/2511.15605)|null|\n", "2511.15379": "|**2025-11-19**|**Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training**|Yunjiao Zhou,...Jianfei Yang|[2511.15379](http://arxiv.org/abs/2511.15379)|null|\n", "2511.15279": "|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Jiashu Yang,...Wenzhao Lian|[2511.15279](http://arxiv.org/abs/2511.15279)|null|\n", "2511.15159": "|**2025-11-19**|**Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation**|Firdavs Nasriddinov,...Andrew J. Hung|[2511.15159](http://arxiv.org/abs/2511.15159)|null|\n", "2511.16651": "|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Yang Tian,...Jiangmiao Pang|[2511.16651](http://arxiv.org/abs/2511.16651)|null|\n", "2511.16449": "|**2025-11-21**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Ziyan Liu,...Bo Zhao|[2511.16449](http://arxiv.org/abs/2511.16449)|null|\n", "2511.16233": "|**2025-11-20**|**FT-NCFM: An Influence-Aware Data Distillation Framework for Efficient VLA Models**|Kewei Chen,...Mingsheng Shang|[2511.16233](http://arxiv.org/abs/2511.16233)|null|\n", "2511.16203": "|**2025-11-20**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yuping Yan,...Yaochu Jin|[2511.16203](http://arxiv.org/abs/2511.16203)|null|\n", "2511.16175": "|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Yi Yang,...Zhijie Deng|[2511.16175](http://arxiv.org/abs/2511.16175)|null|\n", "2511.16166": "|**2025-11-20**|**EvoVLA: Self-Evolving Vision-Language-Action Model**|Zeting Liu,...Hao Tang|[2511.16166](http://arxiv.org/abs/2511.16166)|null|\n", "2511.17502": "|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Jun Cen,...Hao Chen|[2511.17502](http://arxiv.org/abs/2511.17502)|null|\n", "2511.17366": "|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Yankai Fu,...Shanghang Zhang|[2511.17366](http://arxiv.org/abs/2511.17366)|null|\n", "2511.17335": "|**2025-11-21**|**Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM**|Chiori Hori,...Jonathan Le Roux|[2511.17335](http://arxiv.org/abs/2511.17335)|null|\n", "2511.17199": "|**2025-11-21**|**VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation**|Hanyu Zhou,...Gim Hee Lee|[2511.17199](http://arxiv.org/abs/2511.17199)|null|\n", "2511.17097": "|**2025-11-21**|**Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation**|Shuo Wang,...Zhaoxin Fan|[2511.17097](http://arxiv.org/abs/2511.17097)|null|\n", "2511.21663": "|**2025-11-26**|**Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models**|Naifu Zhang,...Nan Zhang|[2511.21663](http://arxiv.org/abs/2511.21663)|null|\n", "2511.21557": "|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Hui Zhou,...Shaoshuai Shi|[2511.21557](http://arxiv.org/abs/2511.21557)|null|\n", "2511.21542": "|**2025-11-26**|**$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Zhihao Zhan,...Guangrun Wang|[2511.21542](http://arxiv.org/abs/2511.21542)|null|\n", "2511.21428": "|**2025-11-26**|**From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings**|Jiajie Zhang,...Alexander Kleiner|[2511.21428](http://arxiv.org/abs/2511.21428)|null|\n", "2511.21202": "|**2025-11-26**|**Towards an Effective Action-Region Tracking Framework for Fine-grained Video Action Recognition**|Baoli Sun,...Zhiyong Wang|[2511.21202](http://arxiv.org/abs/2511.21202)|null|\n", "2511.21192": "|**2025-11-26**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Hui Lu,...Xudong Jiang|[2511.21192](http://arxiv.org/abs/2511.21192)|null|\n", "2511.21064": "|**2025-11-26**|**OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection**|Chujie Wang,...Chu He|[2511.21064](http://arxiv.org/abs/2511.21064)|null|\n", "2511.20937": "|**2025-11-26**|**ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction**|Qineng Wang,...Manling Li|[2511.20937](http://arxiv.org/abs/2511.20937)|null|\n", "2511.20841": "|**2025-11-25**|**OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping**|Edmond Tong,...Odest Chadwicke Jenkins|[2511.20841](http://arxiv.org/abs/2511.20841)|null|\n", "2511.20633": "|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Jiahui Zhang,...Li Zhang|[2511.20633](http://arxiv.org/abs/2511.20633)|**[link](https://LogosRoboticsGroup.github.io/ProphRL)**|\n", "2511.20330": "|**2025-11-25**|**ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation**|Yuhan Wu,...Yan Xia|[2511.20330](http://arxiv.org/abs/2511.20330)|null|\n", "2511.20274": "|**2025-11-25**|**ScenarioCLIP: Pretrained Transferable Visual Language Models and Action-Genome Dataset for Natural Scene Analysis**|Advik Sinha,...Abhijit Das|[2511.20274](http://arxiv.org/abs/2511.20274)|null|\n", "2511.20720": "|**2025-11-25**|**DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving**|Haibo HU,...Chun Jason Xue|[2511.20720](http://arxiv.org/abs/2511.20720)|null|\n", "2511.19912": "|**2025-11-25**|**Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving**|Dapeng Zhang,...Tat-Seng Chua|[2511.19912](http://arxiv.org/abs/2511.19912)|null|\n", "2511.19878": "|**2025-11-25**|**MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization**|Chengyue Huang,...Zsolt Kira|[2511.19878](http://arxiv.org/abs/2511.19878)|null|\n", "2511.19861": "|**2025-11-25**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|GigaWorld Team,...Zheng Zhu|[2511.19861](http://arxiv.org/abs/2511.19861)|**[link](https://gigaworld0.github.io/)**|\n", "2511.19859": "|**2025-11-25**|**Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation**|Xiangkai Ma,...Sanglu Lu|[2511.19859](http://arxiv.org/abs/2511.19859)|null|\n", "2511.19768": "|**2025-11-24**|**Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering**|Noah Frahm,...Roni Sengupta|[2511.19768](http://arxiv.org/abs/2511.19768)|**[link](https://noahfrahm.github.io/Prune-Then-Plan-project-page/)**|\n", "2511.19433": "|**2025-11-24**|**Mixture of Horizons in Action Chunking**|Dong Jing,...Mingyu Ding|[2511.19433](http://arxiv.org/abs/2511.19433)|null|\n", "2511.19584": "|**2025-11-24**|**Learning Massively Multitask World Models for Continuous Control**|Nicklas Hansen,...Xiaolong Wang|[2511.19584](http://arxiv.org/abs/2511.19584)|**[link](https://www.nicklashansen.com/NewtWM)**|\n", "2512.02902": "|**2025-12-02**|**VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling**|Weiqi Li,...Guangrun Wang|[2512.02902](http://arxiv.org/abs/2512.02902)|null|\n", "2512.02846": "|**2025-12-02**|**Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?**|Manuel Benavent-Lledo,...Jose Garcia-Rodriguez|[2512.02846](http://arxiv.org/abs/2512.02846)|null|\n", "2512.02834": "|**2025-12-02**|**Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**|Siyuan Yang,...Xuelong Li|[2512.02834](http://arxiv.org/abs/2512.02834)|null|\n", "2512.02814": "|**2025-12-02**|**Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control**|Yongrui Yu,...Xiaofan Zhang|[2512.02814](http://arxiv.org/abs/2512.02814)|null|\n", "2512.02787": "|**2025-12-03**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Xianchao Zeng,...Yong-Lu Li|[2512.02787](http://arxiv.org/abs/2512.02787)|null|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Yuhong Zhang,...Haoqian Wang|[2512.02729](http://arxiv.org/abs/2512.02729)|null|\n", "2512.02013": "|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Chenyang Gu,...Shanghang Zhang|[2512.02013](http://arxiv.org/abs/2512.02013)|null|\n", "2512.01803": "|**2025-12-01**|**Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos**|Xavier Thomas,...Deepti Ghadiyaram|[2512.01803](http://arxiv.org/abs/2512.01803)|null|\n", "2512.01801": "|**2025-12-02**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yunfei Li,...Yonghui Wu|[2512.01801](http://arxiv.org/abs/2512.01801)|null|\n", "2512.01773": "|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Chenghao Gu,...Zhi Wang|[2512.01773](http://arxiv.org/abs/2512.01773)|null|\n", "2512.01715": "|**2025-12-01**|**DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models**|Wanpeng Zhang,...Zongqing Lu|[2512.01715](http://arxiv.org/abs/2512.01715)|null|\n", "2512.01550": "|**2025-12-01**|**NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction**|Fei Liu,...Mu Xu|[2512.01550](http://arxiv.org/abs/2512.01550)|null|\n", "2512.01031": "|**2025-11-30**|**VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference**|Jiaming Tang,...Song Han|[2512.01031](http://arxiv.org/abs/2512.01031)|null|\n", "2512.01022": "|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Yi-Lin Wei,...Wei-Shi Zheng|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|\n", "2512.00975": "|**2025-11-30**|**MM-ACT: Learn from Multimodal Parallel Generation to Act**|Haotian Liang,...Ping Luo|[2512.00975](http://arxiv.org/abs/2512.00975)|null|\n", "2512.00903": "|**2025-11-30**|**SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models at Minimal Overhead**|Chaojun Ni,...Wenjun Mei|[2512.00903](http://arxiv.org/abs/2512.00903)|null|\n", "2512.00846": "|**2025-11-30**|**AFRAgent : An Adaptive Feature Renormalization Based High Resolution Aware GUI agent**|Neeraj Anand,...Mausoom Sarkar|[2512.00846](http://arxiv.org/abs/2512.00846)|null|\n", "2512.00797": "|**2025-11-30**|**Transforming Monolithic Foundation Models into Embodied Multi-Agent Architectures for Human-Robot Collaboration**|Nan Sun,...Huaping Liu|[2512.00797](http://arxiv.org/abs/2512.00797)|null|\n", "2512.00783": "|**2025-12-02**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang,...Libo Wang|[2512.00783](http://arxiv.org/abs/2512.00783)|**[link](https://huggingface.co/Veltraxor/Sigma)**|\n", "2512.00532": "|**2025-11-29**|**Image Generation as a Visual Planner for Robotic Manipulation**|Ye Pang,...Ye Pang|[2512.00532](http://arxiv.org/abs/2512.00532)|null|\n", "2512.05107": "|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Feng Xu,...Benjamin Busam|[2512.05107](http://arxiv.org/abs/2512.05107)|null|\n", "2512.05103": "|**2025-12-04**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Xiaochuang Han,...Emily Dinan|[2512.05103](http://arxiv.org/abs/2512.05103)|null|\n", "2512.04952": "|**2025-12-08**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Yicheng Liu,...Hang Zhao|[2512.04952](http://arxiv.org/abs/2512.04952)|null|\n", "2512.04733": "|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Yihong Tang,...Chengzhong Xu|[2512.04733](http://arxiv.org/abs/2512.04733)|null|\n", "2512.04686": "|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Yipu Wang,...Xiaolong Zheng|[2512.04686](http://arxiv.org/abs/2512.04686)|null|\n", "2512.04585": "|**2025-12-04**|**SAM3-I: Segment Anything with Instructions**|Jingjing Li,...Li Cheng|[2512.04585](http://arxiv.org/abs/2512.04585)|null|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Pei Yang,...Mike Zheng Shou|[2512.04537](http://arxiv.org/abs/2512.04537)|null|\n", "2512.04459": "|**2025-12-04**|**dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning**|Yingzi Ma,...Chaowei Xiao|[2512.04459](http://arxiv.org/abs/2512.04459)|null|\n", "2512.04446": "|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Chang Liu,...Minghui Zheng|[2512.04446](http://arxiv.org/abs/2512.04446)|null|\n", "2512.04441": "|**2025-12-04**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Bin Suna,...Ziying Song|[2512.04441](http://arxiv.org/abs/2512.04441)|null|\n", "2512.04381": "|**2025-12-04**|**FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination**|Chengyang He,...Guillaume Sartoretti|[2512.04381](http://arxiv.org/abs/2512.04381)|null|\n", "2512.04356": "|**2025-12-04**|**Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment**|Kai-Po Chang,...Yu-Chiang Frank Wang|[2512.04356](http://arxiv.org/abs/2512.04356)|**[link](https://kpc0810.github.io/santa/)**|\n", "2512.03963": "|**2025-12-04**|**TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning**|Tao Wu,...Limin Wang|[2512.03963](http://arxiv.org/abs/2512.03963)|null|\n", "2512.03913": "|**2025-12-03**|**Hierarchical Vision Language Action Model Using Success and Failure Demonstrations**|Jeongeun Park,...Sungjoon Choi|[2512.03913](http://arxiv.org/abs/2512.03913)|**[link](https://vine-vla.github.io/)**|\n", "2512.03724": "|**2025-12-08**|**PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention**|Ziwen Li,...Mingming Gong|[2512.03724](http://arxiv.org/abs/2512.03724)|null|\n", "2512.03479": "|**2025-12-03**|**Towards Object-centric Understanding for Instructional Videos**|Wenliang Guo,...Yu Kong|[2512.03479](http://arxiv.org/abs/2512.03479)|null|\n", "2512.07582": "|**2025-12-08**|**See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations**|Guangyan Chen,...Yufeng Yue|[2512.07582](http://arxiv.org/abs/2512.07582)|null|\n", "2512.07472": "|**2025-12-08**|**Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation**|Siyu Xu,...Chang Xu|[2512.07472](http://arxiv.org/abs/2512.07472)|null|\n", "2512.06963": "|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Yichao Shen,...Baining Guo|[2512.06963](http://arxiv.org/abs/2512.06963)|**[link](https://videovla-nips2025.github.io)**|\n", "2512.06951": "|**2025-12-07**|**Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge**|Ilia Larchenko,...Akash Karnatak|[2512.06951](http://arxiv.org/abs/2512.06951)|null|\n", "2512.06112": "|**2025-12-11**|**WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving**|Yifang Xu,...Siyu Zhu|[2512.06112](http://arxiv.org/abs/2512.06112)|**[link](https://github.com/fudan-generative-vision/WAM-Flow)**|\n", "2512.05964": "|**2025-12-09**|**Training-Time Action Conditioning for Efficient Real-Time Chunking**|Kevin Black,...Sergey Levine|[2512.05964](http://arxiv.org/abs/2512.05964)|null|\n", "2512.05693": "|**2025-12-05**|**HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies**|Zhiying Du,...Yu-Gang Jiang|[2512.05693](http://arxiv.org/abs/2512.05693)|null|\n", "2512.10394": "|**2025-12-11**|**RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI**|Weifan Guan,...Jian Cheng|[2512.10394](http://arxiv.org/abs/2512.10394)|null|\n", "2512.10226": "|**2025-12-11**|**Latent Chain-of-Thought World Modeling for End-to-End Driving**|Shuhan Tan,...Boris Ivanovic|[2512.10226](http://arxiv.org/abs/2512.10226)|null|\n", "2512.09928": "|**2025-12-10**|**HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models**|Minghui Lin,...Donglin Wang|[2512.09928](http://arxiv.org/abs/2512.09928)|**[link](https://hifvla.github.io)**|\n", "2512.09927": "|**2025-12-10**|**Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models**|Yifan Ye,...Zhihe Lu|[2512.09927](http://arxiv.org/abs/2512.09927)|null|\n", "2512.09864": "|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Hao Lu,...Ying-Cong Chen|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|\n", "2512.09619": "|**2025-12-10**|**GLaD: Geometric Latent Distillation for Vision-Language-Action Models**|Minghao Guo,...Xiaojun Chang|[2512.09619](http://arxiv.org/abs/2512.09619)|null|\n", "2512.08580": "|**2025-12-10**|**Mind to Hand: Purposeful Robotic Control via Embodied Reasoning**|Peijun Tang,...Jianan Wang|[2512.08580](http://arxiv.org/abs/2512.08580)|null|\n", "2512.08333": "|**2025-12-09**|**Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging**|Yajat Yadav,...Sergey Levine|[2512.08333](http://arxiv.org/abs/2512.08333)|null|\n", "2512.11769": "|**2025-12-12**|**BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models**|Xiaoyu Ma,...Yanfang Ye|[2512.11769](http://arxiv.org/abs/2512.11769)|**[link](https://github.com/JijiKing-Sam/BLURR-A-Boosted-Low-Resource-Inference-for-Vision-Language-Action-Model)**|\n", "2512.11612": "|**2025-12-12**|**Embodied Image Compression**|Chunyi Li,...Guangtao Zhai|[2512.11612](http://arxiv.org/abs/2512.11612)|null|\n", "2512.11584": "|**2025-12-12**|**Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents**|Stefan Tabakov,...Boris Kraychev|[2512.11584](http://arxiv.org/abs/2512.11584)|null|\n", "2512.11362": "|**2025-12-12**|**An Anatomy of Vision-Language-Action Models: From Modules to Milestones and Challenges**|Chao Xu,...Jiankang Deng|[2512.11362](http://arxiv.org/abs/2512.11362)|null|\n", "2512.11315": "|**2025-12-12**|**Benchmarking the Generality of Vision-Language-Action Models**|Pranav Guruprasad,...Yangyue Wang|[2512.11315](http://arxiv.org/abs/2512.11315)|null|\n", "2512.11218": "|**2025-12-12**|**Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy**|Kechun Xu,...Yue Wang|[2512.11218](http://arxiv.org/abs/2512.11218)|null|\n", "2512.11047": "|**2025-12-15**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Haoran Jiang,...Hongyang Li|[2512.11047](http://arxiv.org/abs/2512.11047)|null|\n", "2512.15692": "|**2025-12-17**|**mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs**|Jonas Pai,...Elvis Nava|[2512.15692](http://arxiv.org/abs/2512.15692)|null|\n", "2512.15411": "|**2025-12-17**|**MiVLA: Towards Generalizable Vision-Language-Action Model with Human-Robot Mutual Imitation Pre-training**|Zhenhan Yin,...Heng Tao Shen|[2512.15411](http://arxiv.org/abs/2512.15411)|null|\n", "2512.15258": "|**2025-12-17**|**VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments**|Yuze Wu,...Fei Gao|[2512.15258](http://arxiv.org/abs/2512.15258)|null|\n", "2512.14666": "|**2025-12-16**|**EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models**|Zechen Bai,...Mike Zheng Shou|[2512.14666](http://arxiv.org/abs/2512.14666)|null|\n", "2512.14031": "|**2025-12-16**|**Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model**|Zhaofeng Hu,...Ci-Jyun Liang|[2512.14031](http://arxiv.org/abs/2512.14031)|null|\n", "2512.13636": "|**2025-12-16**|**MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning**|Haoyu Fu,...Xiang Bai|[2512.13636](http://arxiv.org/abs/2512.13636)|**[link](https://xiaomi-mlab.github.io/MindDrive/)**|\n", "2512.13080": "|**2025-12-15**|**Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos**|Yicheng Feng,...Zongqing Lu|[2512.13080](http://arxiv.org/abs/2512.13080)|null|\n", "2512.13030": "|**2025-12-15**|**Motus: A Unified Latent Action World Model**|Hongzhe Bi,...Jun Zhu|[2512.13030](http://arxiv.org/abs/2512.13030)|null|\n", "2512.12799": "|**2025-12-14**|**DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning**|Zhe Liu,...Hengshuang Zhao|[2512.12799](http://arxiv.org/abs/2512.12799)|null|\n", "2512.11921": "|**2025-12-11**|**Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control**|Abdullah Yahya Abdullah Omaisan,...Ibrahim Sheikh Mohamed|[2512.11921](http://arxiv.org/abs/2512.11921)|null|\n", "2512.11908": "|**2025-12-10**|**Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models**|Heng Zhang,...Arash Ajoudani|[2512.11908](http://arxiv.org/abs/2512.11908)|null|\n"}, "Humanoid": {"2509.21231": "|**2025-09-25**|**SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation**|Jaehwi Jang,...Ye Zhao|[2509.21231](http://arxiv.org/abs/2509.21231)|null|\n", "2509.20696": "|**2025-09-25**|**RuN: Residual Policy for Natural Humanoid Locomotion**|Qingpeng Li,...Yong Liu|[2509.20696](http://arxiv.org/abs/2509.20696)|null|\n", "2509.20579": "|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|Hanna Yurchyk,...David Meger|[2509.20579](http://arxiv.org/abs/2509.20579)|null|\n", "2509.20322": "|**2025-09-24**|**VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation**|Shaofeng Yin,...Jiajun Wu|[2509.20322](http://arxiv.org/abs/2509.20322)|**[link](https://visualmimic.github.io)**|\n", "2509.20263": "|**2025-09-25**|**HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms**|Bingjie Chen,...Houde Liu|[2509.20263](http://arxiv.org/abs/2509.20263)|null|\n", "2509.19573": "|**2025-09-23**|**Chasing Stability: Humanoid Running via Control Lyapunov Function Guided Reinforcement Learning**|Zachary Olkin,...Aaron D. Ames|[2509.19573](http://arxiv.org/abs/2509.19573)|null|\n", "2509.19545": "|**2025-09-23**|**RoMoCo: Robotic Motion Control Toolbox for Reduced-Order Model-Based Locomotion on Bipedal and Humanoid Robots**|Min Dai,...Aaron D. Ames|[2509.19545](http://arxiv.org/abs/2509.19545)|null|\n", "2509.19301": "|**2025-09-25**|**Residual Off-Policy RL for Finetuning Behavior Cloning Policies**|Lars Ankile,...Anusha Nagabandi|[2509.19301](http://arxiv.org/abs/2509.19301)|**[link](https://residual-offpolicy-rl.github.io)**|\n", "2509.16757": "|**2025-09-27**|**HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos**|Haoyang Weng,...Guanya Shi|[2509.16757](http://arxiv.org/abs/2509.16757)|null|\n", "2509.16638": "|**2025-09-20**|**KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control**|Jinrui Han,...Chenjia Bai|[2509.16638](http://arxiv.org/abs/2509.16638)|null|\n", "2509.16469": "|**2025-09-19**|**A Framework for Optimal Ankle Design of Humanoid Robots**|Guglielmo Cervettini,...Daniele Pucci|[2509.16469](http://arxiv.org/abs/2509.16469)|null|\n", "2509.16032": "|**2025-09-19**|**A Matter of Height: The Impact of a Robotic Object on Human Compliance**|Michael Faber,...Hadas Erel|[2509.16032](http://arxiv.org/abs/2509.16032)|null|\n", "2509.15443": "|**2025-09-18**|**Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning**|Xingyu Chen,...Haodong Zhang|[2509.15443](http://arxiv.org/abs/2509.15443)|null|\n", "2509.14935": "|**2025-09-18**|**CAD-Driven Co-Design for Flight-Ready Jet-Powered Humanoids**|Punith Reddy Vanteddu,...Daniele Pucci|[2509.14935](http://arxiv.org/abs/2509.14935)|null|\n", "2509.14687": "|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Cong Tai,...Tao Shen|[2509.14687](http://arxiv.org/abs/2509.14687)|null|\n", "2509.14139": "|**2025-09-23**|**Cybersecurity AI: Humanoid Robots as Attack Vectors**|V\u00edctor Mayoral-Vilches,...Kevin Finisterre|[2509.14139](http://arxiv.org/abs/2509.14139)|null|\n", "2509.14096": "|**2025-09-17**|**The Cybersecurity of a Humanoid Robot**|V\u00edctor Mayoral-Vilches,...V\u00edctor Mayoral-Vilches|[2509.14096](http://arxiv.org/abs/2509.14096)|null|\n", "2509.13780": "|**2025-09-17**|**Behavior Foundation Model for Humanoid Robots**|Weishuai Zeng,...Jiangmiao Pang|[2509.13780](http://arxiv.org/abs/2509.13780)|null|\n", "2509.13733": "|**2025-09-17**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Xiaolin Zhou,...Zhizhong Su|[2509.13733](http://arxiv.org/abs/2509.13733)|null|\n", "2509.13534": "|**2025-09-16**|**Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning**|Chunxin Zheng,...Jun Ma|[2509.13534](http://arxiv.org/abs/2509.13534)|null|\n", "2509.24697": "|**2025-09-29**|**Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering**|Evelyn D'Elia,...Daniele Pucci|[2509.24697](http://arxiv.org/abs/2509.24697)|null|\n", "2509.24530": "|**2025-09-29**|**Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game**|Giulia Pusceddu,...Alessandra Sciutti|[2509.24530](http://arxiv.org/abs/2509.24530)|null|\n", "2509.24163": "|**2025-09-29**|**Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models**|Wanming Yu,...Sethu Vijayakumar|[2509.24163](http://arxiv.org/abs/2509.24163)|null|\n", "2509.23852": "|**2025-09-28**|**SIG-Chat: Spatial Intent-Guided Conversational Gesture Generation Involving How, When and Where**|Yiheng Huang,...Chuanchen Luo|[2509.23852](http://arxiv.org/abs/2509.23852)|null|\n", "2509.26633": "|**2025-10-08**|**OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction**|Lujie Yang,...Guanya Shi|[2509.26633](http://arxiv.org/abs/2509.26633)|**[link](https://omniretarget.github.io)**|\n", "2509.26236": "|**2025-09-30**|**ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm**|Benjamin A. Richardson,...Katherine J. Kuchenbecker|[2509.26236](http://arxiv.org/abs/2509.26236)|null|\n", "2509.26082": "|**2025-09-30**|**Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance**|Tianyi Jin,...Frank Kirchner|[2509.26082](http://arxiv.org/abs/2509.26082)|null|\n", "2509.25443": "|**2025-10-06**|**CoTaP: Compliant Task Pipeline and Reinforcement Learning of Its Controller with Compliance Modulation**|Zewen He,...Yoshihiko Nakamura|[2509.25443](http://arxiv.org/abs/2509.25443)|null|\n", "2510.02252": "|**2025-10-02**|**Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking**|Joao Pedro Araujo,...C. Karen Liu|[2510.02252](http://arxiv.org/abs/2510.02252)|null|\n", "2510.02129": "|**2025-10-02**|**Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control**|Philip Reichenberg,...Tim Laue|[2510.02129](http://arxiv.org/abs/2510.02129)|null|\n", "2510.01843": "|**2025-10-02**|**Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots**|Wanyue Li,...Peng Lu|[2510.01843](http://arxiv.org/abs/2510.01843)|null|\n", "2510.00329": "|**2025-09-30**|**Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning**|Sarmad Mehrdad,...Ludovic Righetti|[2510.00329](http://arxiv.org/abs/2510.00329)|null|\n", "2510.03081": "|**2025-10-03**|**Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot**|Guiliang Liu,...Kui Jia|[2510.03081](http://arxiv.org/abs/2510.03081)|null|\n", "2510.03022": "|**2025-10-03**|**HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton**|Rui Zhong,...Yi Xu|[2510.03022](http://arxiv.org/abs/2510.03022)|null|\n", "2510.05001": "|**2025-10-06**|**Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot**|Aditya Sripada,...Abhishek Warrier|[2510.05001](http://arxiv.org/abs/2510.05001)|null|\n", "2510.04353": "|**2025-10-05**|**Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation**|Stephen McCrory,...Robert Griffin|[2510.04353](http://arxiv.org/abs/2510.04353)|null|\n", "2510.03529": "|**2025-10-03**|**LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy**|Zekai Liang,...Michael C. Yip|[2510.03529](http://arxiv.org/abs/2510.03529)|null|\n", "2510.05923": "|**2025-10-07**|**A Co-Design Framework for Energy-Aware Monoped Jumping with Detailed Actuator Modeling**|Aman Singh,...Shishir Kolathaya|[2510.05923](http://arxiv.org/abs/2510.05923)|null|\n", "2510.07152": "|**2025-10-10**|**DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction**|Jingkai Sun,...Qiang Zhang|[2510.07152](http://arxiv.org/abs/2510.07152)|null|\n", "2510.08475": "|**2025-10-09**|**DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos**|Jhen Hsieh,...Tsung-Wei Ke|[2510.08475](http://arxiv.org/abs/2510.08475)|**[link](https://embodiedai-ntu.github.io/dexman/index.html)**|\n", "2510.08406": "|**2025-10-09**|**Reliability of Single-Level Equality-Constrained Inverse Optimal Control**|Filip Be\u010danovi\u0107,...Vincent Bonnet|[2510.08406](http://arxiv.org/abs/2510.08406)|null|\n", "2510.07882": "|**2025-10-15**|**Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots**|Boyu Li,...Zongqing Lu|[2510.07882](http://arxiv.org/abs/2510.07882)|null|\n", "2510.08807": "|**2025-10-09**|**Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation**|Zhenyu Zhao,...Yue Wang|[2510.08807](http://arxiv.org/abs/2510.08807)|null|\n", "2510.11682": "|**2025-10-13**|**Ego-Vision World Model for Humanoid Contact Planning**|Hang Liu,...Koushil Sreenath|[2510.11682](http://arxiv.org/abs/2510.11682)|null|\n", "2510.11539": "|**2025-10-13**|**Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization**|Denglin Cheng,...Xiaobin Xiong|[2510.11539](http://arxiv.org/abs/2510.11539)|null|\n", "2510.11401": "|**2025-10-13**|**Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots**|Jiayang Wu,...Yao Su|[2510.11401](http://arxiv.org/abs/2510.11401)|null|\n", "2510.11258": "|**2025-10-13**|**DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation**|Yuhui Fu,...Zongqing Lu|[2510.11258](http://arxiv.org/abs/2510.11258)|null|\n", "2510.11072": "|**2025-10-13**|**PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System**|Huayi Wang,...Jiangmiao Pang|[2510.11072](http://arxiv.org/abs/2510.11072)|**[link](https://why618188.github.io/physhsi/)**|\n", "2510.10851": "|**2025-10-12**|**Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion**|Tingxuan Leng,...Mingguo Zhao|[2510.10851](http://arxiv.org/abs/2510.10851)|null|\n", "2510.10206": "|**2025-10-11**|**It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots**|Zuhong Liu,...Siheng Chen|[2510.10206](http://arxiv.org/abs/2510.10206)|null|\n", "2510.09786": "|**2025-10-10**|**Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks**|Yuang Lu,...Zhicheng He|[2510.09786](http://arxiv.org/abs/2510.09786)|null|\n", "2510.12346": "|**2025-10-14**|**PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing**|Bingquan Li,...Yucong Wu|[2510.12346](http://arxiv.org/abs/2510.12346)|null|\n", "2510.13625": "|**2025-10-15**|**A Modular Object Detection System for Humanoid Robots Using YOLO**|Nicolas Pottier,...Meng Cheng Lau|[2510.13625](http://arxiv.org/abs/2510.13625)|null|\n", "2510.13594": "|**2025-10-15**|**Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots**|Austin Barret,...Meng Cheng Lau|[2510.13594](http://arxiv.org/abs/2510.13594)|null|\n", "2510.14959": "|**2025-10-19**|**CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions**|Lizhi Yang,...Aaron D. Ames|[2510.14959](http://arxiv.org/abs/2510.14959)|null|\n", "2510.14952": "|**2025-10-17**|**From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance**|Zhe Li,...Chang Xu|[2510.14952](http://arxiv.org/abs/2510.14952)|null|\n", "2510.14454": "|**2025-10-16**|**Towards Adaptable Humanoid Control via Adaptive Motion Tracking**|Tao Huang,...Jiangmiao Pang|[2510.14454](http://arxiv.org/abs/2510.14454)|null|\n", "2510.17792": "|**2025-10-20**|**SoftMimic: Learning Compliant Whole-body Control from Examples**|Gabriel B. Margolis,...Pulkit Agrawal|[2510.17792](http://arxiv.org/abs/2510.17792)|**[link](https://gmargo11.github.io/softmimic/)**|\n", "2510.18544": "|**2025-10-21**|**SLICE: SLO-Driven Scheduling for LLM Inference on Edge Computing Devices**|Pan Zhou,...Yueyue Dai|[2510.18544](http://arxiv.org/abs/2510.18544)|null|\n", "2510.18002": "|**2025-10-20**|**Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints**|Junli Ren,...Jiangmiao Pang|[2510.18002](http://arxiv.org/abs/2510.18002)|null|\n", "2510.23059": "|**2025-10-27**|**Awakening Facial Emotional Expressions in Human-Robot**|Yongtong Zhu,...Jianwei Zhang|[2510.23059](http://arxiv.org/abs/2510.23059)|null|\n", "2510.22336": "|**2025-11-05**|**Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery**|Bo Yue,...Guiliang Liu|[2510.22336](http://arxiv.org/abs/2510.22336)|null|\n", "2510.25725": "|**2025-10-28**|**A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation**|Eunju Kwon,...Kyung-Joong Kim|[2510.25725](http://arxiv.org/abs/2510.25725)|null|\n", "2510.26082": "|**2025-11-01**|**Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse**|Fan Yang,...Renkai Ma|[2510.26082](http://arxiv.org/abs/2510.26082)|null|\n", "2511.02832": "|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|Yanjie Ze,...C. Karen Liu|[2511.02832](http://arxiv.org/abs/2511.02832)|**[link](https://yanjieze.com/TWIST2)**|\n", "2511.00840": "|**2025-11-02**|**Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches**|William Suliman,...Roman Gorbachev|[2511.00840](http://arxiv.org/abs/2511.00840)|null|\n", "2511.00153": "|**2025-10-31**|**EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations**|Justin Yu,...Philipp Wu|[2511.00153](http://arxiv.org/abs/2511.00153)|null|\n", "2511.03571": "|**2025-11-05**|**OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera**|Hao Shi,...Kaiwei Wang|[2511.03571](http://arxiv.org/abs/2511.03571)|**[link](https://github.com/MasterHow/OneOcc)**|\n", "2511.04679": "|**2025-11-06**|**GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction**|Qingzhou Lu,...C. Karen Liu|[2511.04679](http://arxiv.org/abs/2511.04679)|**[link](https://gentle-humanoid.axell.top)**|\n", "2511.04131": "|**2025-11-06**|**BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning**|Yitang Li,...Guanya Shi|[2511.04131](http://arxiv.org/abs/2511.04131)|null|\n", "2511.03996": "|**2025-11-06**|**Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots**|Yushi Wang,...Mingguo Zhao|[2511.03996](http://arxiv.org/abs/2511.03996)|**[link](https://humanoid-kick.github.io)**|\n", "2511.04758": "|**2025-11-06**|**ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling**|Caelan Garrett,...Fabio Ramos|[2511.04758](http://arxiv.org/abs/2511.04758)|**[link](https://schedulestream.github.io)**|\n", "2511.07407": "|**2025-11-10**|**Unified Humanoid Fall-Safety Policy from a Few Demonstrations**|Zhengjie Xu,...Stella X. Yu|[2511.07407](http://arxiv.org/abs/2511.07407)|null|\n", "2511.06796": "|**2025-11-10**|**Human-Level Actuation for Humanoids**|MD-Nazmus Sunbeam,...MD-Nazmus Sunbeam|[2511.06796](http://arxiv.org/abs/2511.06796)|null|\n", "2511.06371": "|**2025-11-11**|**Towards Adaptive Humanoid Control via Multi-Behavior Distillation and Reinforced Fine-Tuning**|Yingnan Zhao,...Chenjia Bai|[2511.06371](http://arxiv.org/abs/2511.06371)|null|\n", "2511.06036": "|**2025-11-08**|**Towards Human-AI-Robot Collaboration and AI-Agent based Digital Twins for Parkinson's Disease Management: Review and Outlook**|Hassan Hizeh,...Tareq Y. Al-Naffouri|[2511.06036](http://arxiv.org/abs/2511.06036)|null|\n", "2211.13503": "|**2022-11-28**|**Optimization of Humanoid Robot Designs for Human-Robot Ergonomic Payload Lifting**|Carlotta Sartore,...Daniele Pucci|[2211.13503](http://arxiv.org/abs/2211.13503)|null|\n", "2508.12252": "|**2025-08-27**|**Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids**|Kaizhe Hu,...Shuran Song|[2508.12252](http://arxiv.org/abs/2508.12252)|null|\n", "1809.11051": "|**2018-10-01**|**A ROS-based Software Framework for the NimbRo-OP Humanoid Open Platform**|Philipp Allgeuer,...Sven Behnke|[1809.11051](http://arxiv.org/abs/1809.11051)|null|\n", "1810.08388": "|**2018-10-22**|**Online Balanced Motion Generation for Humanoid Robots**|Grzegorz Ficht,...Sven Behnke|[1810.08388](http://arxiv.org/abs/1810.08388)|null|\n", "1607.04763": "|**2016-07-19**|**Design and implementation of computational platform for social-humanoid robot Lumen as an exhibition guide in Electrical Engineering Days 2015**|Ahmad Syarif,...Ary Setijadi Prihatmanto|[1607.04763](http://arxiv.org/abs/1607.04763)|null|\n", "2210.10151": "|**2022-10-20**|**Dialogue system with humanoid robot**|Koki Inoue,...Naoki Igo|[2210.10151](http://arxiv.org/abs/2210.10151)|null|\n", "1809.11144": "|**2018-10-01**|**NimbRo-OP2: Grown-up 3D Printed Open Humanoid Platform for Research**|Grzegorz Ficht,...Sven Behnke|[1809.11144](http://arxiv.org/abs/1809.11144)|null|\n", "1411.3525": "|**2016-11-18**|**Gaze Stabilization for Humanoid Robots: a Comprehensive Framework**|Alessandro Roncone,...Lorenzo Natale|[1411.3525](http://arxiv.org/abs/1411.3525)|null|\n", "2502.12152": "|**2025-04-29**|**Learning Getting-Up Policies for Real-World Humanoid Robots**|Xialin He,...Saurabh Gupta|[2502.12152](http://arxiv.org/abs/2502.12152)|**[link](https://humanoid-getup.github.io/)**|\n", "2312.08820": "|**2023-12-29**|**How to Raise a Robot -- A Case for Neuro-Symbolic AI in Constrained Task Planning for Humanoid Assistive Robots**|Niklas Hemken,...Hannes Hartenstein|[2312.08820](http://arxiv.org/abs/2312.08820)|**[link](https://dl.acm.org/doi/abs/10.1145/3589608.3595078)**|\n", "2104.09025": "|**2021-04-20**|**The MIT Humanoid Robot: Design, Motion Planning, and Control For Acrobatic Behaviors**|Matthew Chignoli,...Sangbae Kim|[2104.09025](http://arxiv.org/abs/2104.09025)|null|\n", "1610.02849": "|**2017-01-11**|**Automatic Gain Tuning of a Momentum Based Balancing Controller for Humanoid Robots**|Daniele Pucci,...Francesco Nori|[1610.02849](http://arxiv.org/abs/1610.02849)|null|\n", "1810.08395": "|**2018-10-22**|**NimbRo-OP2X: Adult-sized Open-source 3D Printed Humanoid Robot**|Grzegorz Ficht,...Sven Behnke|[1810.08395](http://arxiv.org/abs/1810.08395)|null|\n", "2505.16478": "|**2025-08-11**|**Unified Multi-Rate Model Predictive Control for a Jet-Powered Humanoid Robot**|Davide Gorbani,...Daniele Pucci|[2505.16478](http://arxiv.org/abs/2505.16478)|null|\n", "1909.10080": "|**2019-09-24**|**Whole-Body Geometric Retargeting for Humanoid Robots**|Kourosh Darvish,...Daniele Pucci|[1909.10080](http://arxiv.org/abs/1909.10080)|null|\n", "1909.02385": "|**2019-09-06**|**NimbRo Robots Winning RoboCup 2018 Humanoid AdultSize Soccer Competitions**|Hafez Farazi,...Sven Behnke|[1909.02385](http://arxiv.org/abs/1909.02385)|null|\n", "2410.12773": "|**2024-10-17**|**Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions**|Zhenyu Jiang,...Yuke Zhu|[2410.12773](http://arxiv.org/abs/2410.12773)|**[link](https://ut-austin-rpl.github.io/Harmon/)**|\n", "1607.08525": "|**2017-07-18**|**Walking of the iCub humanoid robot in different scenarios: implementation and performance analysis**|Yue Hu,...Katja Mombaur|[1607.08525](http://arxiv.org/abs/1607.08525)|null|\n", "1607.08089": "|**2017-01-16**|**Walking on Partial Footholds Including Line Contacts with the Humanoid Robot Atlas**|Georg Wiedebach,...Jerry Pratt|[1607.08089](http://arxiv.org/abs/1607.08089)|null|\n", "2509.04722": "|**2025-09-08**|**Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots**|Adrian B. Ghansah,...Aaron D. Ames|[2509.04722](http://arxiv.org/abs/2509.04722)|null|\n", "2511.10021": "|**2025-11-13**|**DecARt Leg: Design and Evaluation of a Novel Humanoid Robot Leg with Decoupled Actuation for Agile Locomotion**|Egor Davydenko,...Roman Gorbachev|[2511.10021](http://arxiv.org/abs/2511.10021)|null|\n", "2511.09484": "|**2025-11-12**|**SPIDER: Scalable Physics-Informed Dexterous Retargeting**|Chaoyi Pan,...Francois Hogan|[2511.09484](http://arxiv.org/abs/2511.09484)|**[link](https://jc-bao.github.io/spider-project/)**|\n", "2511.09241": "|**2025-11-12**|**Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots**|Yuxi Wei,...Siheng Chen|[2511.09241](http://arxiv.org/abs/2511.09241)|null|\n", "2511.09141": "|**2025-11-12**|**RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation**|Xuetao Li,...Miao Li|[2511.09141](http://arxiv.org/abs/2511.09141)|null|\n", "2510.27420": "|**2025-10-31**|**Towards a Multi-Embodied Grasping Agent**|Roman Freiberg,...Gerhard Neumann|[2510.27420](http://arxiv.org/abs/2510.27420)|null|\n", "2510.26362": "|**2025-10-30**|**Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations**|Tobias L\u00f6w,...Sylvain Calinon|[2510.26362](http://arxiv.org/abs/2510.26362)|null|\n", "2510.26280": "|**2025-11-05**|**Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments**|Gangyang Li,...Shaqi Luo|[2510.26280](http://arxiv.org/abs/2510.26280)|null|\n", "2511.11218": "|**2025-11-14**|**Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning**|Chenhao Liu,...Xiaoyu Ren|[2511.11218](http://arxiv.org/abs/2511.11218)|null|\n", "2511.12390": "|**2025-11-15**|**Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control**|Sanjar Atamuradov,...Sanjar Atamuradov|[2511.12390](http://arxiv.org/abs/2511.12390)|null|\n", "2511.14756": "|**2025-11-18**|**HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation**|Lai Wei,...Xiaolong Wang|[2511.14756](http://arxiv.org/abs/2511.14756)|null|\n", "2511.15200": "|**2025-11-19**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Tairan He,...Yuke Zhu|[2511.15200](http://arxiv.org/abs/2511.15200)|**[link](https://viral-humanoid.github.io/)**|\n", "2511.16306": "|**2025-11-20**|**InEKFormer: A Hybrid State Estimator for Humanoid Robots**|Lasse Hohmeyer,...Frank Kirchner|[2511.16306](http://arxiv.org/abs/2511.16306)|null|\n", "2511.17373": "|**2025-11-24**|**Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data**|Yixuan Pan,...Hongyang Li|[2511.17373](http://arxiv.org/abs/2511.17373)|null|\n", "2511.21169": "|**2025-11-26**|**Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation**|Kaiyan Xiao,...Qijun Chen|[2511.21169](http://arxiv.org/abs/2511.21169)|null|\n", "2511.20275": "|**2025-12-04**|**HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments**|Chenhui Dong,...Bin He|[2511.20275](http://arxiv.org/abs/2511.20275)|null|\n", "2511.19236": "|**2025-11-24**|**SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control**|Yuxuan Wang,...Zongqing Lu|[2511.19236](http://arxiv.org/abs/2511.19236)|null|\n", "2511.19204": "|**2025-11-24**|**Reference-Free Sampling-Based Model Predictive Control**|Fabian Schramm,...Justin Carpentier|[2511.19204](http://arxiv.org/abs/2511.19204)|null|\n", "2511.18857": "|**2025-11-24**|**AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion**|Changsheng Luo,...Mingguo Zhao|[2511.18857](http://arxiv.org/abs/2511.18857)|null|\n", "2511.18509": "|**2025-11-23**|**SafeFall: Learning Protective Control for Humanoid Robots**|Ziyu Meng,...Siyuan Huang|[2511.18509](http://arxiv.org/abs/2511.18509)|null|\n", "2511.17925": "|**2025-11-22**|**Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game**|Jeonghwan Kim,...Tianyu Li|[2511.17925](http://arxiv.org/abs/2511.17925)|null|\n", "2511.17603": "|**2025-11-18**|**Translating Cultural Choreography from Humanoid Forms to Robotic Arm**|Chelsea-Xi Chen,...Aven-Le Zhou|[2511.17603](http://arxiv.org/abs/2511.17603)|null|\n", "2512.02729": "|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Yuhong Zhang,...Haoqian Wang|[2512.02729](http://arxiv.org/abs/2512.02729)|null|\n", "2512.01996": "|**2025-12-01**|**Learning Sim-to-Real Humanoid Locomotion in 15 Minutes**|Younggyo Seo,...Pieter Abbeel|[2512.01996](http://arxiv.org/abs/2512.01996)|**[link](https://younggyo.me/fastsac-humanoid)**|\n", "2512.01358": "|**2025-12-01**|**Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1**|Junsung Park,...Songhwai Oh|[2512.01358](http://arxiv.org/abs/2512.01358)|null|\n", "2512.01336": "|**2025-12-01**|**Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning**|Diyuan Shi,...Donglin Wang|[2512.01336](http://arxiv.org/abs/2512.01336)|null|\n", "2512.01061": "|**2025-11-30**|**Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer**|Haoru Xue,...Yuke Zhu|[2512.01061](http://arxiv.org/abs/2512.01061)|**[link](https://doorman-humanoid.github.io/)**|\n", "2512.01022": "|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Yi-Lin Wei,...Wei-Shi Zheng|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|\n", "2512.00971": "|**2025-11-30**|**H-Zero: Cross-Humanoid Locomotion Pretraining Enables Few-shot Novel Embodiment Transfer**|Yunfeng Lin,...Weinan Zhang|[2512.00971](http://arxiv.org/abs/2512.00971)|null|\n", "2512.00783": "|**2025-12-02**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang,...Libo Wang|[2512.00783](http://arxiv.org/abs/2512.00783)|**[link](https://huggingface.co/Veltraxor/Sigma)**|\n", "2511.23300": "|**2025-11-28**|**SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot**|Yara Mahmoud,...Dzmitry Tsetserukou|[2511.23300](http://arxiv.org/abs/2511.23300)|null|\n", "2511.22963": "|**2025-11-28**|**Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**|Zhirui Liu,...Jingya Wang|[2511.22963](http://arxiv.org/abs/2511.22963)|**[link](https://humanoidlla.github.io/)**|\n", "2512.00077": "|**2025-11-25**|**A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs**|Bowen Zhi,...Bowen Zhi|[2512.00077](http://arxiv.org/abs/2512.00077)|null|\n", "2512.05094": "|**2025-12-11**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|James Ni,...Roei Herzig|[2512.05094](http://arxiv.org/abs/2512.05094)|**[link](https://genmimic.github.io)**|\n", "2512.04973": "|**2025-12-04**|**Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist**|Giuseppe Milazzo,...Giorgio Grioli|[2512.04973](http://arxiv.org/abs/2512.04973)|**[link](https://doi.org/10.1007/978-3-031-64057-5_9)**|\n", "2512.04537": "|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Pei Yang,...Mike Zheng Shou|[2512.04537](http://arxiv.org/abs/2512.04537)|null|\n", "2512.07819": "|**2025-12-08**|**Efficient and Compliant Control Framework for Versatile Human-Humanoid Collaborative Transportation**|Shubham S. Kumbhar,...Panagiotis Artemiadis|[2512.07819](http://arxiv.org/abs/2512.07819)|null|\n", "2512.07464": "|**2025-12-08**|**Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction**|Haolin Song,...Houqiang Li|[2512.07464](http://arxiv.org/abs/2512.07464)|null|\n", "2512.07041": "|**2025-12-07**|**CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation**|Hiroki Sawada,...Mathias Quoy|[2512.07041](http://arxiv.org/abs/2512.07041)|null|\n", "2512.06571": "|**2025-12-10**|**Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input**|Zifan Xu,...Peter Stone|[2512.06571](http://arxiv.org/abs/2512.06571)|null|\n", "2512.10477": "|**2025-12-14**|**Symphony: A Heuristic Normalized Calibrated Advantage Actor and Critic Algorithm in application for Humanoid Robots**|Timur Ishuov,...J\u00f3zsef Dombi|[2512.10477](http://arxiv.org/abs/2512.10477)|**[link](https://github.com/SuspensionRailway/symphony)**|\n", "2512.09431": "|**2025-12-10**|**A Hierarchical, Model-Based System for High-Performance Humanoid Soccer**|Quanyou Wang,...Dennis W. Hong|[2512.09431](http://arxiv.org/abs/2512.09431)|null|\n", "2512.08518": "|**2025-12-10**|**SensHRPS: Sensing Comfortable Human-Robot Proxemics and Personal Space With Eye-Tracking**|Nadezhda Kushina,...Karsten Berns|[2512.08518](http://arxiv.org/abs/2512.08518)|null|\n", "2512.08952": "|**2025-11-28**|**Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis**|Filippo Cenacchi,...Longbing Cao|[2512.08952](http://arxiv.org/abs/2512.08952)|null|\n", "2512.11047": "|**2025-12-15**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Haoran Jiang,...Hongyang Li|[2512.11047](http://arxiv.org/abs/2512.11047)|null|\n", "2512.14689": "|**2025-12-16**|**CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation**|Sirui Chen,...Yuke Zhu|[2512.14689](http://arxiv.org/abs/2512.14689)|**[link](https://nvlabs.github.io/CHIP/)**|\n", "2512.13304": "|**2025-12-15**|**Humanoid Robot Running Through Random Stepping Stones and Jumping Over Obstacles: Step Adaptation Using Spring-Mass Trajectories**|Sait Sovukluk,...Christian Ott|[2512.13304](http://arxiv.org/abs/2512.13304)|**[link](https://youtu.be/HlAg2nbNct4)**|\n", "2512.13093": "|**2025-12-15**|**PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations**|Mingqi Yuan,...Wenjun Zeng|[2512.13093](http://arxiv.org/abs/2512.13093)|null|\n", "2512.12437": "|**2025-12-13**|**Sim2Real Reinforcement Learning for Soccer skills**|Jonathan Spraggett,...Jonathan Spraggett|[2512.12437](http://arxiv.org/abs/2512.12437)|null|\n", "2512.12230": "|**2025-12-13**|**Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy**|Jonathan Spraggett,...Jonathan Spraggett|[2512.12230](http://arxiv.org/abs/2512.12230)|null|\n", "2512.12208": "|**2025-12-13**|**A Hybrid Deep Learning Framework for Emotion Recognition in Children with Autism During NAO Robot-Mediated Interaction**|Indranil Bhattacharjee,...Bishakh Bhattacharya|[2512.12208](http://arxiv.org/abs/2512.12208)|null|\n"}, "3DGS/NeRF": {"2509.20774": "|**2025-09-25**|**Gaussian splatting holography**|Shuhe Zhang,...Liangcai Cao|[2509.20774](http://arxiv.org/abs/2509.20774)|null|\n", "2509.20251": "|**2025-09-24**|**4D Driving Scene Generation With Stereo Forcing**|Hao Lu,...Yingcong Chen|[2509.20251](http://arxiv.org/abs/2509.20251)|null|\n", "2509.19937": "|**2025-09-24**|**GS-RoadPatching: Inpainting Gaussians via 3D Searching and Placing for Driving Scenes**|Guo Chen,...Sheng Yang|[2509.19937](http://arxiv.org/abs/2509.19937)|null|\n", "2509.19898": "|**2025-09-24**|**Aerial-Ground Image Feature Matching via 3D Gaussian Splatting-based Intermediate View Rendering**|Jiangxue Yu,...Qingquan Li|[2509.19898](http://arxiv.org/abs/2509.19898)|null|\n", "2509.19793": "|**2025-09-24**|**BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting**|Yixun Zhang,...Jianqin Yin|[2509.19793](http://arxiv.org/abs/2509.19793)|null|\n", "2509.19726": "|**2025-09-24**|**PolGS: Polarimetric Gaussian Splatting for Fast Reflective Surface Reconstruction**|Yufei Han,...Zhanyu Ma|[2509.19726](http://arxiv.org/abs/2509.19726)|null|\n", "2509.20400": "|**2025-09-23**|**SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing**|Yiyu Li,...Rynson W. H. Lau|[2509.20400](http://arxiv.org/abs/2509.20400)|null|\n", "2509.19297": "|**2025-09-23**|**VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction**|Weijie Wang,...Bohan Zhuang|[2509.19297](http://arxiv.org/abs/2509.19297)|**[link](https://lhmd.top/volsplat)**|\n", "2509.19296": "|**2025-09-23**|**Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation**|Sherwin Bahmani,...Xuanchi Ren|[2509.19296](http://arxiv.org/abs/2509.19296)|**[link](https://research.nvidia.com/labs/toronto-ai/lyra/)**|\n", "2509.19073": "|**2025-09-23**|**WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction**|Hung Nguyen,...Truong Nguyen|[2509.19073](http://arxiv.org/abs/2509.19073)|null|\n", "2509.18956": "|**2025-09-23**|**Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting**|Zijing Guo,...Lin Wang|[2509.18956](http://arxiv.org/abs/2509.18956)|null|\n", "2509.18898": "|**2025-09-23**|**DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring**|Pengteng Li,...Hui Xiong|[2509.18898](http://arxiv.org/abs/2509.18898)|null|\n", "2509.18759": "|**2025-09-23**|**FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation**|Zhaorui Wang,...Renjing Xu|[2509.18759](http://arxiv.org/abs/2509.18759)|null|\n", "2509.18610": "|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Maximilian Adang,...Mac Schwager|[2509.18610](http://arxiv.org/abs/2509.18610)|null|\n", "2509.18566": "|**2025-09-23**|**Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction**|Xiaoting Yin,...Kaiwei Wang|[2509.18566](http://arxiv.org/abs/2509.18566)|null|\n", "2509.18501": "|**2025-09-23**|**BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting for Deformable Intraoperative Surgical Navigation**|Maximilian Fehrentz,...Nassir Navab|[2509.18501](http://arxiv.org/abs/2509.18501)|null|\n", "2509.18497": "|**2025-09-23**|**Differentiable Light Transport with Gaussian Surfels via Adapted Radiosity for Efficient Relighting and Geometry Reconstruction**|Kaiwen Jiang,...Ravi Ramamoorthi|[2509.18497](http://arxiv.org/abs/2509.18497)|null|\n", "2509.18090": "|**2025-09-22**|**GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction**|Jiahe Li,...Lin Gu|[2509.18090](http://arxiv.org/abs/2509.18090)|**[link](https://fictionarry.github.io/GeoSVR-project/)**|\n", "2509.17889": "|**2025-09-22**|**GaussianPSL: A novel framework based on Gaussian Splatting for exploring the Pareto frontier in multi-criteria optimization**|Phuong Mai Dinh,...Van-Nam Huynh|[2509.17889](http://arxiv.org/abs/2509.17889)|null|\n", "2509.17864": "|**2025-09-22**|**ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos**|Shi Chen,...Martin R. Oswald|[2509.17864](http://arxiv.org/abs/2509.17864)|null|\n", "2509.22615": "|**2025-09-26**|**Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting**|Yasmine Omri,...Thierry Tambe|[2509.22615](http://arxiv.org/abs/2509.22615)|null|\n", "2509.22276": "|**2025-09-26**|**GS-2M: Gaussian Splatting for Joint Mesh Reconstruction and Material Decomposition**|Dinh Minh Nguyen,...Thomas Lindemeier|[2509.22276](http://arxiv.org/abs/2509.22276)|null|\n", "2509.22225": "|**2025-09-26**|**Polysemous Language Gaussian Splatting via Matching-based Mask Lifting**|Jiayu Ding,...Ge Li|[2509.22225](http://arxiv.org/abs/2509.22225)|null|\n", "2509.22112": "|**2025-09-26**|**Large Material Gaussian Model for Relightable 3D Generation**|Jingrui Ye,...Qingmin Liao|[2509.22112](http://arxiv.org/abs/2509.22112)|null|\n", "2509.21888": "|**2025-09-26**|**Drag4D: Align Your Motion with Text-Driven 3D Scene Generation**|Minjun Kang,...Kuk-Jin Yoon|[2509.21888](http://arxiv.org/abs/2509.21888)|null|\n", "2509.21853": "|**2025-09-30**|**Dynamic Novel View Synthesis in High Dynamic Range**|Kaixuan Zhang,...Xiatian Zhu|[2509.21853](http://arxiv.org/abs/2509.21853)|null|\n", "2509.21702": "|**2025-09-25**|**PowerGS: Display-Rendering Power Co-Optimization for Neural Rendering in Power-Constrained XR Systems**|Weikai Lin,...Yuhao Zhu|[2509.21702](http://arxiv.org/abs/2509.21702)|null|\n", "2509.25122": "|**2025-09-29**|**Triangle Splatting+: Differentiable Rendering with Opaque Triangles**|Jan Held,...Andrea Tagliasacchi|[2509.25122](http://arxiv.org/abs/2509.25122)|null|\n", "2509.25075": "|**2025-10-02**|**GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction**|Huaizhi Qu,...Tianlong Chen|[2509.25075](http://arxiv.org/abs/2509.25075)|null|\n", "2509.25001": "|**2025-09-29**|**LVT: Large-Scale Scene Reconstruction via Local View Transformers**|Tooba Imtiaz,...John Flynn|[2509.25001](http://arxiv.org/abs/2509.25001)|**[link](https://toobaimt.github.io/lvt/)**|\n", "2509.24893": "|**2025-09-29**|**DWGS: Enhancing Sparse-View Gaussian Splatting with Hybrid-Loss Depth Estimation and Bidirectional Warping**|Yu Ma,...Yue Cheng|[2509.24893](http://arxiv.org/abs/2509.24893)|null|\n", "2509.24758": "|**2025-09-29**|**ExGS: Extreme 3D Gaussian Compression with Diffusion Priors**|Jiaqi Chen,...Xiao Sun|[2509.24758](http://arxiv.org/abs/2509.24758)|null|\n", "2509.24421": "|**2025-10-01**|**Proxy-GS: Efficient 3D Gaussian Splatting via Proxy Mesh**|Yuanyuan Gao,...Xiao Sun|[2509.24421](http://arxiv.org/abs/2509.24421)|null|\n", "2509.24308": "|**2025-09-29**|**OMeGa: Joint Optimization of Explicit Meshes and Gaussian Splats for Robust Scene-Level Surface Reconstruction**|Yuhang Cao,...Danya Yao|[2509.24308](http://arxiv.org/abs/2509.24308)|null|\n", "2509.23947": "|**2025-09-28**|**CrashSplat: 2D to 3D Vehicle Damage Segmentation in Gaussian Splatting**|Drago\u015f-Andrei Chileban,...Cosmin Cern\u01cezanu-Gl\u01cevan|[2509.23947](http://arxiv.org/abs/2509.23947)|null|\n", "2509.23555": "|**2025-09-28**|**From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations**|Javed Ahmad,...Yonas Teodros Tefera|[2509.23555](http://arxiv.org/abs/2509.23555)|null|\n", "2509.23492": "|**2025-09-27**|**Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual Videos**|Junyi Wu,...Yan Yan|[2509.23492](http://arxiv.org/abs/2509.23492)|**[link](https://github.com/adreamwu/OriGS}{OriGS})**|\n", "2509.23258": "|**2025-09-27**|**OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting**|Atakan Topaloglu,...Federico Tombari|[2509.23258](http://arxiv.org/abs/2509.23258)|null|\n", "2509.22917": "|**2025-09-26**|**Learning Unified Representation of 3D Gaussian Splatting**|Yuelin Xin,...Xinke Li|[2509.22917](http://arxiv.org/abs/2509.22917)|null|\n", "2509.26621": "|**2025-09-30**|**HART: Human Aligned Reconstruction Transformer**|Xiyi Chen,...Ming Lin|[2509.26621](http://arxiv.org/abs/2509.26621)|**[link](https://xiyichen.github.io/hart)**|\n", "2509.26455": "|**2025-09-30**|**Stylos: Multi-View 3D Stylization with Single-Forward Gaussian Splatting**|Hanzhou Liu,...Peng Jiang|[2509.26455](http://arxiv.org/abs/2509.26455)|null|\n", "2509.26055": "|**2025-09-30**|**GaussEdit: Adaptive 3D Scene Editing with Text and Image Prompts**|Zhenyu Shu,...Ligang Liu|[2509.26055](http://arxiv.org/abs/2509.26055)|null|\n", "2509.26008": "|**2025-09-30**|**PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion**|Zhiwei Zhang,...Lizhuang Ma|[2509.26008](http://arxiv.org/abs/2509.26008)|null|\n", "2509.25626": "|**2025-09-30**|**LLM-Powered Code Analysis and Optimization for Gaussian Splatting Kernels**|Yi Hu,...Huiyang Zhou|[2509.25626](http://arxiv.org/abs/2509.25626)|null|\n", "2509.25603": "|**2025-09-29**|**GaussianLens: Localized High-Resolution Reconstruction via On-Demand Gaussian Densification**|Yijia Weng,...Leonidas J. Guibas|[2509.25603](http://arxiv.org/abs/2509.25603)|null|\n", "2510.02314": "|**2025-10-02**|**StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions**|Bo-Hsu Ke,...Wei-Chen Chiu|[2510.02314](http://arxiv.org/abs/2510.02314)|**[link](https://hentci.github.io/stealthattack/)**|\n", "2510.02248": "|**2025-10-02**|**Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0**|Yan Miao,...Sayan Mitra|[2510.02248](http://arxiv.org/abs/2510.02248)|null|\n", "2510.02069": "|**2025-10-02**|**Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects**|Georgios Kouros,...Tinne Tuytelaars|[2510.02069](http://arxiv.org/abs/2510.02069)|null|\n", "2510.02034": "|**2025-10-02**|**GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing**|Mengtian Li,...Chaofeng Chen|[2510.02034](http://arxiv.org/abs/2510.02034)|**[link](https://baiyunshu.github.io/GAUSSIANMORPHING.github.io/)**|\n", "2510.01991": "|**2025-10-02**|**4DGS-Craft: Consistent and Interactive 4D Gaussian Splatting Editing**|Lei Liu,...Dong Xu|[2510.01991](http://arxiv.org/abs/2510.01991)|null|\n", "2510.01978": "|**2025-10-02**|**ROI-GS: Interest-based Local Quality 3D Gaussian Splatting**|Quoc-Anh Bui,...Simone Gasparini|[2510.01978](http://arxiv.org/abs/2510.01978)|null|\n", "2510.01848": "|**2025-10-02**|**GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics**|Diram Tabaa,...Gianni Di Caro|[2510.01848](http://arxiv.org/abs/2510.01848)|null|\n", "2510.01767": "|**2025-10-02**|**LOBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for Large-Scale Scene Reconstruction**|Sheng-Hsiang Hung,...Hung-Kuo Chu|[2510.01767](http://arxiv.org/abs/2510.01767)|null|\n", "2510.01619": "|**2025-10-02**|**MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics**|Changmin Lee,...Tae-Kyun Kim|[2510.01619](http://arxiv.org/abs/2510.01619)|null|\n", "2510.01119": "|**2025-10-01**|**Instant4D: 4D Gaussian Splatting in Minutes**|Zhanpeng Luo,...Li Lu|[2510.01119](http://arxiv.org/abs/2510.01119)|null|\n", "2510.03104": "|**2025-10-03**|**Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields**|Zhiting Mei,...Anirudha Majumdar|[2510.03104](http://arxiv.org/abs/2510.03104)|null|\n", "2510.02884": "|**2025-10-03**|**GS-Share: Enabling High-fidelity Map Sharing with Incremental Gaussian Splatting**|Xinran Zhang,...Yanyong Zhang|[2510.02884](http://arxiv.org/abs/2510.02884)|null|\n", "2510.02732": "|**2025-10-03**|**From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting**|Jianing Chen,...Yucheng Zhang|[2510.02732](http://arxiv.org/abs/2510.02732)|null|\n", "2510.02691": "|**2025-10-03**|**FSFSplatter: Build Surface and Novel Views with Sparse-Views within 3min**|Yibin Zhao,...Jianjun Yi|[2510.02691](http://arxiv.org/abs/2510.02691)|null|\n", "2510.02469": "|**2025-10-02**|**SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting**|Sung-Yeon Park,...Ziran Wang|[2510.02469](http://arxiv.org/abs/2510.02469)|null|\n", "2510.03857": "|**2025-10-04**|**Optimized Minimal 4D Gaussian Splatting**|Minseo Lee,...Eunbyung Park|[2510.03857](http://arxiv.org/abs/2510.03857)|null|\n", "2510.03545": "|**2025-10-03**|**SketchPlan: Diffusion Based Drone Planning From Human Sketches**|Sixten Norelius,...Mac Schwager|[2510.03545](http://arxiv.org/abs/2510.03545)|**[link](https://github.com/sixnor/SketchPlan)**|\n", "2510.03312": "|**2025-09-30**|**Universal Beta Splatting**|Rong Liu,...Ziyan Wu|[2510.03312](http://arxiv.org/abs/2510.03312)|null|\n", "2510.05488": "|**2025-10-07**|**ArchitectHead: Continuous Level of Detail Control for 3D Gaussian Head Avatars**|Peizhi Yan,...Shan Du|[2510.05488](http://arxiv.org/abs/2510.05488)|null|\n", "2510.06967": "|**2025-10-08**|**Generating Surface for Text-to-3D using 2D Gaussian Splatting**|Huanning Dong,...Jianwen Min|[2510.06967](http://arxiv.org/abs/2510.06967)|null|\n", "2510.06802": "|**2025-10-08**|**Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity**|Islomjon Shukhratov,...Sergey Gorinsky|[2510.06802](http://arxiv.org/abs/2510.06802)|null|\n", "2510.06694": "|**2025-10-08**|**SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis**|Jipeng Lyu,...Yu-Xiong Wang|[2510.06694](http://arxiv.org/abs/2510.06694)|null|\n", "2510.06644": "|**2025-10-09**|**RTGS: Real-Time 3D Gaussian Splatting SLAM via Multi-Level Redundancy Reduction**|Leshu Li,...Yang Katie Zhao|[2510.06644](http://arxiv.org/abs/2510.06644)|null|\n", "2510.06481": "|**2025-10-07**|**Active Next-Best-View Optimization for Risk-Averse Path Planning**|Amirhossein Mollaei Khass,...Nader Motee|[2510.06481](http://arxiv.org/abs/2510.06481)|null|\n", "2510.08575": "|**2025-10-09**|**ReSplat: Learning Recurrent Gaussian Splats**|Haofei Xu,...Marc Pollefeys|[2510.08575](http://arxiv.org/abs/2510.08575)|**[link](https://haofeixu.github.io/resplat/)**|\n", "2510.08566": "|**2025-10-09**|**D$^2$GS: Depth-and-Density Guided Gaussian Splatting for Stable and Accurate Sparse-View Reconstruction**|Meixi Song,...Lu Qi|[2510.08566](http://arxiv.org/abs/2510.08566)|null|\n", "2510.08491": "|**2025-10-09**|**Splat the Net: Radiance Fields with Splattable Neural Primitives**|Xilong Zhou,...Christian Theobalt|[2510.08491](http://arxiv.org/abs/2510.08491)|null|\n", "2510.08096": "|**2025-10-09**|**Efficient Label Refinement for Face Parsing Under Extreme Poses Using 3D Gaussian Splatting**|Ankit Gahlawat,...Dinesh Babu Jayagopi|[2510.08096](http://arxiv.org/abs/2510.08096)|null|\n", "2510.07944": "|**2025-10-09**|**CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving**|Tianrui Zhang,...Zehuan Wu|[2510.07944](http://arxiv.org/abs/2510.07944)|null|\n", "2510.07830": "|**2025-10-09**|**PrismGS: Physically-Grounded Anti-Aliasing for High-Fidelity Large-Scale 3D Gaussian Splatting**|Houqiang Zhong,...Qiang Hu|[2510.07830](http://arxiv.org/abs/2510.07830)|null|\n", "2510.07752": "|**2025-10-09**|**DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream**|Junhao He,...Renjing Xu|[2510.07752](http://arxiv.org/abs/2510.07752)|null|\n", "2510.07729": "|**2025-10-09**|**ComGS: Efficient 3D Object-Scene Composition via Surface Octahedral Probes**|Jian Gao,...Yao Yao|[2510.07729](http://arxiv.org/abs/2510.07729)|null|\n", "2510.09586": "|**2025-10-10**|**Vision Language Models: A Survey of 26K Papers**|Fengming Lin,...Fengming Lin|[2510.09586](http://arxiv.org/abs/2510.09586)|null|\n", "2510.09537": "|**2025-10-10**|**FLOWING: Implicit Neural Flows for Structure-Preserving Morphing**|Arthur Bizzi,...Tiago Novello|[2510.09537](http://arxiv.org/abs/2510.09537)|null|\n", "2510.09489": "|**2025-10-10**|**Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction**|Deborah Pintani,...Andrea Giachetti|[2510.09489](http://arxiv.org/abs/2510.09489)|null|\n", "2510.09364": "|**2025-10-10**|**Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes**|Yikang Zhang,...Rui Fan|[2510.09364](http://arxiv.org/abs/2510.09364)|null|\n", "2510.11717": "|**2025-10-13**|**Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams**|Takuya Nakabayashi,...Vladislav Golyanik|[2510.11717](http://arxiv.org/abs/2510.11717)|null|\n", "2510.11689": "|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Maggie Wang,...Mac Schwager|[2510.11689](http://arxiv.org/abs/2510.11689)|null|\n", "2510.11473": "|**2025-10-13**|**VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment**|Qing Li,...Yu-Shen Liu|[2510.11473](http://arxiv.org/abs/2510.11473)|null|\n", "2510.11387": "|**2025-10-13**|**MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference**|Wenyuan Zhang,...Zhizhong Han|[2510.11387](http://arxiv.org/abs/2510.11387)|**[link](https://wen-yuan-zhang.github.io/MaterialRefGS)**|\n", "2510.10691": "|**2025-10-12**|**Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos**|Xuankai Zhang,...Qing Zhang|[2510.10691](http://arxiv.org/abs/2510.10691)|null|\n", "2510.10637": "|**2025-10-12**|**High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting**|Haoyu Zhao,...Hua Zou|[2510.10637](http://arxiv.org/abs/2510.10637)|null|\n", "2510.10492": "|**2025-10-12**|**Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework**|Shanzhi Yin,...Yan Ye|[2510.10492](http://arxiv.org/abs/2510.10492)|null|\n", "2510.10257": "|**2025-10-11**|**Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting**|Abdelrhman Elrawy,...Emad A. Mohammed|[2510.10257](http://arxiv.org/abs/2510.10257)|null|\n", "2510.10152": "|**2025-10-11**|**Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer**|Yecong Wan,...Wangmeng Zuo|[2510.10152](http://arxiv.org/abs/2510.10152)|**[link](https://yecongwan.github.io/Color3D/)**|\n", "2510.10097": "|**2025-10-11**|**Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting**|Jiahui Lu,...Wenxiong Kang|[2510.10097](http://arxiv.org/abs/2510.10097)|null|\n", "2510.10030": "|**2025-10-11**|**P-4DGS: Predictive 4D Gaussian Splatting with 90$\\times$ Compression**|Henan Wang,...Zhibo Chen|[2510.10030](http://arxiv.org/abs/2510.10030)|null|\n", "2510.09997": "|**2025-10-11**|**CLoD-GS: Continuous Level-of-Detail via 3D Gaussian Splatting**|Zhigang Cheng,...Peng Pan|[2510.09997](http://arxiv.org/abs/2510.09997)|null|\n", "2510.09962": "|**2025-10-11**|**VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping**|Yicheng He,...Hong Zhang|[2510.09962](http://arxiv.org/abs/2510.09962)|null|\n", "2510.09881": "|**2025-10-10**|**LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates**|Minkwan Kim,...Young Min Kim|[2510.09881](http://arxiv.org/abs/2510.09881)|null|\n", "2510.12768": "|**2025-10-14**|**Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction**|Fengzhi Guo,...Cheng Zhang|[2510.12768](http://arxiv.org/abs/2510.12768)|**[link](https://tamu-visual-ai.github.io/usplat4d/)**|\n", "2510.12493": "|**2025-10-17**|**BSGS: Bi-stage 3D Gaussian Splatting for Camera Motion Deblurring**|An Zhao,...Mingqiang Wei|[2510.12493](http://arxiv.org/abs/2510.12493)|null|\n", "2510.12308": "|**2025-10-14**|**Hybrid Gaussian Splatting for Novel Urban View Synthesis**|Mohamed Omran,...Amirhossein Habibian|[2510.12308](http://arxiv.org/abs/2510.12308)|null|\n", "2510.12282": "|**2025-10-14**|**PAGS: Priority-Adaptive Gaussian Splatting for Dynamic Driving Scenes**|Ying A,...Jianxun Cui|[2510.12282](http://arxiv.org/abs/2510.12282)|null|\n", "2510.12174": "|**2025-10-14**|**UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering**|Yusen Xie,...Jun Ma|[2510.12174](http://arxiv.org/abs/2510.12174)|null|\n", "2510.12099": "|**2025-10-14**|**G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior**|Junfeng Ni,...Siyuan Huang|[2510.12099](http://arxiv.org/abs/2510.12099)|**[link](https://dali-jack.github.io/g4splat-web/)**|\n", "2510.11878": "|**2025-10-13**|**GS-Verse: Mesh-based Gaussian Splatting for Physics-aware Interaction in Virtual Reality**|Anastasiya Pechko,...Przemys\u0142aw Spurek|[2510.11878](http://arxiv.org/abs/2510.11878)|null|\n", "2510.13454": "|**2025-10-15**|**VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator**|Hyojun Go,...Konrad Schindler|[2510.13454](http://arxiv.org/abs/2510.13454)|**[link](https://gohyojun15.github.io/VIST3A/)**|\n", "2510.13381": "|**2025-10-15**|**Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering**|Siddharth Tourani,...Muhammad Haris Khan|[2510.13381](http://arxiv.org/abs/2510.13381)|**[link](https://dynamic-ugsdf.github.io/)**|\n", "2510.13186": "|**2025-10-15**|**STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control**|Zhen Li,...Chengzhong Xu|[2510.13186](http://arxiv.org/abs/2510.13186)|null|\n", "2510.14705": "|**2025-10-16**|**Leveraging Learned Image Prior for 3D Gaussian Compression**|Seungjoo Shin,...Sunghyun Cho|[2510.14705](http://arxiv.org/abs/2510.14705)|null|\n", "2510.14564": "|**2025-10-16**|**BalanceGS: Algorithm-System Co-design for Efficient 3D Gaussian Splatting Training on GPU**|Junyi Wu,...Guohao Dai|[2510.14564](http://arxiv.org/abs/2510.14564)|null|\n", "2510.14270": "|**2025-10-16**|**GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering**|Alexander Valverde,...Hongyun Wang|[2510.14270](http://arxiv.org/abs/2510.14270)|null|\n", "2510.14179": "|**2025-10-16**|**Virtually Being: Customizing Camera-Controllable Video Diffusion Models with Multi-View Performance Captures**|Yuancheng Xu,...Ning Yu|[2510.14179](http://arxiv.org/abs/2510.14179)|null|\n", "2510.14081": "|**2025-10-17**|**Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from Unstructured Phone Images**|Emanuel Garbin,...Shunsuke Saito|[2510.14081](http://arxiv.org/abs/2510.14081)|null|\n", "2510.13978": "|**2025-10-15**|**Instant Skinned Gaussian Avatars for Web, Mobile and VR Applications**|Naruya Kondo,...Yoichi Ochiai|[2510.13978](http://arxiv.org/abs/2510.13978)|null|\n", "2510.15386": "|**2025-10-17**|**PFGS: Pose-Fused 3D Gaussian Splatting for Complete Multi-Pose Object Reconstruction**|Ting-Yu Yen,...Hung-Kuo Chu|[2510.15386](http://arxiv.org/abs/2510.15386)|null|\n", "2510.15352": "|**2025-10-17**|**GaussGym: An open-source real-to-sim framework for learning locomotion from pixels**|Alejandro Escontrela,...Pieter Abbeel|[2510.15352](http://arxiv.org/abs/2510.15352)|null|\n", "2510.15072": "|**2025-10-16**|**SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images**|Jiaxin Guo,...Yun-Hui Liu|[2510.15072](http://arxiv.org/abs/2510.15072)|null|\n", "2510.17783": "|**2025-10-20**|**Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant Structures with Gaussian Splats**|Simeon Adebola,...Ken Goldberg|[2510.17783](http://arxiv.org/abs/2510.17783)|null|\n", "2510.17719": "|**2025-10-20**|**Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions**|Zhiqiang Teng,...Shunli Zhang|[2510.17719](http://arxiv.org/abs/2510.17719)|null|\n", "2510.17479": "|**2025-10-20**|**Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS**|Feng Zhou,...Jianqin Yin|[2510.17479](http://arxiv.org/abs/2510.17479)|null|\n", "2510.17095": "|**2025-10-20**|**GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation**|Ruitong Gan,...Zhaoxiang Zhang|[2510.17095](http://arxiv.org/abs/2510.17095)|null|\n", "2510.16837": "|**2025-10-19**|**2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting**|Haofan Ren,...Zunjie Zhu|[2510.16837](http://arxiv.org/abs/2510.16837)|null|\n", "2510.16777": "|**2025-10-19**|**GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation**|Junbo Li,...Xiangzhi Bai|[2510.16777](http://arxiv.org/abs/2510.16777)|null|\n", "2510.16463": "|**2025-10-18**|**HGC-Avatar: Hierarchical Gaussian Compression for Streamable Dynamic 3D Avatars**|Haocheng Tang,...Chuanmin Jia|[2510.16463](http://arxiv.org/abs/2510.16463)|null|\n", "2510.16410": "|**2025-10-18**|**REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting**|Changyue Shi,...Zhou Yu|[2510.16410](http://arxiv.org/abs/2510.16410)|null|\n", "2510.16272": "|**2025-10-17**|**Proactive Scene Decomposition and Reconstruction**|Baicheng Li,...Hongbin Zha|[2510.16272](http://arxiv.org/abs/2510.16272)|null|\n", "2510.18739": "|**2025-10-21**|**Moving Light Adaptive Colonoscopy Reconstruction via Illumination-Attenuation-Aware 3D Gaussian Splatting**|Hao Wang,...Zhiwei Wang|[2510.18739](http://arxiv.org/abs/2510.18739)|null|\n", "2510.18489": "|**2025-10-21**|**Mono4DGS-HDR: High Dynamic Range 4D Gaussian Splatting from Alternating-exposure Monocular Videos**|Jinfeng Liu,...Dan Xu|[2510.18489](http://arxiv.org/abs/2510.18489)|**[link](https://liujf1226.github.io/Mono4DGS-HDR/)**|\n", "2510.18253": "|**2025-10-21**|**OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion**|Tianyu Huang,...Tongliang Liu|[2510.18253](http://arxiv.org/abs/2510.18253)|null|\n", "2510.18101": "|**2025-10-20**|**From Volume Rendering to 3D Gaussian Splatting: Theory and Applications**|Vitor Pereira Matias,...Tiago Novello|[2510.18101](http://arxiv.org/abs/2510.18101)|null|\n", "2510.18054": "|**2025-10-20**|**HouseTour: A Virtual Real Estate A(I)gent**|Ata \u00c7elen,...Iro Armeni|[2510.18054](http://arxiv.org/abs/2510.18054)|null|\n", "2510.19578": "|**2025-10-22**|**VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction**|Junhong Lin,...Wei Gao|[2510.19578](http://arxiv.org/abs/2510.19578)|null|\n", "2510.19255": "|**2025-10-22**|**Advances in 4D Representation: Geometry, Motion, and Interaction**|Mingrui Zhao,...Hao Zhang|[2510.19255](http://arxiv.org/abs/2510.19255)|**[link](https://mingrui-zhao.github.io/4DRep-GMI/)**|\n", "2510.19210": "|**2025-10-22**|**MoE-GS: Mixture of Experts for Dynamic Gaussian Splatting**|In-Hwan Jin,...Kyeongbo Kong|[2510.19210](http://arxiv.org/abs/2510.19210)|null|\n", "2510.19200": "|**2025-10-22**|**GRASPLAT: Enabling dexterous grasping through novel view synthesis**|Matteo Bortolon,...Alessio Del Bue|[2510.19200](http://arxiv.org/abs/2510.19200)|null|\n", "2510.19653": "|**2025-10-21**|**Re-Activating Frozen Primitives for 3D Gaussian Splatting**|Yuxin Cheng,...Ngai Wong|[2510.19653](http://arxiv.org/abs/2510.19653)|null|\n", "2510.20813": "|**2025-10-23**|**GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation**|Guangqi Jiang,...Xiaolong Wang|[2510.20813](http://arxiv.org/abs/2510.20813)|null|\n", "2510.20335": "|**2025-10-23**|**Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking**|Zixuan Wu,...Liu Ren|[2510.20335](http://arxiv.org/abs/2510.20335)|**[link](https://github.com/ChampagneAndfragrance/Dino_Diffusion_Parking_Official)**|\n", "2510.20238": "|**2025-10-23**|**COS3D: Collaborative Open-Vocabulary 3D Segmentation**|Runsong Zhu,...Chi-Wing Fu|[2510.20238](http://arxiv.org/abs/2510.20238)|**[link](https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D})**|\n", "2510.20027": "|**2025-10-22**|**Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses**|Damian Bowness,...Charalambos Poullis|[2510.20027](http://arxiv.org/abs/2510.20027)|null|\n", "2510.21307": "|**2025-10-24**|**Towards Physically Executable 3D Gaussian for Embodied Navigation**|Bingchen Miao,...Juncheng Li|[2510.21307](http://arxiv.org/abs/2510.21307)|**[link](https://huggingface.co/datasets/spatialverse/InteriorGS)**|\n", "2510.23521": "|**2025-10-27**|**Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation**|Anthony Opipari,...Odest Chadwicke Jenkins|[2510.23521](http://arxiv.org/abs/2510.23521)|null|\n", "2510.23205": "|**2025-10-27**|**VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting**|Hoonhee Cho,...Kuk-Jin Yoon|[2510.23205](http://arxiv.org/abs/2510.23205)|null|\n", "2510.23087": "|**2025-10-27**|**EndoWave: Rational-Wavelet 4D Gaussian Splatting for Endoscopic Reconstruction**|Taoyu Wu,...Limin Yu|[2510.23087](http://arxiv.org/abs/2510.23087)|null|\n", "2510.22973": "|**2025-10-27**|**Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method**|Bohan Li,...Wenjun Zeng|[2510.22973](http://arxiv.org/abs/2510.22973)|**[link](https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation/tree/v2)**|\n", "2510.22930": "|**2025-10-27**|**Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression**|Pranav Saxena,...Pranav Saxena|[2510.22930](http://arxiv.org/abs/2510.22930)|null|\n", "2510.22812": "|**2025-10-26**|**Region-Adaptive Learned Hierarchical Encoding for 3D Gaussian Splatting Data**|Shashank N. Sridhara,...Antonio Ortega|[2510.22812](http://arxiv.org/abs/2510.22812)|null|\n", "2510.22718": "|**2025-10-26**|**Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication**|Yujie Wan,...Chengzhong Xu|[2510.22718](http://arxiv.org/abs/2510.22718)|null|\n", "2510.22669": "|**2025-10-26**|**LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering**|Wenkai Zhu,...Zihang Wang|[2510.22669](http://arxiv.org/abs/2510.22669)|null|\n", "2510.22600": "|**2025-10-26**|**RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience**|Huilin Yin,...Johannes Betz|[2510.22600](http://arxiv.org/abs/2510.22600)|null|\n", "2510.22473": "|**2025-10-26**|**DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss**|Jing Yang,...Yufeng Yang|[2510.22473](http://arxiv.org/abs/2510.22473)|null|\n", "2510.22213": "|**2025-10-25**|**DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum**|Yaokun Li,...Tianfan Xue|[2510.22213](http://arxiv.org/abs/2510.22213)|**[link](https://dynamictree-dev.github.io/DynamicTree.github.io/)**|\n", "2510.24335": "|**2025-10-28**|**NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation**|Mingyu Jeong,...Andrew Jaeyong Choi|[2510.24335](http://arxiv.org/abs/2510.24335)|null|\n", "2510.24118": "|**2025-10-28**|**LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation**|Haotian Zhou,...Huijing Zhao|[2510.24118](http://arxiv.org/abs/2510.24118)|null|\n", "2510.23988": "|**2025-10-28**|**A Survey on Collaborative SLAM with 3D Gaussian Splatting**|Phuc Nguyen Xuan,...Xiem HoangVan|[2510.23988](http://arxiv.org/abs/2510.23988)|null|\n", "2510.23930": "|**2025-10-27**|**PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors**|Xirui Jin,...Wenxian Yu|[2510.23930](http://arxiv.org/abs/2510.23930)|**[link](https://planargs.github.io)**|\n", "2510.25173": "|**2025-11-02**|**D$^2$GS: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction**|Kejing Xia,...Youjian Zhang|[2510.25173](http://arxiv.org/abs/2510.25173)|null|\n", "2510.25129": "|**2025-10-29**|**AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit Structured Gaussians**|Xiyu Zhang,...Guofeng Zhang|[2510.25129](http://arxiv.org/abs/2510.25129)|**[link](https://zju3dv.github.io/AtlasGS/)**|\n", "2510.26786": "|**2025-10-30**|**HEIR: Learning Graph-Based Motion Hierarchies**|Cheng Zheng,...Felix Heide|[2510.26786](http://arxiv.org/abs/2510.26786)|**[link](https://github.com/princeton-computational-imaging/HEIR)**|\n", "2510.26694": "|**2025-10-30**|**The Impact and Outlook of 3D Gaussian Splatting**|Bernhard Kerbl,...Bernhard Kerbl|[2510.26694](http://arxiv.org/abs/2510.26694)|null|\n", "2510.26358": "|**2025-10-30**|**AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM**|Mirko Usuelli,...Matteo Matteucci|[2510.26358](http://arxiv.org/abs/2510.26358)|null|\n", "2510.26166": "|**2025-10-30**|**6D Channel Knowledge Map Construction via Bidirectional Wireless Gaussian Splatting**|Juncong Zhou,...Jie Xu|[2510.26166](http://arxiv.org/abs/2510.26166)|null|\n", "2510.26117": "|**2025-10-30**|**JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting**|Yuxuan Li,...Xianben Yang|[2510.26117](http://arxiv.org/abs/2510.26117)|null|\n", "2510.27318": "|**2025-10-31**|**SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical Endoscopic Reconstruction**|Wenfeng Huang,...Qiong Wang|[2510.27318](http://arxiv.org/abs/2510.27318)|null|\n", "2510.27133": "|**2025-10-31**|**WildfireX-SLAM: A Large-scale Low-altitude RGB-D Dataset for Wildfire SLAM and Beyond**|Zhicong Sun,...Jinxing Hu|[2510.27133](http://arxiv.org/abs/2510.27133)|null|\n", "2510.26921": "|**2025-10-30**|**DC4GS: Directional Consistency-Driven Adaptive Density Control for 3D Gaussian Splatting**|Moonsoo Jeong,...Sungkil Lee|[2510.26921](http://arxiv.org/abs/2510.26921)|**[link](https://github.com/cgskku/dc4gs)**|\n", "2511.02777": "|**2025-11-04**|**PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing**|Antonio Oroz,...Tobias Kirschstein|[2511.02777](http://arxiv.org/abs/2511.02777)|**[link](https://antoniooroz.github.io/PercHead/)**|\n", "2511.02207": "|**2025-11-04**|**Object-Centric 3D Gaussian Splatting for Strawberry Plant Reconstruction and Phenotyping**|Jiajia Li,...Zhaojian Li|[2511.02207](http://arxiv.org/abs/2511.02207)|null|\n", "2511.00560": "|**2025-11-01**|**4D Neural Voxel Splatting: Dynamic Scene Rendering with Voxelized Guassian Splatting**|Chun-Tin Wu,...Jun-Cheng Chen|[2511.00560](http://arxiv.org/abs/2511.00560)|null|\n", "2511.03099": "|**2025-11-05**|**DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs**|Yiyi Miao,...Jionglong Su|[2511.03099](http://arxiv.org/abs/2511.03099)|null|\n", "2511.04665": "|**2025-11-10**|**Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions**|Kaifeng Zhang,...Yunzhu Li|[2511.04665](http://arxiv.org/abs/2511.04665)|**[link](https://real2sim-eval.github.io/)**|\n", "2511.04283": "|**2025-11-06**|**FastGS: Training 3D Gaussian Splatting in 100 Seconds**|Shiwei Ren,...Biao Lu|[2511.04283](http://arxiv.org/abs/2511.04283)|**[link](https://fastgs.github.io/)**|\n", "2511.03992": "|**2025-11-06**|**CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation**|Yuwen Tao,...Yuan Xie|[2511.03992](http://arxiv.org/abs/2511.03992)|null|\n", "2511.05229": "|**2025-11-07**|**4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos**|Mengqi Guo,...Gim Hee Lee|[2511.05229](http://arxiv.org/abs/2511.05229)|null|\n", "2511.05152": "|**2025-11-07**|**Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges**|Adrian Azzarelli,...David R Bull|[2511.05152](http://arxiv.org/abs/2511.05152)|null|\n", "2511.05109": "|**2025-11-07**|**Efficient representation of 3D spatial data for defense-related applications**|Benjamin Kahl,...Michael Arens|[2511.05109](http://arxiv.org/abs/2511.05109)|null|\n", "2511.04951": "|**2025-11-07**|**CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting**|Hexu Zhao,...Aurojit Panda|[2511.04951](http://arxiv.org/abs/2511.04951)|null|\n", "2511.04944": "|**2025-11-07**|**Channel Knowledge Map Construction: Recent Advances and Open Challenges**|Zixiang Ren,...Rui Zhang|[2511.04944](http://arxiv.org/abs/2511.04944)|null|\n", "2511.04797": "|**2025-11-06**|**3D Gaussian Point Encoders**|Jim James,...James Hays|[2511.04797](http://arxiv.org/abs/2511.04797)|null|\n", "2511.07321": "|**2025-11-10**|**YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting**|Botao Ye,...Marc Pollefeys|[2511.07321](http://arxiv.org/abs/2511.07321)|null|\n", "2511.07241": "|**2025-11-10**|**4DSTR: Advancing Generative 4D Gaussians with Spatial-Temporal Rectification for High-Quality and Consistent 4D Generation**|Mengmeng Liu,...Hao Cheng|[2511.07241](http://arxiv.org/abs/2511.07241)|null|\n", "2511.07122": "|**2025-11-10**|**Sparse4DGS: 4D Gaussian Splatting for Sparse-Frame Dynamic Scene Reconstruction**|Changyue Shi,...Jun Yu|[2511.07122](http://arxiv.org/abs/2511.07122)|null|\n", "2511.06953": "|**2025-11-10**|**GFix: Perceptually Enhanced Gaussian Splatting Video Compression**|Siyue Teng,...David Bull|[2511.06953](http://arxiv.org/abs/2511.06953)|null|\n", "2511.06830": "|**2025-11-10**|**MUGSQA: Novel Multi-Uncertainty-Based Gaussian Splatting Quality Assessment Method, Dataset, and Benchmarks**|Tianang Chen,...Weisi Lin|[2511.06830](http://arxiv.org/abs/2511.06830)|null|\n", "2511.06810": "|**2025-11-10**|**ConeGS: Error-Guided Densification Using Pixel Cones for Improved Reconstruction with Fewer Primitives**|Bart\u0142omiej Baranowski,...Andreas Geiger|[2511.06810](http://arxiv.org/abs/2511.06810)|null|\n", "2511.06765": "|**2025-11-10**|**Robust and High-Fidelity 3D Gaussian Splatting: Fusing Pose Priors and Geometry Constraints for Texture-Deficient Outdoor Scenes**|Meijun Guo,...Bin Liang|[2511.06765](http://arxiv.org/abs/2511.06765)|null|\n", "2511.06734": "|**2025-11-10**|**Rethinking Rainy 3D Scene Reconstruction via Perspective Transforming and Brightness Tuning**|Qianfeng Yang,...Jiyu Jin|[2511.06734](http://arxiv.org/abs/2511.06734)|null|\n", "2511.06632": "|**2025-11-10**|**DIAL-GS: Dynamic Instance Aware Reconstruction for Label-free Street Scenes with 4D Gaussian Splatting**|Chenpeng Su,...Hesheng Wang|[2511.06632](http://arxiv.org/abs/2511.06632)|null|\n", "2511.06457": "|**2025-11-09**|**Inpaint360GS: Efficient Object-Aware 3D Inpainting via Gaussian Splatting for 360\u00b0 Scenes**|Shaoxiang Wang,...Alain Pagani|[2511.06457](http://arxiv.org/abs/2511.06457)|**[link](https://dfki-av.github.io/inpaint360gs/)**|\n", "2511.06299": "|**2025-11-11**|**Physics-Informed Deformable Gaussian Splatting: Towards Unified Constitutive Laws for Time-Evolving Material Field**|Haoqin Hong,...Jingrun Chen|[2511.06299](http://arxiv.org/abs/2511.06299)|null|\n", "2511.06046": "|**2025-11-08**|**StreamSTGS: Streaming Spatial and Temporal Gaussian Grids for Real-Time Free-Viewpoint Video**|Zhihui Ke,...Tie Qiu|[2511.06046](http://arxiv.org/abs/2511.06046)|**[link](https://www.github.com/kkkzh/StreamSTGS)**|\n", "2210.00379": "|**2025-08-12**|**NeRF: Neural Radiance Field in 3D Vision: A Comprehensive Review (Updated Post-Gaussian Splatting)**|Kyle Gao,...Jonathan Li|[2210.00379](http://arxiv.org/abs/2210.00379)|null|\n", "2505.06582": "|**2025-05-13**|**Gaussian Wave Splatting for Computer-Generated Holography**|Suyeon Choi,...Gordon Wetzstein|[2505.06582](http://arxiv.org/abs/2505.06582)|**[link](https://bchao1.github.io/gaussian-wave-splatting/)**|\n", "2411.08279": "|**2025-08-11**|**MBA-SLAM: Motion Blur Aware Gaussian Splatting SLAM**|Peng Wang,...Peidong Liu|[2411.08279](http://arxiv.org/abs/2411.08279)|null|\n", "2308.04079": "|**2023-08-09**|**3D Gaussian Splatting for Real-Time Radiance Field Rendering**|Bernhard Kerbl,...George Drettakis|[2308.04079](http://arxiv.org/abs/2308.04079)|**[link](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)**|\n", "2405.15125": "|**2024-10-29**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai,...Alan Yuille|[2405.15125](http://arxiv.org/abs/2405.15125)|null|\n", "2407.09510": "|**2025-03-06**|**3DGS.zip: A survey on 3D Gaussian Splatting Compression Methods**|Milena T. Bagdasarian,...Wieland Morgenstern|[2407.09510](http://arxiv.org/abs/2407.09510)|null|\n", "2403.04116": "|**2024-10-29**|**Radiative Gaussian Splatting for Efficient X-ray Novel View Synthesis**|Yuanhao Cai,...Alan Yuille|[2403.04116](http://arxiv.org/abs/2403.04116)|null|\n", "2312.00732": "|**2024-07-09**|**Gaussian Grouping: Segment and Edit Anything in 3D Scenes**|Mingqiao Ye,...Lei Ke|[2312.00732](http://arxiv.org/abs/2312.00732)|**[link](https://github.com/lkeab/gaussian-grouping)**|\n", "2509.07774": "|**2025-09-10**|**HairGS: Hair Strand Reconstruction based on 3D Gaussian Splatting**|Yimin Pan,...Tobias Kirschstein|[2509.07774](http://arxiv.org/abs/2509.07774)|**[link](https://yimin-pan.github.io/hair-gs/)**|\n", "2311.16493": "|**2023-11-29**|**Mip-Splatting: Alias-free 3D Gaussian Splatting**|Zehao Yu,...Andreas Geiger|[2311.16493](http://arxiv.org/abs/2311.16493)|**[link](https://niujinshuchong.github.io/mip-splatting/)**|\n", "2312.02155": "|**2024-04-17**|**GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis**|Shunyuan Zheng,...Yebin Liu|[2312.02155](http://arxiv.org/abs/2312.02155)|**[link](https://shunyuanzheng.github.io/GPS-Gaussian)**|\n", "2402.13827": "|**2024-09-26**|**Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering of 3D Gaussian Splatting**|Joongho Jo,...Jongsun Park|[2402.13827](http://arxiv.org/abs/2402.13827)|null|\n", "2311.14521": "|**2023-12-21**|**GaussianEditor: Swift and Controllable 3D Editing with Gaussian Splatting**|Yiwen Chen,...Guosheng Lin|[2311.14521](http://arxiv.org/abs/2311.14521)|**[link](https://buaacyw.github.io/gaussian-editor/)**|\n", "2406.06526": "|**2025-02-28**|**Generative Gaussian Splatting for Unbounded 3D City Generation**|Haozhe Xie,...Ziwei Liu|[2406.06526](http://arxiv.org/abs/2406.06526)|**[link](https://haozhexie.com/project/gaussian-city)**|\n", "2411.11363": "|**2024-11-19**|**GPS-Gaussian+: Generalizable Pixel-wise 3D Gaussian Splatting for Real-Time Human-Scene Rendering from Sparse Views**|Boyao Zhou,...Yebin Liu|[2411.11363](http://arxiv.org/abs/2411.11363)|**[link](https://yaourtb.github.io/GPS-Gaussian+)**|\n", "2501.18672": "|**2025-05-27**|**Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation for 3D Gaussian Splatting**|Yansong Qu,...Rongrong Ji|[2501.18672](http://arxiv.org/abs/2501.18672)|**[link](https://quyans.github.io/Drag-Your-Gaussian)**|\n", "2407.01301": "|**2024-07-02**|**GaussianStego: A Generalizable Stenography Pipeline for Generative 3D Gaussians Splatting**|Chenxin Li,...Yixuan Yuan|[2407.01301](http://arxiv.org/abs/2407.01301)|**[link](https://gaussian-stego.github.io/)**|\n", "2501.01715": "|**2025-01-06**|**Cloth-Splatting: 3D Cloth State Estimation from RGB Supervision**|Alberta Longhini,...Danica Kragic|[2501.01715](http://arxiv.org/abs/2501.01715)|null|\n", "2406.01579": "|**2024-10-14**|**Tetrahedron Splatting for 3D Generation**|Chun Gu,...Li Zhang|[2406.01579](http://arxiv.org/abs/2406.01579)|**[link](https://fudan-zvg.github.io/tet-splatting/)**|\n", "2411.13753": "|**2025-03-13**|**FAST-Splat: Fast, Ambiguity-Free Semantics Transfer in Gaussian Splatting**|Ola Shorinwa,...Mac Schwager|[2411.13753](http://arxiv.org/abs/2411.13753)|null|\n", "2511.10316": "|**2025-11-13**|**Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision**|Yu Deng,...Qi Liu|[2511.10316](http://arxiv.org/abs/2511.10316)|null|\n", "2511.09944": "|**2025-11-13**|**TSPE-GS: Probabilistic Depth Extraction for Semi-Transparent Surface Reconstruction via 3D Gaussian Splatting**|Zhiyuan Xu,...Tong Wei|[2511.09944](http://arxiv.org/abs/2511.09944)|null|\n", "2511.09827": "|**2025-11-13**|**AHA! Animating Human Avatars in Diverse Scenes with Gaussian Splatting**|Aymen Mir,...Bing Zhou|[2511.09827](http://arxiv.org/abs/2511.09827)|null|\n", "2511.09695": "|**2025-11-12**|**A Shared-Autonomy Construction Robotic System for Overhead Works**|David Minkwan Kim,...Young Wook Kim|[2511.09695](http://arxiv.org/abs/2511.09695)|null|\n", "2511.09397": "|**2025-11-12**|**OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS**|Haiyi Li,...Hsiang-Ting Chen|[2511.09397](http://arxiv.org/abs/2511.09397)|null|\n", "2511.08294": "|**2025-11-11**|**SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering**|Laura Bragagnolo,...Stefano Ghidoni|[2511.08294](http://arxiv.org/abs/2511.08294)|null|\n", "2511.08032": "|**2025-11-11**|**Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric**|Zhaolin Wan,...Debin Zhao|[2511.08032](http://arxiv.org/abs/2511.08032)|null|\n", "2511.07743": "|**2025-11-11**|**UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis**|Yuezhe Yang,...Zhe Jin|[2511.07743](http://arxiv.org/abs/2511.07743)|null|\n", "2511.11231": "|**2025-11-14**|**3D Gaussian and Diffusion-Based Gaze Redirection**|Abiram Panchalingam,...Stuart Middleton|[2511.11231](http://arxiv.org/abs/2511.11231)|null|\n", "2511.11213": "|**2025-11-14**|**RealisticDreamer: Guidance Score Distillation for Few-shot Gaussian Splatting**|Ruocheng Wu,...Bihan Wen|[2511.11213](http://arxiv.org/abs/2511.11213)|null|\n", "2511.11175": "|**2025-11-14**|**Dynamic Gaussian Scene Reconstruction from Unsynchronized Videos**|Zhixin Xu,...Bin Wang|[2511.11175](http://arxiv.org/abs/2511.11175)|null|\n", "2511.11048": "|**2025-11-14**|**PINGS-X: Physics-Informed Normalized Gaussian Splatting with Axes Alignment for Efficient Super-Resolution of 4D Flow MRI**|Sun Jo,...Je Hyeong Hong|[2511.11048](http://arxiv.org/abs/2511.11048)|null|\n", "2511.13684": "|**2025-11-17**|**Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting**|Jiangnan Ye,...Haoji Hu|[2511.13684](http://arxiv.org/abs/2511.13684)|null|\n", "2511.13571": "|**2025-11-17**|**Opt3DGS: Optimizing 3D Gaussian Splatting with Adaptive Exploration and Curvature-Aware Exploitation**|Ziyang Huang,...Shunping Ji|[2511.13571](http://arxiv.org/abs/2511.13571)|null|\n", "2511.13278": "|**2025-11-17**|**SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting**|Zihan Li,...Zongqian Zhan|[2511.13278](http://arxiv.org/abs/2511.13278)|null|\n", "2511.13264": "|**2025-11-19**|**SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression**|Keshav Gupta,...Avinash Sharma|[2511.13264](http://arxiv.org/abs/2511.13264)|**[link](https://symgs.github.io/)**|\n", "2511.13011": "|**2025-11-17**|**Beyond Darkness: Thermal-Supervised 3D Gaussian Splatting for Low-Light Novel View Synthesis**|Qingsen Ma,...Zhaofeng He|[2511.13011](http://arxiv.org/abs/2511.13011)|null|\n", "2511.13009": "|**2025-11-17**|**TR-Gaussians: High-fidelity Real-time Rendering of Planar Transmission and Reflection with 3D Gaussian Splatting**|Yong Liu,...Kun Zhou|[2511.13009](http://arxiv.org/abs/2511.13009)|null|\n", "2511.12972": "|**2025-11-17**|**SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models**|Siddarth Narasimhan,...Goldie Nejat|[2511.12972](http://arxiv.org/abs/2511.12972)|**[link](https://splat-search.github.io/)**|\n", "2511.12941": "|**2025-11-17**|**GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving**|Chunyong Hu,...Sheng Yang|[2511.12941](http://arxiv.org/abs/2511.12941)|null|\n", "2511.12930": "|**2025-11-17**|**Neo: Real-Time On-Device 3D Gaussian Splatting with Reuse-and-Update Sorting Acceleration**|Changhun Oh,...Jongse Park|[2511.12930](http://arxiv.org/abs/2511.12930)|null|\n", "2511.12895": "|**2025-11-17**|**Reconstructing 3D Scenes in Native High Dynamic Range**|Kaixuan Zhang,...Xiatian Zhu|[2511.12895](http://arxiv.org/abs/2511.12895)|null|\n", "2511.12370": "|**2025-11-15**|**Changes in Real Time: Online Scene Change Detection with Multi-View Fusion**|Chamuditha Jayanga Galappaththige,...Dimity Miller|[2511.12370](http://arxiv.org/abs/2511.12370)|null|\n", "2511.12304": "|**2025-11-15**|**LiDAR-GS++:Improving LiDAR Gaussian Reconstruction via Diffusion Priors**|Qifeng Chen,...Sheng Yang|[2511.12304](http://arxiv.org/abs/2511.12304)|null|\n", "2511.12040": "|**2025-11-15**|**SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images**|Xinyuan Hu,...Min Tan|[2511.12040](http://arxiv.org/abs/2511.12040)|**[link](https://xinyuanhu66.github.io/SRSplat/)**|\n", "2511.14633": "|**2025-11-18**|**SparseSurf: Sparse-View 3D Gaussian Splatting for Surface Reconstruction**|Meiying Gu,...Xiao Bai|[2511.14633](http://arxiv.org/abs/2511.14633)|**[link](https://miya-oi.github.io/SparseSurf-project)**|\n", "2511.14540": "|**2025-11-18**|**Interaction-Aware 4D Gaussian Splatting for Dynamic Hand-Object Interaction Reconstruction**|Hao Tian,...Xiaolin Qin|[2511.14540](http://arxiv.org/abs/2511.14540)|null|\n", "2511.14477": "|**2025-11-18**|**2D Gaussians Spatial Transport for Point-supervised Density Regression**|Miao Shang,...Xiaopeng Hong|[2511.14477](http://arxiv.org/abs/2511.14477)|null|\n", "2511.14357": "|**2025-11-18**|**IBGS: Image-Based Gaussian Splatting**|Hoang Chuong Nguyen,...Miaomiao Liu|[2511.14357](http://arxiv.org/abs/2511.14357)|null|\n", "2511.14343": "|**2025-11-18**|**Silhouette-to-Contour Registration: Aligning Intraoral Scan Models with Cephalometric Radiographs**|Yiyi Miao,...Jionglong Su|[2511.14343](http://arxiv.org/abs/2511.14343)|null|\n", "2511.14315": "|**2025-11-18**|**Dental3R: Geometry-Aware Pairing for Intraoral 3D Reconstruction from Sparse-View Photographs**|Yiyi Miao,...Jionglong Su|[2511.14315](http://arxiv.org/abs/2511.14315)|null|\n", "2511.14291": "|**2025-11-18**|**GEN3D: Generating Domain-Free 3D Scenes from a Single Image**|Yuxin Zhang,...Houde Liu|[2511.14291](http://arxiv.org/abs/2511.14291)|null|\n", "2511.14270": "|**2025-11-19**|**Gaussian Splatting-based Low-Rank Tensor Representation for Multi-Dimensional Image Recovery**|Yiming Zeng,...Chao Wang|[2511.14270](http://arxiv.org/abs/2511.14270)|null|\n", "2511.14161": "|**2025-11-19**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Xiaoquan Sun,...Jiayu Chen|[2511.14161](http://arxiv.org/abs/2511.14161)|null|\n", "2511.14149": "|**2025-11-18**|**iGaussian: Real-Time Camera Pose Estimation via Feed-Forward 3D Gaussian Splatting Inversion**|Hao Wang,...Haibin Yan|[2511.14149](http://arxiv.org/abs/2511.14149)|null|\n", "2511.14042": "|**2025-11-18**|**Splat Regression Models**|Mara Daniels,...Philippe Rigollet|[2511.14042](http://arxiv.org/abs/2511.14042)|null|\n", "2511.15102": "|**2025-11-19**|**Gaussian Blending: Rethinking Alpha Blending in 3D Gaussian Splatting**|Junseo Koo,...Gunhee Kim|[2511.15102](http://arxiv.org/abs/2511.15102)|null|\n", "2511.14848": "|**2025-11-18**|**Gaussian See, Gaussian Do: Semantic 3D Motion Transfer from Multiview Video**|Yarin Bekor,...Or Litany|[2511.14848](http://arxiv.org/abs/2511.14848)|null|\n", "2511.16542": "|**2025-11-20**|**EOGS++: Earth Observation Gaussian Splatting with Internal Camera Refinement and Direct Panchromatic Rendering**|Pierrick Bournez,...Gabriele Facciolo|[2511.16542](http://arxiv.org/abs/2511.16542)|null|\n", "2511.16301": "|**2025-11-20**|**Upsample Anything: A Simple and Hard to Beat Baseline for Feature Upsampling**|Minseok Seo,...Changick Kim|[2511.16301](http://arxiv.org/abs/2511.16301)|null|\n", "2511.16298": "|**2025-11-20**|**Optimizing 3D Gaussian Splattering for Mobile GPUs**|Md Musfiqur Rahman Sanim,...Gagan Agrawal|[2511.16298](http://arxiv.org/abs/2511.16298)|null|\n", "2511.16144": "|**2025-11-20**|**LEGO-SLAM: Language-Embedded Gaussian Optimization SLAM**|Sibaek Lee,...Hyeonwoo Yu|[2511.16144](http://arxiv.org/abs/2511.16144)|null|\n", "2511.16112": "|**2025-11-20**|**Clustered Error Correction with Grouped 4D Gaussian Splatting**|Taeho Kang,...Youngki Lee|[2511.16112](http://arxiv.org/abs/2511.16112)|null|\n", "2511.16091": "|**2025-11-20**|**Rad-GS: Radar-Vision Integration for 3D Gaussian Splatting SLAM in Outdoor Environments**|Renxiang Xiao,...Liang Hu|[2511.16091](http://arxiv.org/abs/2511.16091)|null|\n", "2511.16030": "|**2025-11-20**|**CuriGS: Curriculum-Guided Gaussian Splatting for Sparse View Synthesis**|Zijian Wu,...Guiyang Pu|[2511.16030](http://arxiv.org/abs/2511.16030)|null|\n", "2511.17210": "|**2025-11-21**|**FisheyeGaussianLift: BEV Feature Lifting for Surround-View Fisheye Camera Perception**|Shubham Sonarghare,...Ganesh Sistu|[2511.17210](http://arxiv.org/abs/2511.17210)|null|\n", "2511.17116": "|**2025-11-21**|**PEGS: Physics-Event Enhanced Large Spatiotemporal Motion Reconstruction via 3D Gaussian Splatting**|Yijun Xu,...Chu He|[2511.17116](http://arxiv.org/abs/2511.17116)|null|\n", "2511.17111": "|**2025-11-21**|**Towards Generative Design Using Optimal Transport for Shape Exploration and Solution Field Interpolation**|Sergio Torregrosa,...Francisco Chinesta|[2511.17111](http://arxiv.org/abs/2511.17111)|null|\n", "2511.17092": "|**2025-11-21**|**SPAGS: Sparse-View Articulated Object Reconstruction from Single State via Planar Gaussian Splatting**|Di Wu,...Liangtu Song|[2511.17092](http://arxiv.org/abs/2511.17092)|null|\n", "2511.17059": "|**2025-11-21**|**REArtGS++: Generalizable Articulation Reconstruction with Temporal Geometry Constraint via Planar Gaussian Splatting**|Di Wu,...Cewu Lu|[2511.17059](http://arxiv.org/abs/2511.17059)|null|\n", "2511.16988": "|**2025-11-21**|**PhysMorph-GS: Differentiable Shape Morphing via Joint Optimization of Physics and Rendering Objectives**|Chang-Yong Song,...David Hyde|[2511.16988](http://arxiv.org/abs/2511.16988)|null|\n", "2511.16980": "|**2025-11-21**|**Gradient-Driven Natural Selection for Compact 3D Gaussian Splatting**|Xiaobin Deng,...Duanqing Xu|[2511.16980](http://arxiv.org/abs/2511.16980)|null|\n", "2511.16966": "|**2025-11-21**|**One Walk is All You Need: Data-Efficient 3D RF Scene Reconstruction with Human Movements**|Yiheng Bian,...Guangtao xue|[2511.16966](http://arxiv.org/abs/2511.16966)|null|\n", "2511.16831": "|**2025-11-20**|**Vorion: A RISC-V GPU with Hardware-Accelerated 3D Gaussian Rendering and Training**|Yipeng Wang,...Jaydeep P. Kulkarni|[2511.16831](http://arxiv.org/abs/2511.16831)|null|\n", "2511.21459": "|**2025-11-26**|**Resolution Where It Counts: Hash-based GPU-Accelerated 3D Reconstruction via Variance-Adaptive Voxel Grids**|Lorenzo De Rebotti,...Luca Di Giammarino|[2511.21459](http://arxiv.org/abs/2511.21459)|**[link](https://rvp-group.github.io/mrhash/)**|\n", "2511.21367": "|**2025-11-26**|**Endo-G$^{2}$T: Geometry-Guided & Temporally Aware Time-Embedded 4DGS For Endoscopic Scenes**|Yangle Liu,...Jieming Ma|[2511.21367](http://arxiv.org/abs/2511.21367)|null|\n", "2511.21265": "|**2025-11-26**|**Unlocking Zero-shot Potential of Semi-dense Image Matching via Gaussian Splatting**|Juncheng Chen,...Yanjun Cao|[2511.21265](http://arxiv.org/abs/2511.21265)|null|\n", "2511.20354": "|**2025-11-25**|**GS-Checker: Tampering Localization for 3D Gaussian Splatting**|Haoliang Han,...Renjie Wan|[2511.20354](http://arxiv.org/abs/2511.20354)|null|\n", "2511.20348": "|**2025-11-25**|**Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin**|Jo\u00e3o Malheiro Silva,...Holger Caesar|[2511.20348](http://arxiv.org/abs/2511.20348)|null|\n", "2511.19861": "|**2025-11-25**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|GigaWorld Team,...Zheng Zhu|[2511.19861](http://arxiv.org/abs/2511.19861)|**[link](https://gigaworld0.github.io/)**|\n", "2511.19854": "|**2025-11-25**|**STAvatar: Soft Binding and Temporal Density Control for Monocular 3D Head Avatars Reconstruction**|Jiankuo Zhao,...Zhen Lei|[2511.19854](http://arxiv.org/abs/2511.19854)|null|\n", "2511.19294": "|**2025-11-24**|**DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting**|Phurtivilai Patt,...Yang Lei|[2511.19294](http://arxiv.org/abs/2511.19294)|null|\n", "2511.19235": "|**2025-11-24**|**IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes**|Carl Lindstr\u00f6m,...Lennart Svensson|[2511.19235](http://arxiv.org/abs/2511.19235)|null|\n", "2511.19202": "|**2025-11-24**|**NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting**|Brent Zoomers,...Nick Michiels|[2511.19202](http://arxiv.org/abs/2511.19202)|null|\n", "2511.19172": "|**2025-11-24**|**MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate High-Fidelity Large-Scale Scenes**|Kehua Chen,...Zhaoqi Wang|[2511.19172](http://arxiv.org/abs/2511.19172)|**[link](https://m3phist0.github.io/MetroGS)**|\n", "2511.19542": "|**2025-11-24**|**Proxy-Free Gaussian Splats Deformation with Splat-Based Surface Estimation**|Jaeyeong Kim,...Minhyuk Sung|[2511.19542](http://arxiv.org/abs/2511.19542)|null|\n", "2511.18873": "|**2025-11-24**|**Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction**|Yiming Wang,...Siyu Tang|[2511.18873](http://arxiv.org/abs/2511.18873)|**[link](https://19reborn.github.io/nts/)**|\n", "2511.18755": "|**2025-11-24**|**Splatonic: Architecture Support for 3D Gaussian Splatting SLAM via Sparse Processing**|Xiaotong Huang,...Minyi Guo|[2511.18755](http://arxiv.org/abs/2511.18755)|null|\n", "2511.18570": "|**2025-11-23**|**PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation**|Samarth Chopra,...Dinesh Manocha|[2511.18570](http://arxiv.org/abs/2511.18570)|null|\n", "2511.18525": "|**2025-11-23**|**Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot Navigation**|Samarth Chopra,...Dinesh Manocha|[2511.18525](http://arxiv.org/abs/2511.18525)|null|\n", "2511.18441": "|**2025-11-23**|**ReCoGS: Real-time ReColoring for Gaussian Splatting scenes**|Lorenzo Rutayisire,...Fabio Pellacini|[2511.18441](http://arxiv.org/abs/2511.18441)|**[link](https://github.com/loryruta/recogs)**|\n", "2511.18386": "|**2025-11-23**|**SegSplat: Feed-forward Gaussian Splatting and Open-Set Semantic Segmentation**|Peter Siegel,...Daniel Barath|[2511.18386](http://arxiv.org/abs/2511.18386)|null|\n", "2511.18367": "|**2025-11-23**|**Alias-free 4D Gaussian Splatting**|Zilong Chen,...Hao Zhao|[2511.18367](http://arxiv.org/abs/2511.18367)|**[link](https://4d-alias-free.github.io/4D-Alias-free/)**|\n", "2511.18140": "|**2025-11-22**|**Observer Actor: Active Vision Imitation Learning with Sparse View Gaussian Splatting**|Yilong Wang,...Edward Johns|[2511.18140](http://arxiv.org/abs/2511.18140)|**[link](https://obact.github.io)**|\n", "2512.03010": "|**2025-12-02**|**SurfFill: Completion of LiDAR Point Clouds via Gaussian Surfel Splatting**|Svenja Strobel,...Linus Franke|[2512.03010](http://arxiv.org/abs/2512.03010)|**[link](https://lfranke.github.io/surffill)**|\n", "2512.02932": "|**2025-12-02**|**EGGS: Exchangeable 2D/3D Gaussian Splatting for Geometry-Appearance Balanced Novel View Synthesis**|Yancheng Zhang,...Chen Chen|[2512.02932](http://arxiv.org/abs/2512.02932)|null|\n", "2512.02664": "|**2025-12-02**|**PolarGuide-GSDR: 3D Gaussian Splatting Driven by Polarization Priors and Deferred Reflection for Real-World Reflective Scenes**|Derui Shan,...Peng Lu|[2512.02664](http://arxiv.org/abs/2512.02664)|null|\n", "2512.02648": "|**2025-12-02**|**PoreTrack3D: A Benchmark for Dynamic 3D Gaussian Splatting in Pore-Scale Facial Trajectory Tracking**|Dong Li,...Le Chang|[2512.02648](http://arxiv.org/abs/2512.02648)|null|\n", "2512.02621": "|**2025-12-02**|**Content-Aware Texturing for Gaussian Splatting**|Panagiotis Papantonakis,...George Drettakis|[2512.02621](http://arxiv.org/abs/2512.02621)|**[link](https://repo-sam.inria.fr/nerphys/gs-texturing/)**|\n", "2512.02482": "|**2025-12-02**|**G-SHARP: Gaussian Surgical Hardware Accelerated Real-time Pipeline**|Vishwesh Nath,...Sean D. Huver|[2512.02482](http://arxiv.org/abs/2512.02482)|null|\n", "2512.02293": "|**2025-12-02**|**VIGS-SLAM: Visual Inertial Gaussian Splatting SLAM**|Zihan Zhu,...Daniel Barath|[2512.02293](http://arxiv.org/abs/2512.02293)|**[link](https://vigs-slam.github.io)**|\n", "2512.02172": "|**2025-12-01**|**SplatSuRe: Selective Super-Resolution for Multi-view Consistent 3D Gaussian Splatting**|Pranav Asthana,...Amitabh Varshney|[2512.02172](http://arxiv.org/abs/2512.02172)|**[link](https://splatsure.github.io/)**|\n", "2512.02013": "|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Chenyang Gu,...Shanghang Zhang|[2512.02013](http://arxiv.org/abs/2512.02013)|null|\n", "2512.01329": "|**2025-12-01**|**TagSplat: Topology-Aware Gaussian Splatting for Dynamic Mesh Modeling and Tracking**|Hanzhi Guo,...Chenyu Xu|[2512.01329](http://arxiv.org/abs/2512.01329)|null|\n", "2512.01296": "|**2025-12-01**|**EGG-Fusion: Efficient 3D Reconstruction with Geometry-aware Gaussian Surfel on the Fly**|Xiaokun Pan,...Guofeng Zhang|[2512.01296](http://arxiv.org/abs/2512.01296)|null|\n", "2512.01008": "|**2025-11-30**|**LISA-3D: Lifting Language-Image Segmentation to 3D via Multi-View Consistency**|Zhongbin Guo,...Ping Jian|[2512.01008](http://arxiv.org/abs/2512.01008)|null|\n", "2512.00944": "|**2025-11-30**|**Binary-Gaussian: Compact and Progressive Representation for 3D Gaussian Segmentation**|An Yang,...Cong Liu|[2512.00944](http://arxiv.org/abs/2512.00944)|null|\n", "2512.00877": "|**2025-11-30**|**Feed-Forward 3D Gaussian Splatting Compression with Long-Context Modeling**|Zhening Liu,...Jun Zhang|[2512.00877](http://arxiv.org/abs/2512.00877)|null|\n", "2512.00850": "|**2025-11-30**|**Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting**|Haishan Wang,...Arno Solin|[2512.00850](http://arxiv.org/abs/2512.00850)|null|\n", "2512.00794": "|**2025-11-30**|**PolarGS: Polarimetric Cues for Ambiguity-Free Gaussian Splatting with Accurate Geometry Recovery**|Bo Guo,...Zhiming Zheng|[2512.00794](http://arxiv.org/abs/2512.00794)|null|\n", "2512.00677": "|**2025-11-30**|**Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer**|Dong In Lee,...Karthik Ramani|[2512.00677](http://arxiv.org/abs/2512.00677)|null|\n", "2512.00547": "|**2025-11-29**|**Asset-Driven Sematic Reconstruction of Dynamic Scene with Multi-Human-Object Interactions**|Sandika Biswas,...Hamid Rezatofighi|[2512.00547](http://arxiv.org/abs/2512.00547)|null|\n", "2512.00534": "|**2025-11-29**|**Cross-Temporal 3D Gaussian Splatting for Sparse-View Guided Scene Update**|Zeyuan An,...Xiaohui Liang|[2512.00534](http://arxiv.org/abs/2512.00534)|null|\n", "2512.00413": "|**2025-11-29**|**SplatFont3D: Structure-Aware Text-to-3D Artistic Font Generation with Part-Level Style Control**|Ji Gan,...Xinbo Gao|[2512.00413](http://arxiv.org/abs/2512.00413)|null|\n", "2512.05113": "|**2025-12-08**|**Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting**|Hao-Jen Chien,...Yu-Lun Liu|[2512.05113](http://arxiv.org/abs/2512.05113)|**[link](https://chien90190.github.io/splannequin/)**|\n", "2512.05060": "|**2025-12-04**|**4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer**|Xianfeng Wu,...Xinggang Wang|[2512.05060](http://arxiv.org/abs/2512.05060)|**[link](https://github.com/hustvl/4DLangVGGT)**|\n", "2512.04815": "|**2025-12-04**|**RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS**|Chuanyu Fu,...Xiaochun Cao|[2512.04815](http://arxiv.org/abs/2512.04815)|null|\n", "2512.04731": "|**2025-12-04**|**Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting**|Jian Tang,...Xuguang Lan|[2512.04731](http://arxiv.org/abs/2512.04731)|null|\n", "2512.04542": "|**2025-12-04**|**Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization**|Hong Kuang,...Jianchen Liu|[2512.04542](http://arxiv.org/abs/2512.04542)|null|\n", "2512.04421": "|**2025-12-04**|**UTrice: Unifying Primitives in Differentiable Ray Tracing and Rasterization via Triangles for Particle-Based 3D Scenes**|Changhe Liu,...Manabu Tsukada|[2512.04421](http://arxiv.org/abs/2512.04421)|null|\n", "2512.04315": "|**2025-12-03**|**SyncTrack4D: Cross-Video Motion Alignment and Video Synchronization for Multi-Video 4D Gaussian Splatting**|Yonghan Lee,...Dinesh Manocha|[2512.04315](http://arxiv.org/abs/2512.04315)|null|\n", "2512.04313": "|**2025-12-03**|**Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding**|Haolin Xiong,...Yajie Zhao|[2512.04313](http://arxiv.org/abs/2512.04313)|null|\n", "2512.04021": "|**2025-12-03**|**C3G: Learning Compact 3D Representations with 2K Gaussians**|Honggyu An,...Seungryong Kim|[2512.04021](http://arxiv.org/abs/2512.04021)|**[link](https://cvlab-kaist.github.io/C3G/)**|\n", "2512.03601": "|**2025-12-03**|**Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding**|Haoran Zhou,...Gim Hee Lee|[2512.03601](http://arxiv.org/abs/2512.03601)|null|\n", "2512.03422": "|**2025-12-03**|**What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models**|Tianchen Deng,...Weidong Chen|[2512.03422](http://arxiv.org/abs/2512.03422)|null|\n", "2512.03210": "|**2025-12-02**|**Flux4D: Flow-based Unsupervised 4D Reconstruction**|Jingkang Wang,...Raquel Urtasun|[2512.03210](http://arxiv.org/abs/2512.03210)|**[link](https://waabi.ai/flux4d/)**|\n", "2512.07806": "|**2025-12-08**|**Multi-view Pyramid Transformer: Look Coarser to See Broader**|Gyeongjin Kang,...Eunbyung Park|[2512.07806](http://arxiv.org/abs/2512.07806)|**[link](https://gynjn.github.io/MVP/)**|\n", "2512.07381": "|**2025-12-08**|**Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects**|Shuohan Tao,...Yebin Liu|[2512.07381](http://arxiv.org/abs/2512.07381)|null|\n", "2512.07345": "|**2025-12-08**|**Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting**|Shilong Jin,...Yuan Zhou|[2512.07345](http://arxiv.org/abs/2512.07345)|null|\n", "2512.07247": "|**2025-12-08**|**AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing**|Ziming Hong,...Tongliang Liu|[2512.07247](http://arxiv.org/abs/2512.07247)|null|\n", "2512.07230": "|**2025-12-08**|**STRinGS: Selective Text Refinement in Gaussian Splatting**|Abhinav Raundhal,...Makarand Tapaswi|[2512.07230](http://arxiv.org/abs/2512.07230)|**[link](https://STRinGS-official.github.io)**|\n", "2512.07197": "|**2025-12-08**|**SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting**|Seokhyun Youn,...Jihyong Oh|[2512.07197](http://arxiv.org/abs/2512.07197)|**[link](https://cmlab-korea.github.io/Awesome-Efficient-GS/)**|\n", "2512.07165": "|**2025-12-08**|**MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation**|Muyu Xu,...Shijian Lu|[2512.07165](http://arxiv.org/abs/2512.07165)|null|\n", "2512.07107": "|**2025-12-08**|**COREA: Coarse-to-Fine 3D Representation Alignment Between Relightable 3D Gaussians and SDF via Bidirectional 3D-to-3D Supervision**|Jaeyoon Lee,...Jongwon Choi|[2512.07107](http://arxiv.org/abs/2512.07107)|**[link](https://vilab-cau.github.io/COREA/)**|\n", "2512.07052": "|**2025-12-07**|**RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting**|Hoang-Nhat Tran,...Enzo Tartaglione|[2512.07052](http://arxiv.org/abs/2512.07052)|null|\n", "2512.06818": "|**2025-12-07**|**MeshSplatting: Differentiable Rendering with Opaque Meshes**|Jan Held,...Andrea Tagliasacchi|[2512.06818](http://arxiv.org/abs/2512.06818)|null|\n", "2512.06774": "|**2025-12-07**|**RDSplat: Robust Watermarking Against Diffusion Editing for 3D Gaussian Splatting**|Longjie Zhao,...Tongliang Liu|[2512.06774](http://arxiv.org/abs/2512.06774)|null|\n", "2512.06684": "|**2025-12-07**|**EMGauss: Continuous Slice-to-3D Reconstruction via Dynamic Gaussian Modeling in Volume Electron Microscopy**|Yumeng He,...Xiaokang Yang|[2512.06684](http://arxiv.org/abs/2512.06684)|null|\n", "2512.06438": "|**2025-12-06**|**AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars**|Ramazan Fazylov,...Ivan Laptev|[2512.06438](http://arxiv.org/abs/2512.06438)|null|\n", "2512.06269": "|**2025-12-06**|**TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting**|Quan Tran,...Tuan Dang|[2512.06269](http://arxiv.org/abs/2512.06269)|null|\n", "2512.06158": "|**2025-12-05**|**Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation**|Su Sun,...Mei Chen|[2512.06158](http://arxiv.org/abs/2512.06158)|null|\n", "2512.05446": "|**2025-12-05**|**TED-4DGS: Temporally Activated and Embedding-based Deformation for 4DGS Compression**|Cheng-Yuan Ho,...Wen-Hsiao Peng|[2512.05446](http://arxiv.org/abs/2512.05446)|null|\n", "2512.05354": "|**2025-12-05**|**SplatPainter: Interactive Authoring of 3D Gaussians from 2D Edits via Test-Time Training**|Yang Zheng,...Wang Yifan|[2512.05354](http://arxiv.org/abs/2512.05354)|**[link](https://y-zheng18.github.io/SplatPainter/)**|\n", "2512.10939": "|**2025-12-11**|**GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting**|Madhav Agarwal,...Steven McDonagh|[2512.10939](http://arxiv.org/abs/2512.10939)|null|\n", "2512.10572": "|**2025-12-11**|**DeMapGS: Simultaneous Mesh Deformation and Surface Attribute Mapping via Gaussian Splatting**|Shuyi Zhou,...Takeshi Oishi|[2512.10572](http://arxiv.org/abs/2512.10572)|**[link](https://shuyizhou495.github.io/DeMapGS-project-page/)**|\n", "2512.10424": "|**2025-12-11**|**Neural Hamiltonian Deformation Fields for Dynamic Scene Rendering**|Hai-Long Qin,...Jincheng Dai|[2512.10424](http://arxiv.org/abs/2512.10424)|**[link](https://qin-jingyun.github.io/NeHaD)**|\n", "2512.10369": "|**2025-12-11**|**Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views**|Zhankuo Xu,...Yonghong Tian|[2512.10369](http://arxiv.org/abs/2512.10369)|null|\n", "2512.10293": "|**2025-12-11**|**Physically Aware 360$^\\circ$ View Generation from a Single Image using Disentangled Scene Embeddings**|Karthikeya KV,...Narendra Bandaru|[2512.10293](http://arxiv.org/abs/2512.10293)|null|\n", "2512.10267": "|**2025-12-11**|**Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction**|Chen Ziwen,...Li Fuxin|[2512.10267](http://arxiv.org/abs/2512.10267)|null|\n", "2512.10095": "|**2025-12-10**|**TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing**|Jiachen Tao,...Yan Yan|[2512.10095](http://arxiv.org/abs/2512.10095)|null|\n", "2512.09925": "|**2025-12-10**|**GAINS: Gaussian-based Inverse Rendering from Sparse Multi-View Captures**|Patrick Noras,...Roni Sengupta|[2512.09925](http://arxiv.org/abs/2512.09925)|null|\n", "2512.09923": "|**2025-12-10**|**Splatent: Splatting Diffusion Latents for Novel View Synthesis**|Or Hirschorn,...Lior Fritz|[2512.09923](http://arxiv.org/abs/2512.09923)|null|\n", "2512.09903": "|**2025-12-10**|**YOPO-Nav: Visual Navigation using 3DGS Graphs from One-Pass Videos**|Ryan Meegan,...Kristin Dana|[2512.09903](http://arxiv.org/abs/2512.09903)|null|\n", "2512.09656": "|**2025-12-10**|**ReMoSPLAT: Reactive Mobile Manipulation Control on a Gaussian Splat**|Nicolas Marticorena,...Niko Suenderhauf|[2512.09656](http://arxiv.org/abs/2512.09656)|null|\n", "2512.09411": "|**2025-12-10**|**D$^2$GSLAM: 4D Dynamic Gaussian Splatting SLAM**|Siting Zhu,...Hesheng Wang|[2512.09411](http://arxiv.org/abs/2512.09411)|null|\n", "2512.09335": "|**2025-12-11**|**Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video**|Seonghwa Choi,...Sanghoon Lee|[2512.09335](http://arxiv.org/abs/2512.09335)|null|\n", "2512.09270": "|**2025-12-10**|**MoRel: Long-Range Flicker-Free 4D Motion Modeling via Anchor Relay-based Bidirectional Blending with Hierarchical Densification**|Sangwoon Kwak,...Jihyong Oh|[2512.09270](http://arxiv.org/abs/2512.09270)|**[link](https://cmlab-korea.github.io/MoRel/)**|\n", "2512.09162": "|**2025-12-09**|**GTAvatar: Bridging Gaussian Splatting and Texture Mapping for Relightable and Editable Gaussian Avatars**|Kelian Baert,...Adnane Boukhayma|[2512.09162](http://arxiv.org/abs/2512.09162)|null|\n", "2512.08625": "|**2025-12-09**|**OpenMonoGS-SLAM: Monocular Gaussian Splatting SLAM with Open-set Semantics**|Jisang Yoo,...Eunbyung Park|[2512.08625](http://arxiv.org/abs/2512.08625)|null|\n", "2512.08498": "|**2025-12-09**|**On-the-fly Large-scale 3D Reconstruction from Multi-Camera Rigs**|Yijia Guo,...Lei Ma|[2512.08498](http://arxiv.org/abs/2512.08498)|null|\n", "2512.08478": "|**2025-12-09**|**Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform**|Yuning Gong,...Zhihang Zhong|[2512.08478](http://arxiv.org/abs/2512.08478)|**[link](https://visionary-laboratory.github.io/visionary)**|\n", "2512.08334": "|**2025-12-09**|**HybridSplat: Fast Reflection-baked Gaussian Tracing using Hybrid Splatting**|Chang Liu,...Shi-Sheng Huang|[2512.08334](http://arxiv.org/abs/2512.08334)|null|\n", "2512.08271": "|**2025-12-09**|**Zero-Splat TeleAssist: A Zero-Shot Pose Estimation Framework for Semantic Teleoperation**|Srijan Dokania,...Dharini Raghavan|[2512.08271](http://arxiv.org/abs/2512.08271)|null|\n", "2512.11800": "|**2025-12-12**|**Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance**|Jan U. M\u00fcller,...Reinhard Klein|[2512.11800](http://arxiv.org/abs/2512.11800)|null|\n", "2512.11356": "|**2025-12-12**|**Prior-Enhanced Gaussian Splatting for Dynamic Scene Reconstruction from Casual Video**|Meng-Li Shih,...Brian Curless|[2512.11356](http://arxiv.org/abs/2512.11356)|null|\n", "2512.11186": "|**2025-12-12**|**Lightweight 3D Gaussian Splatting Compression via Video Codec**|Qi Yang,...Zhu Li|[2512.11186](http://arxiv.org/abs/2512.11186)|null|\n", "2512.15711": "|**2025-12-17**|**Gaussian Pixel Codec Avatars: A Hybrid Representation for Efficient Rendering**|Divam Gupta,...Giljoo Nam|[2512.15711](http://arxiv.org/abs/2512.15711)|null|\n", "2512.15508": "|**2025-12-17**|**Off The Grid: Detection of Primitives for Feed-Forward 3D Gaussian Splatting**|Arthur Moreau,...Eduardo P\u00e9rez-Pellitero|[2512.15508](http://arxiv.org/abs/2512.15508)|null|\n", "2512.15258": "|**2025-12-17**|**VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments**|Yuze Wu,...Fei Gao|[2512.15258](http://arxiv.org/abs/2512.15258)|null|\n", "2512.15048": "|**2025-12-17**|**MVGSR: Multi-View Consistent 3D Gaussian Super-Resolution via Epipolar Guidance**|Kaizhe Zhang,...Yudeng Xin|[2512.15048](http://arxiv.org/abs/2512.15048)|null|\n", "2512.15034": "|**2025-12-17**|**A Gaussian Parameterization for Direct Atomic Structure Identification in Electron Tomography**|Nalini M. Singh,...Laura Waller|[2512.15034](http://arxiv.org/abs/2512.15034)|null|\n", "2512.14406": "|**2025-12-16**|**Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos**|Le Jiang,...Sarah Ostadabbas|[2512.14406](http://arxiv.org/abs/2512.14406)|null|\n", "2512.14352": "|**2025-12-16**|**HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis**|Kaizhe Zhang,...Yong-Jin Liu|[2512.14352](http://arxiv.org/abs/2512.14352)|null|\n", "2512.14200": "|**2025-12-16**|**Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination**|Zhuoxiao Li,...Wufan Zhao|[2512.14200](http://arxiv.org/abs/2512.14200)|null|\n", "2512.14180": "|**2025-12-16**|**Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere**|Francesco Di Sario,...Andrea Tagliasacchi|[2512.14180](http://arxiv.org/abs/2512.14180)|null|\n", "2512.14087": "|**2025-12-16**|**GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants**|Yang Yang,...Fumio Okura|[2512.14087](http://arxiv.org/abs/2512.14087)|null|\n", "2512.14039": "|**2025-12-16**|**ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization**|Meng Wei,...Jianfei Cai|[2512.14039](http://arxiv.org/abs/2512.14039)|null|\n", "2512.13796": "|**2025-12-15**|**Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries**|Victor Rong,...David B. Lindell|[2512.13796](http://arxiv.org/abs/2512.13796)|**[link](https://lessvrong.com/cs/nexels)**|\n", "2512.13411": "|**2025-12-15**|**Computer vision training dataset generation for robotic environments using Gaussian splatting**|Patryk Ni\u017ceniec,...Marcin Iwanowski|[2512.13411](http://arxiv.org/abs/2512.13411)|**[link](https://patrykni.github.io/UnitySplat2Data/)**|\n", "2512.13007": "|**2025-12-15**|**Light Field Based 6DoF Tracking of Previously Unobserved Objects**|Nikolai Goncharov,...Donald G. Dansereau|[2512.13007](http://arxiv.org/abs/2512.13007)|null|\n", "2512.12898": "|**2025-12-15**|**Qonvolution: Towards Learning High-Frequency Signals with Queried Convolution**|Abhinav Kumar,...Suren Kumar|[2512.12898](http://arxiv.org/abs/2512.12898)|**[link](https://abhi1kumar.github.io/qonvolution/)**|\n", "2512.12774": "|**2025-12-14**|**Fast 2DGS: Efficient Image Representation with Deep Gaussian Prior**|Hao Wang,...Abolfazl Razi|[2512.12774](http://arxiv.org/abs/2512.12774)|null|\n"}}