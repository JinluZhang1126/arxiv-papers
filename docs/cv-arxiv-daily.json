{"Interaction": {"2509.18937": "|**2025-09-23**|**Lang2Morph: Language-Driven Morphological Design of Robotic Hands**|Yanyuan Qiao,...Josie Hughes|[2509.18937](http://arxiv.org/abs/2509.18937)|null|\n", "2509.18571": "|**2025-09-23**|**Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought**|Yuhan Wang,...Weichao Wu|[2509.18571](http://arxiv.org/abs/2509.18571)|null|\n", "2509.17888": "|**2025-09-22**|**Trainee Action Recognition through Interaction Analysis in CCATT Mixed-Reality Training**|Divya Mereddy,...Benjamin Goldberg|[2509.17888](http://arxiv.org/abs/2509.17888)|null|\n", "2509.16557": "|**2025-09-20**|**Person Identification from Egocentric Human-Object Interactions using 3D Hand Pose**|Muhammad Hamza,...Muhammad Tahir Akram|[2509.16557](http://arxiv.org/abs/2509.16557)|null|\n", "2509.16398": "|**2025-09-19**|**Dynamic Objects Relocalization in Changing Environments with Flow Matching**|Francesco Argenziano,...Liam Paull|[2509.16398](http://arxiv.org/abs/2509.16398)|null|\n", "2509.12784": "|**2025-10-03**|**Contextualized Representation Learning for Effective Human-Object Interaction Detection**|Zhehao Li,...Jiafei Wu|[2509.12784](http://arxiv.org/abs/2509.12784)|null|\n", "2509.12554": "|**2025-09-16**|**Explicit Multimodal Graph Modeling for Human-Object Interaction Detection**|Wenxuan Ji,...Xiao-Yu zhang|[2509.12554](http://arxiv.org/abs/2509.12554)|null|\n", "2509.12250": "|**2025-09-12**|**OnlineHOI: Towards Online Human-Object Interaction Generation and Perception**|Yihong Ji,...Fei Yu|[2509.12250](http://arxiv.org/abs/2509.12250)|null|\n", "2509.09555": "|**2025-09-11**|**InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation**|Sirui Xu,...Liang-Yan Gui|[2509.09555](http://arxiv.org/abs/2509.09555)|null|\n", "2509.09067": "|**2025-09-16**|**Improvement of Human-Object Interaction Action Recognition Using Scene Information and Multi-Task Learning Approach**|Hesham M. Shehata,...Mohammad Abdolrahmani|[2509.09067](http://arxiv.org/abs/2509.09067)|null|\n", "2509.07920": "|**2025-09-09**|**ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion**|Ao Li,...Yansong Tang|[2509.07920](http://arxiv.org/abs/2509.07920)|null|\n", "2509.01232": "|**2025-09-01**|**FantasyHSI: Video-Generation-Centric 4D Human Synthesis In Any Scene through A Graph-based Multi-Agent Framework**|Lingzhou Mu,...Kai Zhang|[2509.01232](http://arxiv.org/abs/2509.01232)|**[link](https://fantasy-amap.github.io/fantasy-hsi/)**|\n", "2509.00767": "|**2025-08-31**|**InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos**|Yangsong Zhang,...Ivan Laptev|[2509.00767](http://arxiv.org/abs/2509.00767)|**[link](https://mael-zys.github.io/InterPose/)**|\n", "2509.00760": "|**2025-08-31**|**No More Sibling Rivalry: Debiasing Human-Object Interaction Detection**|Bin Yang,...Sibei Yang|[2509.00760](http://arxiv.org/abs/2509.00760)|null|\n", "2508.21556": "|**2025-08-29**|**ECHO: Ego-Centric modeling of Human-Object interactions**|Ilya A. Petrov,...Gerard Pons-Moll|[2508.21556](http://arxiv.org/abs/2508.21556)|null|\n", "2508.19852": "|**2025-08-28**|**Ego-centric Predictive Model Conditioned on Hand Trajectories**|Binjie Zhang,...Mike Zheng Shou|[2508.19852](http://arxiv.org/abs/2508.19852)|null|\n", "2508.19575": "|**2025-08-28**|**Interact-Custom: Customized Human Object Interaction Image Generation**|Zhu Xu,...Yang Liu|[2508.19575](http://arxiv.org/abs/2508.19575)|null|\n", "2508.18896": "|**2025-08-26**|**DQEN: Dual Query Enhancement Network for DETR-based HOI Detection**|Zhehao Li,...Jiafei Wu|[2508.18896](http://arxiv.org/abs/2508.18896)|null|\n", "2508.18753": "|**2025-09-29**|**Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods**|Qinqian Lei,...Robby T. Tan|[2508.18753](http://arxiv.org/abs/2508.18753)|null|\n", "2508.18691": "|**2025-08-26**|**Deep Sensorimotor Control by Imitating Predictive Models of Human Motion**|Himanshu Gaurav Singh,...Antonio Loquercio|[2508.18691](http://arxiv.org/abs/2508.18691)|**[link](https://hgaurav2k.github.io/trackr/)**|\n", "2509.23612": "|**2025-09-28**|**InteractMove: Text-Controlled Human-Object Interaction Generation in 3D Scenes with Movable Objects**|Xinhao Cai,...Yang Liu|[2509.23612](http://arxiv.org/abs/2509.23612)|null|\n", "2509.26621": "|**2025-09-30**|**HART: Human Aligned Reconstruction Transformer**|Xiyi Chen,...Ming Lin|[2509.26621](http://arxiv.org/abs/2509.26621)|**[link](https://xiyichen.github.io/hart)**|\n", "2509.26004": "|**2025-09-30**|**Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations**|Nicola Messina,...Antonino Furnari|[2509.26004](http://arxiv.org/abs/2509.26004)|null|\n", "2510.02155": "|**2025-10-02**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Shu Zou,...Jing Zhang|[2510.02155](http://arxiv.org/abs/2510.02155)|null|\n", "2510.03135": "|**2025-10-03**|**Mask2IV: Interaction-Centric Video Generation via Mask Trajectories**|Gen Li,...Laura Sevilla-Lara|[2510.03135](http://arxiv.org/abs/2510.03135)|**[link](https://reagan1311.github.io/mask2iv)**|\n", "2510.05609": "|**2025-10-07**|**HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection**|Junwen Chen,...Keiji Yanai|[2510.05609](http://arxiv.org/abs/2510.05609)|null|\n", "2510.07828": "|**2025-10-11**|**MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions**|Kaen Kogashi,...Meng-Yu Jennifer Kuo|[2510.07828](http://arxiv.org/abs/2510.07828)|null|\n", "2510.11649": "|**2025-10-13**|**PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from a Single Image**|Pradyumna Yalandur Muralidhar,...Gerard Pons-Moll|[2510.11649](http://arxiv.org/abs/2510.11649)|**[link](https://yuxuan-xue.com/physic)**|\n", "2510.16272": "|**2025-10-17**|**Proactive Scene Decomposition and Reconstruction**|Baicheng Li,...Hongbin Zha|[2510.16272](http://arxiv.org/abs/2510.16272)|null|\n", "2510.18357": "|**2025-10-21**|**Learning Human-Object Interaction as Groups**|Jiajun Hong,...Wenguan Wang|[2510.18357](http://arxiv.org/abs/2510.18357)|null|\n", "2510.23203": "|**2025-10-27**|**DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification**|Lukas Bierling,...Angelo Broere|[2510.23203](http://arxiv.org/abs/2510.23203)|null|\n", "2510.22199": "|**2025-10-25**|**MOGRAS: Human Motion with Grasping in 3D Scenes**|Kunal Bhosikar,...Charu Sharma|[2510.22199](http://arxiv.org/abs/2510.22199)|null|\n", "2510.21769": "|**2025-10-17**|**H2OFlow: Grounding Human-Object Affordances with 3D Generative Models and Dense Diffused Flows**|Harry Zhang,...Luca Carlone|[2510.21769](http://arxiv.org/abs/2510.21769)|null|\n"}, "World Model": {"2509.21027": "|**2025-09-25**|**KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models**|Sibo Li,...Yong Li|[2509.21027](http://arxiv.org/abs/2509.21027)|null|\n", "2509.20998": "|**2025-09-25**|**CORE: Full-Path Evaluation of LLM Agents Beyond Final State**|Panagiotis Michelakis,...Dimitrios Stamoulis|[2509.20998](http://arxiv.org/abs/2509.20998)|null|\n", "2509.20623": "|**2025-09-24**|**Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation**|Satyajeet Das,...Gaurav S. Sukhatme|[2509.20623](http://arxiv.org/abs/2509.20623)|null|\n", "2509.20021": "|**2025-09-24**|**Embodied AI: From LLMs to World Models**|Tongtong Feng,...Wenwu Zhu|[2509.20021](http://arxiv.org/abs/2509.20021)|null|\n", "2509.19555": "|**2025-09-23**|**AnySafe: Adapting Latent Safety Filters at Runtime via Safety Constraint Parameterization in the Latent Space**|Sankalp Agrawal,...Andrea Bajcsy|[2509.19555](http://arxiv.org/abs/2509.19555)|null|\n", "2509.19538": "|**2025-09-23**|**DAWM: Diffusion Action World Models for Offline Reinforcement Learning via Action-Inferred Transitions**|Zongyue Li,...Matthias Schubert|[2509.19538](http://arxiv.org/abs/2509.19538)|null|\n", "2509.19080": "|**2025-09-23**|**World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation**|Zhennan Jiang,...Dongbin Zhao|[2509.19080](http://arxiv.org/abs/2509.19080)|null|\n", "2509.19041": "|**2025-09-23**|**Position: Human-Robot Interaction in Embodied Intelligence Demands a Shift From Static Privacy Controls to Dynamic Learning**|Shuning Zhang,...Hewu Li|[2509.19041](http://arxiv.org/abs/2509.19041)|null|\n", "2509.18428": "|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Bahey Tharwat,...Ian Reid|[2509.18428](http://arxiv.org/abs/2509.18428)|null|\n", "2509.17808": "|**2025-09-27**|**Remote Sensing-Oriented World Model**|Yuxi Lu,...Bin Liang|[2509.17808](http://arxiv.org/abs/2509.17808)|null|\n", "2509.17393": "|**2025-09-23**|**Program Synthesis via Test-Time Transduction**|Kang-il Lee,...Kyomin Jung|[2509.17393](http://arxiv.org/abs/2509.17393)|null|\n", "2509.16338": "|**2025-09-19**|**Polarized Signatures of Variable Worlds: Modeling Heterogeneous Habitable Earth- and Early Mars-like (Exo)planets**|Kenneth E. Goodis Gordon,...Eric T. Wolf|[2509.16338](http://arxiv.org/abs/2509.16338)|null|\n", "2509.15915": "|**2025-09-19**|**Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds**|Remo Sasso,...Paulo Rauber|[2509.15915](http://arxiv.org/abs/2509.15915)|null|\n", "2509.15536": "|**2025-09-19**|**SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models**|Sen Wang,...Hua Gang|[2509.15536](http://arxiv.org/abs/2509.15536)|null|\n", "2509.15479": "|**2025-09-18**|**OpenViGA: Video Generation for Automotive Driving Scenes by Streamlining and Fine-Tuning Open Source Models with Public Data**|Bj\u00f6rn M\u00f6ller,...Tim Fingscheidt|[2509.15479](http://arxiv.org/abs/2509.15479)|null|\n", "2509.14758": "|**2025-09-18**|**Designing Latent Safety Filters using Pre-Trained Vision Models**|Ihab Tabbara,...Hussein Sibai|[2509.14758](http://arxiv.org/abs/2509.14758)|null|\n", "2509.13903": "|**2025-09-17**|**PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models**|Artem Lykov,...Dzmitry Tsetserukou|[2509.13903](http://arxiv.org/abs/2509.13903)|null|\n", "2509.13389": "|**2025-09-25**|**From Next Token Prediction to (STRIPS) World Models -- Preliminary Results**|Carlos N\u00fa\u00f1ez-Molina,...Hector Geffner|[2509.13389](http://arxiv.org/abs/2509.13389)|null|\n", "2509.13095": "|**2025-09-26**|**Empowering Multi-Robot Cooperation via Sequential World Models**|Zijie Zhao,...Dongbin Zhao|[2509.13095](http://arxiv.org/abs/2509.13095)|null|\n", "2509.13384": "|**2025-09-16**|**A tree-based Polynomial Chaos expansion for surrogate modeling and sensitivity analysis of complex numerical models**|Faten Ben Said,...Fabrice Zaoui|[2509.13384](http://arxiv.org/abs/2509.13384)|null|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo,...Ziwei Wang|[2509.22643](http://arxiv.org/abs/2509.22643)|null|\n", "2509.22642": "|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Xiaowei Chi,...Jian Tang|[2509.22642](http://arxiv.org/abs/2509.22642)|null|\n", "2509.22353": "|**2025-09-26**|**Context and Diversity Matter: The Emergence of In-Context Learning in World Models**|Fan Wang,...Yu Kang|[2509.22353](http://arxiv.org/abs/2509.22353)|null|\n", "2509.21797": "|**2025-09-30**|**MoWM: Mixture-of-World-Models for Embodied Planning via Latent-to-Pixel Feature Modulation**|Yu Shang,...Yong Li|[2509.21797](http://arxiv.org/abs/2509.21797)|null|\n", "2509.21790": "|**2025-09-26**|**LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE**|Yu Shang,...Yong Li|[2509.21790](http://arxiv.org/abs/2509.21790)|null|\n", "2509.21657": "|**2025-09-25**|**FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction**|Yixiang Dai,...Yonggang Qi|[2509.21657](http://arxiv.org/abs/2509.21657)|null|\n", "2509.21592": "|**2025-09-25**|**What Happens Next? Anticipating Future Motion by Generating Point Trajectories**|Gabrijel Boduljak,...Andrea Vedaldi|[2509.21592](http://arxiv.org/abs/2509.21592)|null|\n", "2509.21574": "|**2025-09-25**|**X-Streamer: Unified Human World Modeling with Audiovisual Interaction**|You Xie,...Linjie Luo|[2509.21574](http://arxiv.org/abs/2509.21574)|**[link](https://byteaigc.github.io/X-Streamer)**|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24804": "|**2025-09-29**|**DyMoDreamer: World Modeling with Dynamic Modulation**|Boxuan Zhang,...Gang Wang|[2509.24804](http://arxiv.org/abs/2509.24804)|null|\n", "2509.24591": "|**2025-09-29**|**PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control**|Haozhuo Zhang,...Wei Pan|[2509.24591](http://arxiv.org/abs/2509.24591)|null|\n", "2509.24559": "|**2025-09-29**|**Emergent World Representations in OpenVLA**|Marco Molinari,...Omar G. Younis|[2509.24559](http://arxiv.org/abs/2509.24559)|null|\n", "2509.24527": "|**2025-09-29**|**Training Agents Inside of Scalable World Models**|Danijar Hafner,...Timothy Lillicrap|[2509.24527](http://arxiv.org/abs/2509.24527)|**[link](https://danijar.com/dreamer4/)**|\n", "2509.24313": "|**2025-09-29**|**Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning**|Korbinian Moller,...Johannes Betz|[2509.24313](http://arxiv.org/abs/2509.24313)|null|\n", "2509.24241": "|**2025-09-29**|**FreeAction: Training-Free Techniques for Enhanced Fidelity of Trajectory-to-Video Generation**|Seungwook Kim,...Minsu Cho|[2509.24241](http://arxiv.org/abs/2509.24241)|null|\n", "2509.24116": "|**2025-09-30**|**Dual-Scale World Models for LLM Agents Towards Hard-Exploration Problems**|Minsoo Kim,...Seung-won Hwang|[2509.24116](http://arxiv.org/abs/2509.24116)|null|\n", "2509.23979": "|**2025-09-28**|**ByteSized32Refactored: Towards an Extensible Interactive Text Games Corpus for LLM World Modeling and Evaluation**|Haonan Wang,...Ziang Xiao|[2509.23979](http://arxiv.org/abs/2509.23979)|null|\n", "2509.23958": "|**2025-09-28**|**Reinforcement Learning with Inverse Rewards for World Model Post-training**|Yang Ye,...Jiang Bian|[2509.23958](http://arxiv.org/abs/2509.23958)|null|\n", "2509.23488": "|**2025-10-01**|**Mapping Overlaps in Benchmarks through Perplexity in the Wild**|Siyang Wu,...James A. Evans|[2509.23488](http://arxiv.org/abs/2509.23488)|null|\n", "2509.23008": "|**2025-09-27**|**ARSS: Taming Decoder-only Autoregressive Visual Generation for View Synthesis From Single View**|Wenbin Teng,...Yajie Zhao|[2509.23008](http://arxiv.org/abs/2509.23008)|null|\n", "2509.22814": "|**2025-09-26**|**Model Context Protocol for Vision Systems: Audit, Security, and Protocol Extensions**|Aditi Tiwari,...Darshan Prasad|[2509.22814](http://arxiv.org/abs/2509.22814)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.26339": "|**2025-09-30**|**Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models**|Eric R. Damm,...Thomas M. Howard|[2509.26339](http://arxiv.org/abs/2509.26339)|null|\n", "2509.26255": "|**2025-10-01**|**ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning**|Yichao Liang,...Kevin Ellis|[2509.26255](http://arxiv.org/abs/2509.26255)|null|\n", "2509.25518": "|**2025-10-02**|**World Model for AI Autonomous Navigation in Mechanical Thrombectomy**|Harry Robertshaw,...Thomas C Booth|[2509.25518](http://arxiv.org/abs/2509.25518)|null|\n", "2509.25373": "|**2025-09-29**|**From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models**|Chenyue Zhou,...Yike Guo|[2509.25373](http://arxiv.org/abs/2509.25373)|null|\n", "2509.25161": "|**2025-09-29**|**Rolling Forcing: Autoregressive Long Video Diffusion in Real Time**|Kunhao Liu,...Shijian Lu|[2509.25161](http://arxiv.org/abs/2509.25161)|**[link](https://kunhao-liu.github.io/Rolling_Forcing_Webpage/)**|\n", "2509.25282": "|**2025-09-29**|**Toward Causal-Visual Programming: Enhancing Agentic Reasoning in Low-Code Environments**|Jiexi Xu,...Su Liu|[2509.25282](http://arxiv.org/abs/2509.25282)|null|\n", "2510.02287": "|**2025-10-02**|**MultiModal Action Conditioned Video Generation**|Yichen Li,...Antonio Torralba|[2510.02287](http://arxiv.org/abs/2510.02287)|null|\n", "2510.02110": "|**2025-10-02**|**SoundReactor: Frame-level Online Video-to-Audio Generation**|Koichi Saito,...Yuki Mitsufuji|[2510.02110](http://arxiv.org/abs/2510.02110)|null|\n", "2510.01641": "|**2025-10-02**|**FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion Deblurring**|Xiaoyang Liu,...Yulun Zhang|[2510.01641](http://arxiv.org/abs/2510.01641)|null|\n", "2510.01183": "|**2025-10-01**|**EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory**|Jiahao Wang,...Jieneng Chen|[2510.01183](http://arxiv.org/abs/2510.01183)|**[link](https://github.com/JiahaoPlus/EvoWorld)**|\n", "2510.01179": "|**2025-10-01**|**TOUCAN: Synthesizing 1.5M Tool-Agentic Data from Real-World MCP Environments**|Zhangchen Xu,...Rameswar Panda|[2510.01179](http://arxiv.org/abs/2510.01179)|null|\n", "2510.00855": "|**2025-10-01**|**Can World Models Benefit VLMs for World Dynamics?**|Kevin Zhang,...Shanghang Zhang|[2510.00855](http://arxiv.org/abs/2510.00855)|**[link](https://dyva-worldlm.github.io)**|\n", "2510.00739": "|**2025-10-01**|**TD-JEPA: Latent-predictive Representations for Zero-Shot Reinforcement Learning**|Marco Bagatella,...Andrea Tirinzoni|[2510.00739](http://arxiv.org/abs/2510.00739)|null|\n", "2510.00406": "|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Hengtao Li,...Weihua Su|[2510.00406](http://arxiv.org/abs/2510.00406)|null|\n", "2510.00129": "|**2025-09-30**|**BigBang-Proton Technical Report: Next-Word-Prediction is Scientific Multitask Learner**|Hengkui Wu,...Weipeng Xu|[2510.00129](http://arxiv.org/abs/2510.00129)|null|\n", "2510.03198": "|**2025-10-03**|**Memory Forcing: Spatio-Temporal Memory for Consistent Scene Generation on Minecraft**|Junchao Huang,...Li Jiang|[2510.03198](http://arxiv.org/abs/2510.03198)|null|\n", "2510.02538": "|**2025-10-02**|**A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models**|Yilin Wang,...Hao Su|[2510.02538](http://arxiv.org/abs/2510.02538)|null|\n", "2510.02387": "|**2025-09-30**|**CWM: An Open-Weights LLM for Research on Code Generation with World Models**|FAIR CodeGen team,...Gabriel Synnaeve|[2510.02387](http://arxiv.org/abs/2510.02387)|null|\n", "2510.05057": "|**2025-10-06**|**StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation**|Mingyu Liu,...Chunhua Shen|[2510.05057](http://arxiv.org/abs/2510.05057)|null|\n", "2510.04978": "|**2025-10-06**|**Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI**|Kun Xiang,...Xiaodan Liang|[2510.04978](http://arxiv.org/abs/2510.04978)|null|\n", "2510.04542": "|**2025-10-06**|**Code World Models for General Game Playing**|Wolfgang Lehrach,...Kevin P. Murphy|[2510.04542](http://arxiv.org/abs/2510.04542)|null|\n", "2510.04391": "|**2025-10-05**|**Internal World Models as Imagination Networks in Cognitive Agents**|Saurabh Ranjan,...Brian Odegaard|[2510.04391](http://arxiv.org/abs/2510.04391)|null|\n", "2510.04390": "|**2025-10-05**|**MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D World Simulator**|Xuehai He,...Xin Eric Wang|[2510.04390](http://arxiv.org/abs/2510.04390)|null|\n", "2510.04374": "|**2025-10-05**|**GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks**|Tejal Patwardhan,...Jerry Tworek|[2510.04374](http://arxiv.org/abs/2510.04374)|null|\n", "2510.04020": "|**2025-10-09**|**Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models**|Hao Wu,...Xiaomeng Huang|[2510.04020](http://arxiv.org/abs/2510.04020)|null|\n", "2510.03727": "|**2025-10-04**|**Bridging the Gap Between Multimodal Foundation Models and World Models**|Xuehai He,...Xuehai He|[2510.03727](http://arxiv.org/abs/2510.03727)|null|\n", "2510.03420": "|**2025-10-03**|**A Generalized Second-Order Positivity-Preserving Numerical Method for Non-Autonomous Dynamical Systems with Applications**|Manh Tuan Hoang,...Matthias Ehrhardt|[2510.03420](http://arxiv.org/abs/2510.03420)|null|\n", "2510.06209": "|**2025-10-07**|**Drive&Gen: Co-Evaluating End-to-End Driving and Video Generation Models**|Jiahao Wang,...Chiyu Max Jiang|[2510.06209](http://arxiv.org/abs/2510.06209)|null|\n", "2510.05865": "|**2025-10-07**|**The Safety Challenge of World Models for Embodied AI Agents: A Review**|Lorenzo Baraldi,...Lorenzo Baraldi|[2510.05865](http://arxiv.org/abs/2510.05865)|null|\n", "2510.07313": "|**2025-10-08**|**WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation**|Zezhong Qian,...Shanghang Zhang|[2510.07313](http://arxiv.org/abs/2510.07313)|null|\n", "2510.07092": "|**2025-10-08**|**Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report**|Riccardo Mereu,...Paul Chang|[2510.07092](http://arxiv.org/abs/2510.07092)|null|\n", "2510.06492": "|**2025-10-07**|**What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?**|Matthew Kim,...Andrea Bajcsy|[2510.06492](http://arxiv.org/abs/2510.06492)|null|\n", "2510.06448": "|**2025-10-07**|**How NOT to benchmark your SITE metric: Beyond Static Leaderboards and Towards Realistic Evaluation**|Prabhant Singh,...Joaquin Vanschoren|[2510.06448](http://arxiv.org/abs/2510.06448)|null|\n", "2510.08558": "|**2025-10-13**|**Agent Learning via Early Experience**|Kai Zhang,...Yifan Wu|[2510.08558](http://arxiv.org/abs/2510.08558)|null|\n", "2510.08553": "|**2025-10-09**|**Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation**|Yunzhe Xu,...Zhe Liu|[2510.08553](http://arxiv.org/abs/2510.08553)|null|\n", "2510.08398": "|**2025-10-09**|**VideoVerse: How Far is Your T2V Generator from a World Model?**|Zeqing Wang,...Lei Zhang|[2510.08398](http://arxiv.org/abs/2510.08398)|null|\n", "2510.07974": "|**2025-10-11**|**Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning**|Jialu Du,...Weiming Lu|[2510.07974](http://arxiv.org/abs/2510.07974)|null|\n", "2510.07944": "|**2025-10-16**|**CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving**|Tianrui Zhang,...Zehuan Wu|[2510.07944](http://arxiv.org/abs/2510.07944)|null|\n", "2510.07456": "|**2025-10-08**|**ExpertAgent: Enhancing Personalized Education through Dynamic Planning and Retrieval-Augmented Long-Chain Reasoning**|Binrong Zhu,...Nina Jiang|[2510.07456](http://arxiv.org/abs/2510.07456)|null|\n", "2510.07417": "|**2025-10-08**|**FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams**|Corban Rivera,...David Handelman|[2510.07417](http://arxiv.org/abs/2510.07417)|null|\n", "2510.09036": "|**2025-10-10**|**iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation**|Chuanrui Zhang,...Ziwei Wang|[2510.09036](http://arxiv.org/abs/2510.09036)|null|\n", "2510.08713": "|**2025-10-09**|**Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation**|Yifei Dong,...Alexander G Hauptmann|[2510.08713](http://arxiv.org/abs/2510.08713)|**[link](https://github.com/F1y1113/UniWM)**|\n", "2510.11682": "|**2025-10-13**|**Ego-Vision World Model for Humanoid Contact Planning**|Hang Liu,...Koushil Sreenath|[2510.11682](http://arxiv.org/abs/2510.11682)|null|\n", "2510.10960": "|**2025-10-13**|**Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving**|Dong Hu,...Chao Huang|[2510.10960](http://arxiv.org/abs/2510.10960)|null|\n", "2510.10670": "|**2025-10-12**|**AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D Scenes**|Yu Li,...Yujiu Yang|[2510.10670](http://arxiv.org/abs/2510.10670)|null|\n", "2510.10325": "|**2025-10-11**|**KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments**|Walid Abdela,...Walid Abdela|[2510.10325](http://arxiv.org/abs/2510.10325)|null|\n", "2510.10125": "|**2025-10-15**|**Ctrl-World: A Controllable Generative World Model for Robot Manipulation**|Yanjiang Guo,...Chelsea Finn|[2510.10125](http://arxiv.org/abs/2510.10125)|null|\n", "2510.12796": "|**2025-10-14**|**DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving**|Yingyan Li,...Zhaoxiang Zhang|[2510.12796](http://arxiv.org/abs/2510.12796)|null|\n", "2510.12560": "|**2025-10-14**|**CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving**|Xiaoji Zheng,...Jiangtao Gong|[2510.12560](http://arxiv.org/abs/2510.12560)|null|\n", "2510.12312": "|**2025-10-14**|**Deep SPI: Safe Policy Improvement via World Models**|Florent Delgrange,...Willem R\u00f6pke|[2510.12312](http://arxiv.org/abs/2510.12312)|null|\n", "2510.12088": "|**2025-10-14**|**One Life to Learn: Inferring Symbolic World Models for Stochastic Environments from Unguided Exploration**|Zaid Khan,...Mohit Bansal|[2510.12088](http://arxiv.org/abs/2510.12088)|**[link](https://onelife-worldmodel.github.io/)**|\n", "2510.11892": "|**2025-10-13**|**R-WoM: Retrieval-augmented World Model For Computer-use Agents**|Kai Mei,...Jiarong Jiang|[2510.11892](http://arxiv.org/abs/2510.11892)|null|\n", "2510.13809": "|**2025-10-15**|**PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning**|Sihui Ji,...Hengshuang Zhao|[2510.13809](http://arxiv.org/abs/2510.13809)|**[link](https://sihuiji.github.io/PhysMaster-Page/)**|\n", "2510.13804": "|**2025-10-15**|**Generative Universal Verifier as Multimodal Meta-Reasoner**|Xinchen Zhang,...Yujiu Yang|[2510.13804](http://arxiv.org/abs/2510.13804)|null|\n", "2510.13247": "|**2025-10-15**|**Agency cannot be a purely quantum phenomenon**|Emily C. Adlam,...Mordecai Waegell|[2510.13247](http://arxiv.org/abs/2510.13247)|null|\n", "2510.14977": "|**2025-10-16**|**Terra: Explorable Native 3D World Model with Point Latents**|Yuanhui Huang,...Jiwen Lu|[2510.14977](http://arxiv.org/abs/2510.14977)|**[link](https://huang-yh.github.io/terra/)**|\n", "2510.14783": "|**2025-10-16**|**SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning**|Aderik Verraest,...Christophe De Wagter|[2510.14783](http://arxiv.org/abs/2510.14783)|null|\n", "2510.15422": "|**2025-10-17**|**Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction**|Lin Wang,...Lin Wang|[2510.15422](http://arxiv.org/abs/2510.15422)|null|\n", "2510.15144": "|**2025-10-16**|**HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks**|Chance Jiajie Li,...Kent Larson|[2510.15144](http://arxiv.org/abs/2510.15144)|null|\n", "2510.15047": "|**2025-10-16**|**Internalizing World Models via Self-Play Finetuning for Agentic RL**|Shiqi Chen,...Manling Li|[2510.15047](http://arxiv.org/abs/2510.15047)|null|\n", "2510.15041": "|**2025-10-16**|**Generalized Dynamics Generation towards Scannable Physical World Model**|Yichen Li,...Antonio Torralba|[2510.15041](http://arxiv.org/abs/2510.15041)|null|\n", "2510.17731": "|**2025-10-20**|**Can Image-To-Video Models Simulate Pedestrian Dynamics?**|Aaron Appelle,...Jerome P. Lynch|[2510.17731](http://arxiv.org/abs/2510.17731)|**[link](https://physical-world-modeling.github.io/)**|\n", "2510.17482": "|**2025-10-22**|**SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries**|Chenxu Dang,...Yan Wang|[2510.17482](http://arxiv.org/abs/2510.17482)|null|\n", "2510.16907": "|**2025-10-19**|**VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents**|Kangrui Wang,...Manling Li|[2510.16907](http://arxiv.org/abs/2510.16907)|null|\n", "2510.16732": "|**2025-10-19**|**A Comprehensive Survey on World Models for Embodied AI**|Xinqing Li,...Yun Liu|[2510.16732](http://arxiv.org/abs/2510.16732)|**[link](https://github.com/Li-Zn-H/AwesomeWorldModels)**|\n", "2510.16729": "|**2025-10-19**|**Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models**|Jianbiao Mei,...Yong Liu|[2510.16729](http://arxiv.org/abs/2510.16729)|null|\n", "2510.16500": "|**2025-10-18**|**Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks**|Chen Min,...Yu Hu|[2510.16500](http://arxiv.org/abs/2510.16500)|null|\n", "2510.16240": "|**2025-10-17**|**Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning**|Lukas Zbinden,...Sean Huver|[2510.16240](http://arxiv.org/abs/2510.16240)|null|\n", "2510.16123": "|**2025-10-17**|**Zero-shot World Models via Search in Memory**|Federico Malato,...Ville Hautam\u00e4ki|[2510.16123](http://arxiv.org/abs/2510.16123)|null|\n", "2510.16039": "|**2025-10-16**|**Vector Quantization in the Brain: Grid-like Codes in World Models**|Xiangyuan Peng,...Si Wu|[2510.16039](http://arxiv.org/abs/2510.16039)|null|\n", "2510.18315": "|**2025-10-21**|**Higher Embedding Dimension Creates a Stronger World Model for a Simple Sorting Task**|Brady Bhalla,...Tony Yue YU|[2510.18315](http://arxiv.org/abs/2510.18315)|null|\n", "2510.18313": "|**2025-10-24**|**OmniNWM: Omniscient Driving Navigation World Models**|Bohan Li,...Xin Jin|[2510.18313](http://arxiv.org/abs/2510.18313)|**[link](https://arlo0o.github.io/OmniNWM/)**|\n", "2510.18135": "|**2025-10-20**|**World-in-World: World Models in a Closed-Loop World**|Jiahan Zhang,...Jieneng Chen|[2510.18135](http://arxiv.org/abs/2510.18135)|**[link](https://github.com/World-In-World/world-in-world)**|\n", "2510.19818": "|**2025-10-22**|**Semantic World Models**|Jacob Berg,...Abhishek Gupta|[2510.19818](http://arxiv.org/abs/2510.19818)|null|\n", "2510.19788": "|**2025-10-23**|**Benchmarking World-Model Learning**|Archana Warrier,...Zenna Tavares|[2510.19788](http://arxiv.org/abs/2510.19788)|null|\n", "2510.19654": "|**2025-10-22**|**From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction**|Zhida Zhao,...Huchuan Lu|[2510.19654](http://arxiv.org/abs/2510.19654)|null|\n", "2510.19430": "|**2025-10-22**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**|GigaBrain Team,...Zheng Zhu|[2510.19430](http://arxiv.org/abs/2510.19430)|**[link](https://gigabrain0.github.io/)**|\n", "2510.19364": "|**2025-10-22**|**ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling**|Golnaz Raja,...Reza Ghabcheloo|[2510.19364](http://arxiv.org/abs/2510.19364)|null|\n", "2510.19270": "|**2025-10-22**|**Social World Model-Augmented Mechanism Design Policy Learning**|Xiaoyuan Zhang,...Xue Feng|[2510.19270](http://arxiv.org/abs/2510.19270)|null|\n", "2510.19195": "|**2025-10-24**|**Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks**|Kai Zeng,...Wentao Zhang|[2510.19195](http://arxiv.org/abs/2510.19195)|null|\n", "2510.20668": "|**2025-10-23**|**From Masks to Worlds: A Hitchhiker's Guide to World Models**|Jinbin Bai,...Ming-Hsuan Yang|[2510.20668](http://arxiv.org/abs/2510.20668)|**[link](https://github.com/M-E-AGI-Lab/Awesome-World-Models)**|\n", "2510.21682": "|**2025-10-24**|**WorldGrow: Generating Infinite 3D World**|Sikuang Li,...Qi Tian|[2510.21682](http://arxiv.org/abs/2510.21682)|**[link](https://world-grow.github.io/)**|\n", "2510.21447": "|**2025-10-24**|**PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis**|Yu Yang,...Wangmeng Zuo|[2510.21447](http://arxiv.org/abs/2510.21447)|null|\n", "2510.21418": "|**2025-10-24**|**DreamerV3-XP: Optimizing exploration through uncertainty estimation**|Lukas Bierling,...Kiki Van Gerwen|[2510.21418](http://arxiv.org/abs/2510.21418)|null|\n", "2510.21232": "|**2025-10-24**|**How Hard is it to Confuse a World Model?**|Waris Radji,...Odalric-Ambrym Maillard|[2510.21232](http://arxiv.org/abs/2510.21232)|null|\n", "2510.21219": "|**2025-10-24**|**World Models Should Prioritize the Unification of Physical and Social Dynamics**|Xiaoyuan Zhang,...Yaodong Yang|[2510.21219](http://arxiv.org/abs/2510.21219)|null|\n", "2510.20884": "|**2025-10-23**|**ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning**|Pranamya Kulkarni,...Ali Tajer|[2510.20884](http://arxiv.org/abs/2510.20884)|null|\n", "2510.23509": "|**2025-10-27**|**Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model**|Weizheng Wang,...Byung-Cheol Min|[2510.23509](http://arxiv.org/abs/2510.23509)|null|\n", "2510.23258": "|**2025-10-27**|**Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation**|Riko Yokozawa,...Shingo Murata|[2510.23258](http://arxiv.org/abs/2510.23258)|null|\n", "2510.22732": "|**2025-10-26**|**ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation**|Jiali Cheng,...Hadi Amiri|[2510.22732](http://arxiv.org/abs/2510.22732)|null|\n", "2510.22304": "|**2025-10-28**|**ODesign: A World Model for Biomolecular Interaction Design**|Odin Zhang,...Shuangjia Zheng|[2510.22304](http://arxiv.org/abs/2510.22304)|null|\n", "2510.22200": "|**2025-10-28**|**LongCat-Video Technical Report**|Meituan LongCat Team,...Tong Zhang|[2510.22200](http://arxiv.org/abs/2510.22200)|null|\n", "2510.21867": "|**2025-10-23**|**Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs**|Haicheng Liao,...Zhenning Li|[2510.21867](http://arxiv.org/abs/2510.21867)|null|\n", "2510.21840": "|**2025-10-22**|**Improving the Physics of Video Generation with VJEPA-2 Reward Signal**|Jianhao Yuan,...Adriana Romero-Soriano|[2510.21840](http://arxiv.org/abs/2510.21840)|null|\n", "2510.24690": "|**2025-10-28**|**Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning**|Shengjie Liu,...Zhenyu Zhang|[2510.24690](http://arxiv.org/abs/2510.24690)|null|\n", "2510.24654": "|**2025-10-28**|**Evolving Diagnostic Agents in a Virtual Clinical Environment**|Pengcheng Qiu,...Weidi Xie|[2510.24654](http://arxiv.org/abs/2510.24654)|null|\n", "2510.24546": "|**2025-10-28**|**Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks**|Lingyi Wang,...Naren Ramakrishnan|[2510.24546](http://arxiv.org/abs/2510.24546)|null|\n", "2510.24459": "|**2025-10-28**|**Affordance Representation and Recognition for Autonomous Agents**|Habtom Kahsay Gidey,...Alois Knoll|[2510.24459](http://arxiv.org/abs/2510.24459)|null|\n", "2510.24030": "|**2025-10-28**|**Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts**|Ahmet Akkaya Melih,...Hanuman Bhatia|[2510.24030](http://arxiv.org/abs/2510.24030)|null|\n"}, "VLM": {"2509.21301": "|**2025-09-25**|**Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive Cross-Stage Parallelization**|Yuhang Xu,...Guihai Chen|[2509.21301](http://arxiv.org/abs/2509.21301)|null|\n", "2509.21287": "|**2025-09-25**|**DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding**|Kin Ian Lo,...Mehrnoosh Sadrzadeh|[2509.21287](http://arxiv.org/abs/2509.21287)|null|\n", "2509.21262": "|**2025-09-25**|**Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication**|Evgeny Kaskov,...Alexander Nagaev|[2509.21262](http://arxiv.org/abs/2509.21262)|null|\n", "2509.21257": "|**2025-09-25**|**Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation**|Seyed Amir Kasaei,...Mohammad Hossein Rohban|[2509.21257](http://arxiv.org/abs/2509.21257)|null|\n", "2509.21247": "|**2025-09-25**|**Learning to Look: Cognitive Attention Alignment with Vision-Language Models**|Ryan L. Yang,...Nidhi Rastogi|[2509.21247](http://arxiv.org/abs/2509.21247)|null|\n", "2509.21205": "|**2025-09-25**|**TABLET: A Large-Scale Dataset for Robust Visual Table Understanding**|I\u00f1igo Alonso,...Mirella Lapata|[2509.21205](http://arxiv.org/abs/2509.21205)|null|\n", "2509.21189": "|**2025-09-25**|**Human-like Navigation in a World Built for Humans**|Bhargav Chandaka,...Shenlong Wang|[2509.21189](http://arxiv.org/abs/2509.21189)|**[link](https://reasonnav.github.io/)**|\n", "2509.21173": "|**2025-09-25**|**Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy**|Aymen Bouguerra,...Chokri Mraidha|[2509.21173](http://arxiv.org/abs/2509.21173)|null|\n", "2509.21126": "|**2025-09-25**|**Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning**|Xiefeng Wu,...Mingyu Hu|[2509.21126](http://arxiv.org/abs/2509.21126)|null|\n", "2509.21107": "|**2025-09-25**|**Cross-Modal Instructions for Robot Motion Generation**|William Barron,...Weiming Zhi|[2509.21107](http://arxiv.org/abs/2509.21107)|null|\n", "2509.21102": "|**2025-09-25**|**Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models**|Suaiba Amina Salahuddin,...Robert Jenssen|[2509.21102](http://arxiv.org/abs/2509.21102)|null|\n", "2509.21079": "|**2025-09-25**|**SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials**|Qixin Wan,...Lu Cheng|[2509.21079](http://arxiv.org/abs/2509.21079)|null|\n", "2509.20961": "|**2025-09-25**|**Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos**|Sarmistha Das,...Alka Maurya|[2509.20961](http://arxiv.org/abs/2509.20961)|null|\n", "2509.20941": "|**2025-09-25**|**Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery**|Angelo Henriques,...M. Ali Nasseri|[2509.20941](http://arxiv.org/abs/2509.20941)|null|\n", "2509.20843": "|**2025-09-25**|**MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases**|Ziang Luo,...Diange Yang|[2509.20843](http://arxiv.org/abs/2509.20843)|null|\n", "2509.20792": "|**2025-09-25**|**DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation**|Ved Umrajkar,...Ved Umrajkar|[2509.20792](http://arxiv.org/abs/2509.20792)|null|\n", "2509.20769": "|**2025-09-25**|**Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems**|Tuo Zhang,...Ruiliang Liu|[2509.20769](http://arxiv.org/abs/2509.20769)|null|\n", "2509.20751": "|**2025-09-25**|**Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models**|Zoe Wanying He,...Meenakshi Khosla|[2509.20751](http://arxiv.org/abs/2509.20751)|null|\n", "2509.20628": "|**2025-09-25**|**Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery**|Yiming Xiao,...Ali Mostafavi|[2509.20628](http://arxiv.org/abs/2509.20628)|null|\n", "2509.20524": "|**2025-09-24**|**InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On**|Julien Han,...Karim Bouyarmane|[2509.20524](http://arxiv.org/abs/2509.20524)|null|\n", "2509.22653": "|**2025-09-26**|**See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation**|Chih Yao Hu,...Yu-Lun Liu|[2509.22653](http://arxiv.org/abs/2509.22653)|**[link](https://spf-web.pages.dev)**|\n", "2509.22647": "|**2025-09-26**|**CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning**|Long Xing,...Dahua Lin|[2509.22647](http://arxiv.org/abs/2509.22647)|**[link](https://github.com/InternLM/CapRL)**|\n", "2509.22645": "|**2025-09-26**|**Hierarchical Representation Matching for CLIP-based Class-Incremental Learning**|Zhen-Hao Wen,...Da-Wei Zhou|[2509.22645](http://arxiv.org/abs/2509.22645)|null|\n", "2509.22642": "|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Xiaowei Chi,...Jian Tang|[2509.22642](http://arxiv.org/abs/2509.22642)|null|\n", "2509.22624": "|**2025-09-26**|**SPARK: Synergistic Policy And Reward Co-Evolving Framework**|Ziyu Liu,...Jiaqi Wang|[2509.22624](http://arxiv.org/abs/2509.22624)|**[link](https://github.com/InternLM/Spark)**|\n", "2509.22524": "|**2025-09-26**|**Color Names in Vision-Language Models**|Alexandra Gomez-Villa,...Javier Vazquez-Corral|[2509.22524](http://arxiv.org/abs/2509.22524)|null|\n", "2509.22447": "|**2025-09-26**|**Guiding Evolution of Artificial Life Using Vision-Language Models**|Nikhil Baid,...Frederico Wieser|[2509.22447](http://arxiv.org/abs/2509.22447)|null|\n", "2509.22437": "|**2025-09-26**|**Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding**|Ziheng Chi,...Mrinmaya Sachan|[2509.22437](http://arxiv.org/abs/2509.22437)|**[link](https://github.com/CHIzhP/Chimera))**|\n", "2509.22404": "|**2025-09-26**|**RAU: Reference-based Anatomical Understanding with Vision Language Models**|Yiwei Li,...Shanhui Sun|[2509.22404](http://arxiv.org/abs/2509.22404)|null|\n", "2509.22378": "|**2025-09-26**|**Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach**|Zijian Zhao,...Zijing Zhou|[2509.22378](http://arxiv.org/abs/2509.22378)|null|\n", "2509.22283": "|**2025-09-26**|**Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models**|Michael Jungo,...Andreas Fischer|[2509.22283](http://arxiv.org/abs/2509.22283)|**[link](https://github.com/jungomi/vision-finetune)**|\n", "2509.22258": "|**2025-09-26**|**Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks**|Miao Jing,...Shangyang Li|[2509.22258](http://arxiv.org/abs/2509.22258)|null|\n", "2509.22229": "|**2025-09-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Jiaping Yu,...Cheng Deng|[2509.22229](http://arxiv.org/abs/2509.22229)|null|\n", "2509.22225": "|**2025-09-26**|**Polysemous Language Gaussian Splatting via Matching-based Mask Lifting**|Jiayu Ding,...Ge Li|[2509.22225](http://arxiv.org/abs/2509.22225)|null|\n", "2509.22221": "|**2025-09-26**|**Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models**|Jiaqi Liu,...Bo Yang|[2509.22221](http://arxiv.org/abs/2509.22221)|null|\n", "2509.22195": "|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Asher J. Hancock,...Anirudha Majumdar|[2509.22195](http://arxiv.org/abs/2509.22195)|null|\n", "2509.22186": "|**2025-09-26**|**MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing**|Junbo Niu,...Conghui He|[2509.22186](http://arxiv.org/abs/2509.22186)|**[link](https://github.com/opendatalab/MinerU)**|\n", "2509.22123": "|**2025-09-26**|**Multilingual Vision-Language Models, A Survey**|Andrei-Alexandru Manea,...Jind\u0159ich Libovick\u00fd|[2509.22123](http://arxiv.org/abs/2509.22123)|null|\n", "2509.22014": "|**2025-09-26**|**Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics**|Saurav Jha,...Stefan K. Ehrlich|[2509.22014](http://arxiv.org/abs/2509.22014)|null|\n", "2509.22010": "|**2025-09-26**|**CoFFT: Chain of Foresight-Focus Thought for Visual Language Models**|Xinyu Zhang,...Mike Zheng Shou|[2509.22010](http://arxiv.org/abs/2509.22010)|null|\n", "2509.25143": "|**2025-09-29**|**TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models**|Junyi Zhang,...Nanyun Peng|[2509.25143](http://arxiv.org/abs/2509.25143)|null|\n", "2509.25142": "|**2025-09-29**|**Visual serial processing deficits explain divergences in human and VLM reasoning**|Nicholas Budny,...Thomas L. Griffiths|[2509.25142](http://arxiv.org/abs/2509.25142)|null|\n", "2509.25026": "|**2025-09-29**|**GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning**|Mustansar Fiaz,...Salman Khan|[2509.25026](http://arxiv.org/abs/2509.25026)|**[link](https://mustansarfiaz.github.io/GeoVLM-R1/)**|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24917": "|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Markus Peschl,...Daniel Dijkman|[2509.24917](http://arxiv.org/abs/2509.24917)|null|\n", "2509.24837": "|**2025-09-29**|**Training-Free Token Pruning via Zeroth-Order Gradient Estimation in Vision-Language Models**|Youngeun Kim,...Sungeun Hong|[2509.24837](http://arxiv.org/abs/2509.24837)|null|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Eric Hannus,...Ville Kyrki|[2509.24768](http://arxiv.org/abs/2509.24768)|null|\n", "2509.24709": "|**2025-09-29**|**IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?**|Yang Chen,...Botian Shi|[2509.24709](http://arxiv.org/abs/2509.24709)|null|\n", "2509.24640": "|**2025-09-29**|**Can you SPLICE it together? A Human Curated Benchmark for Probing Visual Reasoning in VLMs**|Mohamad Ballout,...Elia Bruni|[2509.24640](http://arxiv.org/abs/2509.24640)|null|\n", "2509.24597": "|**2025-09-30**|**Inducing Dyslexia in Vision Language Models**|Melika Honarmand,...Martin Schrimpf|[2509.24597](http://arxiv.org/abs/2509.24597)|null|\n", "2509.24566": "|**2025-09-29**|**TokenSwap: Backdoor Attack on the Compositional Understanding of Large Vision-Language Models**|Zhifang Zhang,...Joey Tianyi Zhou|[2509.24566](http://arxiv.org/abs/2509.24566)|null|\n", "2509.24528": "|**2025-09-29**|**CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D**|Mohamad Amin Mirzaei,...Matin Mirzababaei|[2509.24528](http://arxiv.org/abs/2509.24528)|null|\n", "2509.24524": "|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Zhihao Wang,...Xianyuan Zhan|[2509.24524](http://arxiv.org/abs/2509.24524)|null|\n", "2509.24494": "|**2025-09-29**|**GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training**|Hongcheng Wang,...Hao Dong|[2509.24494](http://arxiv.org/abs/2509.24494)|null|\n", "2509.24473": "|**2025-09-29**|**Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks**|Shijie Lian,...Kai Chen|[2509.24473](http://arxiv.org/abs/2509.24473)|null|\n", "2509.24378": "|**2025-09-29**|**AXIS: Explainable Time Series Anomaly Detection with Large Language Models**|Tian Lan,...Chen Zhang|[2509.24378](http://arxiv.org/abs/2509.24378)|null|\n", "2509.24321": "|**2025-09-29**|**SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm**|Yao Wang,...Jiankun Wang|[2509.24321](http://arxiv.org/abs/2509.24321)|null|\n", "2509.24304": "|**2025-09-30**|**FrameThinker: Learning to Think with Long Videos via Multi-Turn Frame Spotlighting**|Zefeng He,...Yu Cheng|[2509.24304](http://arxiv.org/abs/2509.24304)|null|\n", "2509.24219": "|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Tomoyuki Kagaya,...Yang You|[2509.24219](http://arxiv.org/abs/2509.24219)|null|\n", "2509.24192": "|**2025-09-29**|**Talk in Pieces, See in Whole: Disentangling and Hierarchical Aggregating Representations for Language-based Object Detection**|Sojung An,...Donghyun Kim|[2509.24192](http://arxiv.org/abs/2509.24192)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.26641": "|**2025-09-30**|**Query-Kontext: An Unified Multimodal Model for Image Generation and Editing**|Yuxin Song,...Jingdong Wang|[2509.26641](http://arxiv.org/abs/2509.26641)|null|\n", "2509.26594": "|**2025-09-30**|**Clarification as Supervision: Reinforcement Learning for Vision-Language Interfaces**|John Gkountouras,...Ivan Titov|[2509.26594](http://arxiv.org/abs/2509.26594)|null|\n", "2509.26557": "|**2025-09-30**|**The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows**|Litao Yan,...Emerson Murphy-Hill|[2509.26557](http://arxiv.org/abs/2509.26557)|null|\n", "2509.26555": "|**2025-09-30**|**Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation**|Agneet Chatterjee,...Varun Jampani|[2509.26555](http://arxiv.org/abs/2509.26555)|**[link](https://stable-cinemetrics.github.io/)**|\n", "2509.26462": "|**2025-09-30**|**Zero-Shot Decentralized Federated Learning**|Alessio Masano,...Giovanni Bellitto|[2509.26462](http://arxiv.org/abs/2509.26462)|**[link](https://github.com/perceivelab/ZeroDFL)**|\n", "2509.26330": "|**2025-09-30**|**SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval**|Ren-Di Wu,...Huei-Fang Yang|[2509.26330](http://arxiv.org/abs/2509.26330)|null|\n", "2509.26278": "|**2025-09-30**|**ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation**|Edoardo Bianchi,...Antonio Liotta|[2509.26278](http://arxiv.org/abs/2509.26278)|null|\n", "2509.26235": "|**2025-09-30**|**Interpret, prune and distill Donut : towards lightweight VLMs for VQA on document**|Adnan Ben Mansour,...David Naccache|[2509.26235](http://arxiv.org/abs/2509.26235)|null|\n", "2509.26208": "|**2025-09-30**|**TSalV360: A Method and Dataset for Text-driven Saliency Detection in 360-Degrees Videos**|Ioannis Kontostathis,...Vasileios Mezaris|[2509.26208](http://arxiv.org/abs/2509.26208)|**[link](https://ieeexplore.ieee.org/)**|\n", "2509.26039": "|**2025-09-30**|**SGS: Segmentation-Guided Scoring for Global Scene Inconsistencies**|Gagandeep Singh,...Xue Li|[2509.26039](http://arxiv.org/abs/2509.26039)|null|\n", "2509.26006": "|**2025-10-01**|**AgenticIQA: An Agentic Framework for Adaptive and Interpretable Image Quality Assessment**|Hanwei Zhu,...Weisi Lin|[2509.26006](http://arxiv.org/abs/2509.26006)|null|\n", "2509.26004": "|**2025-09-30**|**Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations**|Nicola Messina,...Antonino Furnari|[2509.26004](http://arxiv.org/abs/2509.26004)|null|\n", "2509.25991": "|**2025-09-30**|**Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline**|Haiyang Li,...Zhun Zhong|[2509.25991](http://arxiv.org/abs/2509.25991)|null|\n", "2509.25944": "|**2025-09-30**|**NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving**|Yuan Gao,...Johannes Betz|[2509.25944](http://arxiv.org/abs/2509.25944)|null|\n", "2509.25916": "|**2025-09-30**|**VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs**|Peng Liu,...Tiancheng Zhao|[2509.25916](http://arxiv.org/abs/2509.25916)|null|\n", "2509.25896": "|**2025-10-01**|**LLaVAShield: Safeguarding Multimodal Multi-Turn Dialogues in Vision-Language Models**|Guolei Huang,...Yongjun Shen|[2509.25896](http://arxiv.org/abs/2509.25896)|null|\n", "2509.25866": "|**2025-09-30**|**DeepSketcher: Internalizing Visual Manipulation for Multimodal Reasoning**|Chi Zhang,...Jing Zhang|[2509.25866](http://arxiv.org/abs/2509.25866)|null|\n", "2509.25863": "|**2025-09-30**|**MAPLE: Multi-scale Attribute-enhanced Prompt Learning for Few-shot Whole Slide Image Classification**|Junjie Zhou,...Daoqiang Zhang|[2509.25863](http://arxiv.org/abs/2509.25863)|null|\n", "2509.25852": "|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Zitong Bo,...Hao Chen|[2509.25852](http://arxiv.org/abs/2509.25852)|null|\n", "2510.02292": "|**2025-10-02**|**From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens**|Hala Sheta,...Freda Shi|[2510.02292](http://arxiv.org/abs/2510.02292)|**[link](https://github.com/compling-wat/vlm-lens)**|\n", "2510.02270": "|**2025-10-02**|**microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification**|Sathira Silva,...Muhammad Haris Khan|[2510.02270](http://arxiv.org/abs/2510.02270)|null|\n", "2510.02204": "|**2025-10-02**|**Say One Thing, Do Another? Diagnosing Reasoning-Execution Gaps in VLM-Powered Mobile-Use Agents**|Lingzhong Dong,...Zhuosheng Zhang|[2510.02204](http://arxiv.org/abs/2510.02204)|null|\n", "2510.02186": "|**2025-10-02**|**GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation**|Weijia Dou,...Heng Tao Shen|[2510.02186](http://arxiv.org/abs/2510.02186)|null|\n", "2510.02155": "|**2025-10-02**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Shu Zou,...Jing Zhang|[2510.02155](http://arxiv.org/abs/2510.02155)|null|\n", "2510.01795": "|**2025-10-02**|**Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving**|Haibo Hu,...Chun Jason Xue|[2510.01795](http://arxiv.org/abs/2510.01795)|null|\n", "2510.01718": "|**2025-10-02**|**Accelerating Attention with Basis Decomposition**|Jialin Zhao,...Jialin Zhao|[2510.01718](http://arxiv.org/abs/2510.01718)|null|\n", "2510.01711": "|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim,...Jinwoo Shin|[2510.01711](http://arxiv.org/abs/2510.01711)|null|\n", "2510.01700": "|**2025-10-02**|**VaPR -- Vision-language Preference alignment for Reasoning**|Rohan Wadhawan,...Nanyun Peng|[2510.01700](http://arxiv.org/abs/2510.01700)|null|\n", "2510.01681": "|**2025-10-02**|**Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning**|Xuchen Li,...Wentao Zhang|[2510.01681](http://arxiv.org/abs/2510.01681)|null|\n", "2510.01649": "|**2025-10-02**|**Source-Free Cross-Domain Continual Learning**|Muhammad Tanzil Furqon,...Kutluyil Dogancay|[2510.01649](http://arxiv.org/abs/2510.01649)|null|\n", "2510.01642": "|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin,...Bihan Wen|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|\n", "2510.01582": "|**2025-10-02**|**ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models**|Krishna Teja Chitty-Venkata,...Murali Emani|[2510.01582](http://arxiv.org/abs/2510.01582)|null|\n", "2510.01494": "|**2025-10-03**|**Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed**|Isha Gupta,...Sanmi Koyejo|[2510.01494](http://arxiv.org/abs/2510.01494)|null|\n", "2510.01483": "|**2025-10-01**|**VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs**|Mohamad Al Mdfaa,...Gonzalo Ferrer|[2510.01483](http://arxiv.org/abs/2510.01483)|null|\n", "2510.01454": "|**2025-10-01**|**Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories**|Nilay Naharas,...Baharan Mirzasoleiman|[2510.01454](http://arxiv.org/abs/2510.01454)|**[link](https://bigml-cs-ucla.github.io/XMAS-project-page/)**|\n", "2510.01448": "|**2025-10-01**|**GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings**|Angel Daruna,...Rakesh Kumar|[2510.01448](http://arxiv.org/abs/2510.01448)|null|\n", "2510.01388": "|**2025-10-01**|**VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation**|Arthur Zhang,...Amirreza Shaban|[2510.01388](http://arxiv.org/abs/2510.01388)|null|\n", "2510.01185": "|**2025-10-01**|**Dirichlet-Prior Shaping: Guiding Expert Specialization in Upcycled MoEs**|Leyla Mirvakhabova,...Paul Whatmough|[2510.01185](http://arxiv.org/abs/2510.01185)|null|\n", "2510.01304": "|**2025-10-01**|**Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models**|Yu Zeng,...Feng Zhao|[2510.01304](http://arxiv.org/abs/2510.01304)|null|\n", "2510.03182": "|**2025-10-03**|**Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning**|Yilun Hao,...Yang Zhang|[2510.03182](http://arxiv.org/abs/2510.03182)|null|\n", "2510.03160": "|**2025-10-03**|**SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus**|Ming Zhao,...Caifeng Shan|[2510.03160](http://arxiv.org/abs/2510.03160)|null|\n", "2510.02922": "|**2025-10-03**|**Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights**|Daphne Tsolissou,...Konstantina Nikita|[2510.02922](http://arxiv.org/abs/2510.02922)|null|\n", "2510.02913": "|**2025-10-03**|**Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting**|Nikoo Naghavian,...Mostafa Tavassolipour|[2510.02913](http://arxiv.org/abs/2510.02913)|null|\n", "2510.02815": "|**2025-10-03**|**Med-K2N: Flexible K-to-N Modality Translation for Medical Image Synthesis**|Feng Yuan,...Xin Gao|[2510.02815](http://arxiv.org/abs/2510.02815)|null|\n", "2510.02790": "|**2025-10-03**|**MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding**|Jingyuan Deng,...Yujiu Yang|[2510.02790](http://arxiv.org/abs/2510.02790)|null|\n", "2510.02787": "|**2025-10-03**|**OTR: Synthesizing Overlay Text Dataset for Text Removal**|Jan Zdenek,...Kota Yamaguchi|[2510.02787](http://arxiv.org/abs/2510.02787)|**[link](https://doi.org/10.1145/3746027.3758297)**|\n", "2510.02780": "|**2025-10-03**|**Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models**|Prahitha Movva,...Prahitha Movva|[2510.02780](http://arxiv.org/abs/2510.02780)|null|\n", "2510.02778": "|**2025-10-03**|**AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding**|Xian Zhang,...Mohammed Bennamoun|[2510.02778](http://arxiv.org/abs/2510.02778)|null|\n", "2510.02750": "|**2025-10-03**|**Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models**|Lihua Zhou,...Zhen Lei|[2510.02750](http://arxiv.org/abs/2510.02750)|null|\n", "2510.02728": "|**2025-10-03**|**Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4**|Lingfeng Zhang,...Xiaoshuai Hao|[2510.02728](http://arxiv.org/abs/2510.02728)|null|\n", "2510.02677": "|**2025-10-03**|**ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks**|Zhaorun Chen,...Bo Li|[2510.02677](http://arxiv.org/abs/2510.02677)|null|\n", "2510.02543": "|**2025-10-02**|**Exploring OCR-augmented Generation for Bilingual VQA**|JoonHo Lee,...Sunho Park|[2510.02543](http://arxiv.org/abs/2510.02543)|null|\n", "2510.02528": "|**2025-10-02**|**Multimodal Function Vectors for Spatial Relations**|Shuhao Fu,...Hongjing Lu|[2510.02528](http://arxiv.org/abs/2510.02528)|null|\n", "2510.05038": "|**2025-10-06**|**Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization**|Omri Uzan,...Ariel Gera|[2510.05038](http://arxiv.org/abs/2510.05038)|null|\n", "2510.04991": "|**2025-10-06**|**Efficient Navigation in Unknown Indoor Environments with Vision-Language Models**|D. Schwartz,...J. P. How|[2510.04991](http://arxiv.org/abs/2510.04991)|null|\n", "2510.04710": "|**2025-10-06**|**ViTs: Teaching Machines to See Time Series Anomalies Like Human Experts**|Zexin Wang,...Dan Pei|[2510.04710](http://arxiv.org/abs/2510.04710)|null|\n", "2510.04564": "|**2025-10-06**|**Conditional Representation Learning for Customized Tasks**|Honglin Liu,...Xi Peng|[2510.04564](http://arxiv.org/abs/2510.04564)|null|\n", "2510.04532": "|**2025-10-06**|**More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models**|Xurui Song,...Jun Luo|[2510.04532](http://arxiv.org/abs/2510.04532)|null|\n", "2510.04479": "|**2025-10-06**|**VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery**|Nonghai Zhang,...Hao Tang|[2510.04479](http://arxiv.org/abs/2510.04479)|null|\n", "2510.04477": "|**2025-10-06**|**MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models**|Soo Yong Kim,...Gyeongyeon Hwang|[2510.04477](http://arxiv.org/abs/2510.04477)|null|\n", "2510.04428": "|**2025-10-06**|**A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering**|Yuanhao Zou,...Chen Chen|[2510.04428](http://arxiv.org/abs/2510.04428)|null|\n", "2510.04401": "|**2025-10-06**|**Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting**|Xuyang Guo,...Jiahao Zhang|[2510.04401](http://arxiv.org/abs/2510.04401)|null|\n", "2510.04257": "|**2025-10-05**|**AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents**|Yanjie Li,...Bin Xiao|[2510.04257](http://arxiv.org/abs/2510.04257)|null|\n", "2510.04246": "|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Huiwon Jang,...Jinwoo Shin|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|\n", "2510.04225": "|**2025-10-05**|**Zoom-In to Sort AI-Generated Images Out**|Yikun Ji,...Jianfu Zhang|[2510.04225](http://arxiv.org/abs/2510.04225)|null|\n", "2510.04145": "|**2025-10-05**|**Automating construction safety inspections using a multi-modal vision-language RAG framework**|Chenxin Wang,...Daniel Dias-da-Costa|[2510.04145](http://arxiv.org/abs/2510.04145)|null|\n", "2510.04002": "|**2025-10-07**|**AgriGPT-VL: Agricultural Vision-Language Understanding Suite**|Bo Yang,...Shijian Li|[2510.04002](http://arxiv.org/abs/2510.04002)|null|\n", "2510.03978": "|**2025-10-04**|**No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models**|Min Woo Sun,...Serena Yeung-Levy|[2510.03978](http://arxiv.org/abs/2510.03978)|null|\n", "2510.03903": "|**2025-10-04**|**Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models**|Md. Atabuzzaman,...Chris Thomas|[2510.03903](http://arxiv.org/abs/2510.03903)|null|\n", "2510.03896": "|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Mingyu Liu,...Chunhua Shen|[2510.03896](http://arxiv.org/abs/2510.03896)|null|\n", "2510.03840": "|**2025-10-04**|**Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models**|Pranav Sharma,...Durga Toshniwal|[2510.03840](http://arxiv.org/abs/2510.03840)|null|\n", "2510.03721": "|**2025-10-04**|**Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models**|Leander Girrbach,...Zeynep Akata|[2510.03721](http://arxiv.org/abs/2510.03721)|null|\n", "2510.03666": "|**2025-10-04**|**MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations**|Jiang Wu,...Jingliang Duan|[2510.03666](http://arxiv.org/abs/2510.03666)|null|\n", "2510.06067": "|**2025-10-07**|**Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA**|Python Song,...Junfeng Yang|[2510.06067](http://arxiv.org/abs/2510.06067)|null|\n", "2510.06064": "|**2025-10-07**|**Medical Vision Language Models as Policies for Robotic Surgery**|Akshay Muppidi,...Martin Radfar|[2510.06064](http://arxiv.org/abs/2510.06064)|null|\n", "2510.05722": "|**2025-10-07**|**Data Factory with Minimal Human Effort Using VLMs**|Jiaojiao Ye,...Andrew Markham|[2510.05722](http://arxiv.org/abs/2510.05722)|null|\n", "2510.05544": "|**2025-10-07**|**Activation-Informed Pareto-Guided Low-Rank Compression for Efficient LLM/VLM**|Ryan Solgi,...Zheng Zhang|[2510.05544](http://arxiv.org/abs/2510.05544)|null|\n", "2510.07181": "|**2025-10-09**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Yi Han,...Shanghang Zhang|[2510.07181](http://arxiv.org/abs/2510.07181)|null|\n", "2510.07135": "|**2025-10-08**|**Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models**|Karim El Khoury,...Benoit Macq|[2510.07135](http://arxiv.org/abs/2510.07135)|null|\n", "2510.07098": "|**2025-10-08**|**TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription**|Guo Yutong,...Haoyu Wang|[2510.07098](http://arxiv.org/abs/2510.07098)|null|\n", "2510.07077": "|**2025-10-08**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Kento Kawaharazuka,...Yuke Zhu|[2510.07077](http://arxiv.org/abs/2510.07077)|**[link](https://vla-survey.github.io)**|\n", "2510.07035": "|**2025-10-08**|**Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration**|Tengwei Song,...Yuan Fang|[2510.07035](http://arxiv.org/abs/2510.07035)|null|\n", "2510.06790": "|**2025-10-08**|**Get RICH or Die Scaling: Profitably Trading Inference Compute for Robustness**|Tavish McDonald,...Brian Bartoldson|[2510.06790](http://arxiv.org/abs/2510.06790)|null|\n", "2510.06783": "|**2025-10-08**|**TTRV: Test-Time Reinforcement Learning for Vision Language Models**|Akshit Singh,...M. Jehanzeb Mirza|[2510.06783](http://arxiv.org/abs/2510.06783)|null|\n", "2510.06664": "|**2025-10-08**|**ToolMem: Enhancing Multimodal Agents with Learnable Tool Capability Memory**|Yunzhong Xiao,...Zora Zhiruo Wang|[2510.06664](http://arxiv.org/abs/2510.06664)|null|\n", "2510.06529": "|**2025-10-08**|**VUGEN: Visual Understanding priors for GENeration**|Xiangyi Chen,...Jakob Verbeek|[2510.06529](http://arxiv.org/abs/2510.06529)|null|\n", "2510.06292": "|**2025-10-07**|**ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations**|Yike Wu,...Yujun Cai|[2510.06292](http://arxiv.org/abs/2510.06292)|null|\n", "2510.06280": "|**2025-10-06**|**Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals**|Zohaib Hasan Siddiqui,...Beenish Moalla Chaudhry|[2510.06280](http://arxiv.org/abs/2510.06280)|null|\n", "2510.08567": "|**2025-10-09**|**MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning**|Tajamul Ashraf,...Salman Khan|[2510.08567](http://arxiv.org/abs/2510.08567)|null|\n", "2510.08531": "|**2025-10-09**|**SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models**|Hongxing Li,...Yueting Zhuang|[2510.08531](http://arxiv.org/abs/2510.08531)|**[link](https://zju-real.github.io/SpatialLadder/)**|\n", "2510.08510": "|**2025-10-09**|**To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models**|Jiayun Luo,...Leonid Sigal|[2510.08510](http://arxiv.org/abs/2510.08510)|**[link](https://davidhalladay.github.io/diysink_demo)**|\n", "2510.08508": "|**2025-10-09**|**MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration**|Lu Liu,...Guangtao Zhai|[2510.08508](http://arxiv.org/abs/2510.08508)|null|\n", "2510.08482": "|**2025-10-09**|**The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping**|Onur Kele\u015f,...Esam Ghaleb|[2510.08482](http://arxiv.org/abs/2510.08482)|null|\n", "2510.08470": "|**2025-10-09**|**Looking to Learn: Token-wise Dynamic Gating for Low-Resource Vision-Language Modelling**|Bianca-Mihaela Ganescu,...Paula Buttery|[2510.08470](http://arxiv.org/abs/2510.08470)|null|\n", "2510.08398": "|**2025-10-09**|**VideoVerse: How Far is Your T2V Generator from a World Model?**|Zeqing Wang,...Lei Zhang|[2510.08398](http://arxiv.org/abs/2510.08398)|null|\n", "2510.08352": "|**2025-10-09**|**Evaluating Small Vision-Language Models on Distance-Dependent Traffic Perception**|Nikos Theodoridis,...Ciaran Eising|[2510.08352](http://arxiv.org/abs/2510.08352)|null|\n", "2510.08238": "|**2025-10-09**|**Chain-of-Trigger: An Agentic Backdoor that Paradoxically Enhances Agentic Robustness**|Jiyang Qiu,...Hai Zhao|[2510.08238](http://arxiv.org/abs/2510.08238)|null|\n", "2510.08132": "|**2025-10-09**|**Approximate Domain Unlearning for Vision-Language Models**|Kodai Kawamura,...Go Irie|[2510.08132](http://arxiv.org/abs/2510.08132)|null|\n", "2510.08003": "|**2025-10-09**|**CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning**|Weihuang Lin,...Rongrong Ji|[2510.08003](http://arxiv.org/abs/2510.08003)|null|\n", "2510.07975": "|**2025-10-09**|**Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation**|Mingyang Sun,...Jianhua Sun|[2510.07975](http://arxiv.org/abs/2510.07975)|null|\n", "2510.07809": "|**2025-10-09**|**Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents**|Renhua Ding,...Jun Zhu|[2510.07809](http://arxiv.org/abs/2510.07809)|null|\n", "2510.07791": "|**2025-10-09**|**GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models**|Qinghongbing Xie,...Long Zeng|[2510.07791](http://arxiv.org/abs/2510.07791)|null|\n", "2510.07778": "|**2025-10-09**|**IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction**|Yandu Chen,...Liqiang Nie|[2510.07778](http://arxiv.org/abs/2510.07778)|null|\n", "2510.07709": "|**2025-10-09**|**Multimodal Safety Evaluation in Generative Agent Social Simulations**|Alhim Vera,...Bernard Ghanem|[2510.07709](http://arxiv.org/abs/2510.07709)|null|\n", "2510.07632": "|**2025-10-09**|**Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models**|Yinglun Zhu,...Fuzhi Tang|[2510.07632](http://arxiv.org/abs/2510.07632)|null|\n", "2510.07567": "|**2025-10-08**|**Cross-Modal Attention Guided Unlearning in Vision-Language Models**|Karuna Bhaila,...Xintao Wu|[2510.07567](http://arxiv.org/abs/2510.07567)|null|\n", "2510.07545": "|**2025-10-08**|**Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices**|Md Tahmid Rahman Laskar,...Jimmy Huang|[2510.07545](http://arxiv.org/abs/2510.07545)|null|\n", "2510.09608": "|**2025-10-10**|**StreamingVLM: Real-Time Understanding for Infinite Video Streams**|Ruyi Xu,...Song Han|[2510.09608](http://arxiv.org/abs/2510.09608)|null|\n", "2510.09607": "|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Shaoqi Dong,...Caifeng Shan|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|\n", "2510.09586": "|**2025-10-10**|**Vision Language Models: A Survey of 26K Papers**|Fengming Lin,...Fengming Lin|[2510.09586](http://arxiv.org/abs/2510.09586)|null|\n", "2510.09473": "|**2025-10-10**|**D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models**|Jisu Han,...Wonjun Hwang|[2510.09473](http://arxiv.org/abs/2510.09473)|null|\n", "2510.09358": "|**2025-10-10**|**Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models**|Qihang Ma,...Jiao Ran|[2510.09358](http://arxiv.org/abs/2510.09358)|**[link](https://github.com/bytedance/DynamicCoT)**|\n", "2510.09285": "|**2025-10-10**|**Spotlight on Token Perception for Multimodal Reinforcement Learning**|Siyuan Huang,...Yu Cheng|[2510.09285](http://arxiv.org/abs/2510.09285)|**[link](https://github.com/huaixuheqing/VPPO-RL)**|\n", "2510.09256": "|**2025-10-10**|**Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy**|Patrick Wienholt,...Daniel Truhn|[2510.09256](http://arxiv.org/abs/2510.09256)|**[link](https://github.com/TruhnLab/VisionSemanticEntropy)**|\n", "2510.09253": "|**2025-10-10**|**Zero-shot image privacy classification with Vision-Language Models**|Alina Elena Baia,...Andrea Cavallaro|[2510.09253](http://arxiv.org/abs/2510.09253)|null|\n", "2510.09228": "|**2025-10-10**|**Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation**|Vijay M. Galshetwar,...Subrahmanyam Murala|[2510.09228](http://arxiv.org/abs/2510.09228)|null|\n", "2510.09078": "|**2025-10-10**|**MCMC: Bridging Rendering, Optimization and Generative AI**|Gurprit Singh,...Wenzel Jakob|[2510.09078](http://arxiv.org/abs/2510.09078)|null|\n", "2510.09008": "|**2025-10-10**|**On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models**|Hoigi Seo,...Se Young Chun|[2510.09008](http://arxiv.org/abs/2510.09008)|null|\n", "2510.08964": "|**2025-10-10**|**Unleashing Perception-Time Scaling to Multimodal Reasoning Models**|Yifan Li,...Minghui Qiu|[2510.08964](http://arxiv.org/abs/2510.08964)|null|\n", "2510.08919": "|**2025-10-10**|**PHyCLIP: $\\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning**|Daiki Yoshikawa,...Takashi Matsubara|[2510.08919](http://arxiv.org/abs/2510.08919)|null|\n", "2510.08851": "|**2025-10-09**|**CDE: Concept-Driven Exploration for Reinforcement Learning**|Le Mao,...Joseph Campbell|[2510.08851](http://arxiv.org/abs/2510.08851)|null|\n", "2510.08849": "|**2025-10-09**|**FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation**|Hongrui Wu,...Zhihua Wei|[2510.08849](http://arxiv.org/abs/2510.08849)|null|\n", "2510.08818": "|**2025-10-09**|**D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition**|Yiyang Huang,...Yun Fu|[2510.08818](http://arxiv.org/abs/2510.08818)|null|\n", "2510.08789": "|**2025-10-09**|**Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization**|Shuo Xing,...Zhengzhong Tu|[2510.08789](http://arxiv.org/abs/2510.08789)|null|\n", "2510.11718": "|**2025-10-13**|**CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images**|Chengqi Duan,...Xihui Liu|[2510.11718](http://arxiv.org/abs/2510.11718)|null|\n", "2510.11689": "|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Maggie Wang,...Mac Schwager|[2510.11689](http://arxiv.org/abs/2510.11689)|null|\n", "2510.11631": "|**2025-10-13**|**EvoCAD: Evolutionary CAD Code Generation with Vision Language Models**|Tobias Preintner,...Niki van Stein|[2510.11631](http://arxiv.org/abs/2510.11631)|null|\n", "2510.11520": "|**2025-10-13**|**mmWalk: Towards Multi-modal Multi-view Walking Assistance**|Kedi Ying,...Rainer Stiefelhagen|[2510.11520](http://arxiv.org/abs/2510.11520)|**[link](https://github.com/KediYing/mmWalk)**|\n", "2510.11456": "|**2025-10-13**|**Coupled Degradation Modeling and Fusion: A VLM-Guided Degradation-Coupled Network for Degradation-Aware Infrared and Visible Image Fusion**|Tianpei Zhang,...Guangmang Cui|[2510.11456](http://arxiv.org/abs/2510.11456)|null|\n", "2510.11314": "|**2025-10-13**|**Template-Based Text-to-Image Alignment for Language Accessibility: A Study on Visualizing Text Simplifications**|Belkiss Souayed,...Yingqiang Gao|[2510.11314](http://arxiv.org/abs/2510.11314)|null|\n", "2510.11302": "|**2025-10-13**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani,...Samer Al-Hamadani|[2510.11302](http://arxiv.org/abs/2510.11302)|null|\n", "2510.11296": "|**2025-10-13**|**$\u0394\\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization**|Lin Zhu,...Nanyang Ye|[2510.11296](http://arxiv.org/abs/2510.11296)|null|\n", "2510.11295": "|**2025-10-13**|**Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering**|Jian Lan,...Thomas Seidl|[2510.11295](http://arxiv.org/abs/2510.11295)|null|\n", "2510.11196": "|**2025-10-13**|**Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations**|Johannes Moll,...Keno K. Bressem|[2510.11196](http://arxiv.org/abs/2510.11196)|null|\n", "2510.11178": "|**2025-10-13**|**BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models**|Bryan Chen Zhengyu Tan,...Roy Ka-Wei Lee|[2510.11178](http://arxiv.org/abs/2510.11178)|null|\n", "2510.11027": "|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Ganlin Yang,...Zhi Hou|[2510.11027](http://arxiv.org/abs/2510.11027)|null|\n", "2510.11020": "|**2025-10-13**|**GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation**|Shasha Guo,...Jing Zhang|[2510.11020](http://arxiv.org/abs/2510.11020)|null|\n", "2510.11012": "|**2025-10-13**|**COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models**|Sanchit Sinha,...Aidong Zhang|[2510.11012](http://arxiv.org/abs/2510.11012)|null|\n", "2510.10982": "|**2025-10-13**|**Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization**|Zihan Wang,...Guangdong Bai|[2510.10982](http://arxiv.org/abs/2510.10982)|null|\n", "2510.10973": "|**2025-10-13**|**Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning**|Sanchit Sinha,...Aidong Zhang|[2510.10973](http://arxiv.org/abs/2510.10973)|null|\n", "2510.10969": "|**2025-10-13**|**IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation**|Zeteng Lin,...Jing Tang|[2510.10969](http://arxiv.org/abs/2510.10969)|null|\n", "2510.10962": "|**2025-10-13**|**MC#: Mixture Compressor for Mixture-of-Experts Large Models**|Wei Huang,...Xiaojuan Qi|[2510.10962](http://arxiv.org/abs/2510.10962)|null|\n", "2510.10921": "|**2025-10-13**|**FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model**|Chunyu Xie,...Yuhui Yin|[2510.10921](http://arxiv.org/abs/2510.10921)|null|\n", "2510.10889": "|**2025-10-13**|**Topological Alignment of Shared Vision-Language Embedding Space**|Junwon You,...Jae-Hun Jung|[2510.10889](http://arxiv.org/abs/2510.10889)|null|\n", "2510.12789": "|**2025-10-14**|**UniFusion: Vision-Language Model as Unified Encoder in Image Generation**|Kevin Li,...Ajinkya Kale|[2510.12789](http://arxiv.org/abs/2510.12789)|**[link](https://thekevinli.github.io/unifusion/)**|\n", "2510.12709": "|**2025-10-15**|**SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model**|Lin Lin,...Chao Feng|[2510.12709](http://arxiv.org/abs/2510.12709)|null|\n", "2510.12693": "|**2025-10-14**|**ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning**|Hanyang Chen,...Tong Zhang|[2510.12693](http://arxiv.org/abs/2510.12693)|null|\n", "2510.12548": "|**2025-10-14**|**VISaGE: Understanding Visual Generics and Exceptions**|Stella Frank,...Emily Allaway|[2510.12548](http://arxiv.org/abs/2510.12548)|null|\n", "2510.12444": "|**2025-10-14**|**A Review of Longitudinal Radiology Report Generation: Dataset Composition, Methods, and Performance Evaluation**|Shaoyang Zhou,...Luping Zhou|[2510.12444](http://arxiv.org/abs/2510.12444)|null|\n", "2510.12400": "|**2025-10-14**|**Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda**|Andr\u00e9 Torneiro,...Nuno F. Rodrigues|[2510.12400](http://arxiv.org/abs/2510.12400)|null|\n", "2510.12287": "|**2025-10-14**|**Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector**|Sifan Li,...Yiwei Wang|[2510.12287](http://arxiv.org/abs/2510.12287)|null|\n", "2510.12276": "|**2025-10-14**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Fuhao Li,...Haoang Li|[2510.12276](http://arxiv.org/abs/2510.12276)|null|\n", "2510.12225": "|**2025-10-14**|**HoneyBee: Data Recipes for Vision-Language Reasoners**|Hritik Bansal,...Ramakanth Pasunuru|[2510.12225](http://arxiv.org/abs/2510.12225)|null|\n", "2510.12190": "|**2025-10-14**|**Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos**|Shingo Yokoi,...Yu Yamaguchi|[2510.12190](http://arxiv.org/abs/2510.12190)|null|\n", "2510.12119": "|**2025-10-14**|**ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation**|Ziyuan Luo,...Renjie Wan|[2510.12119](http://arxiv.org/abs/2510.12119)|null|\n", "2510.12014": "|**2025-10-13**|**Embedding the Teacher: Distilling vLLM Preferences for Scalable Image Retrieval**|Eric He,...Vyas Raina|[2510.12014](http://arxiv.org/abs/2510.12014)|null|\n", "2510.11978": "|**2025-10-13**|**Learning Dynamics of VLM Finetuning**|Jusheng Zhang,...Keze Wang|[2510.11978](http://arxiv.org/abs/2510.11978)|null|\n", "2510.11852": "|**2025-10-13**|**Evaluating Open-Source Vision-Language Models for Multimodal Sarcasm Detection**|Saroj Basnet,...Marcos Zampieri|[2510.11852](http://arxiv.org/abs/2510.11852)|**[link](https://icdmw25mmai.github.io/)**|\n", "2510.11835": "|**2025-10-13**|**Data or Language Supervision: What Makes CLIP Better than DINO?**|Yiming Liu,...Serena Yeung-Levy|[2510.11835](http://arxiv.org/abs/2510.11835)|null|\n", "2510.13808": "|**2025-10-15**|**VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models**|Dominick Reilly,...Srijan Das|[2510.13808](http://arxiv.org/abs/2510.13808)|null|\n", "2510.13804": "|**2025-10-15**|**Generative Universal Verifier as Multimodal Meta-Reasoner**|Xinchen Zhang,...Yujiu Yang|[2510.13804](http://arxiv.org/abs/2510.13804)|null|\n", "2510.13394": "|**2025-10-15**|**Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models**|Xinmiao Huang,...Xiaowei Huang|[2510.13394](http://arxiv.org/abs/2510.13394)|null|\n", "2510.13375": "|**2025-10-15**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Tianyuan Yuan,...Hang Zhao|[2510.13375](http://arxiv.org/abs/2510.13375)|null|\n", "2510.13364": "|**2025-10-15**|**Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity**|MingZe Tang,...Jubal Chandy Jacob|[2510.13364](http://arxiv.org/abs/2510.13364)|null|\n", "2510.13359": "|**2025-10-15**|**Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models**|Yuki Yada,...Andre Rusli|[2510.13359](http://arxiv.org/abs/2510.13359)|null|\n", "2510.13315": "|**2025-10-15**|**Self-Augmented Visual Contrastive Decoding**|Eun Woo Im,...Vivek Gupta|[2510.13315](http://arxiv.org/abs/2510.13315)|null|\n", "2510.13276": "|**2025-10-15**|**MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models**|Keyan Zhou,...Min Zhang|[2510.13276](http://arxiv.org/abs/2510.13276)|null|\n", "2510.13251": "|**2025-10-15**|**Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs**|Minji Kim,...Bohyung Han|[2510.13251](http://arxiv.org/abs/2510.13251)|null|\n", "2510.13232": "|**2025-10-15**|**What \"Not\" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging**|Inha Kang,...Hyunjung Shim|[2510.13232](http://arxiv.org/abs/2510.13232)|null|\n", "2510.13190": "|**2025-10-15**|**SHIELD: Classifier-Guided Prompting for Robust and Safer LVLMs**|Juan Ren,...Usman Naseem|[2510.13190](http://arxiv.org/abs/2510.13190)|null|\n", "2510.13108": "|**2025-10-15**|**DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models**|Jingyu Song,...Jose M. Alvarez|[2510.13108](http://arxiv.org/abs/2510.13108)|null|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Ankit Goyal,...Fabio Ramos|[2510.13054](http://arxiv.org/abs/2510.13054)|null|\n", "2510.13016": "|**2025-10-14**|**SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding**|Tanveer Hannan,...Thomas Seidl|[2510.13016](http://arxiv.org/abs/2510.13016)|null|\n", "2510.12992": "|**2025-10-14**|**UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles**|Neel P. Bhatt,...Ufuk Topcu|[2510.12992](http://arxiv.org/abs/2510.12992)|null|\n", "2510.12974": "|**2025-10-14**|**Scope: Selective Cross-modal Orchestration of Visual Perception Experts**|Tianyu Zhang,...Perouz Taslakian|[2510.12974](http://arxiv.org/abs/2510.12974)|null|\n", "2510.12953": "|**2025-10-14**|**Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation**|Xiao He,...Bo Du|[2510.12953](http://arxiv.org/abs/2510.12953)|null|\n", "2510.12931": "|**2025-10-14**|**Unifying Vision-Language Latents for Zero-label Image Caption Enhancement**|Sanghyun Byun,...Woo Seong Chung|[2510.12931](http://arxiv.org/abs/2510.12931)|null|\n", "2510.14979": "|**2025-10-16**|**From Pixels to Words -- Towards Native Vision-Language Primitives at Scale**|Haiwen Diao,...Ziwei Liu|[2510.14979](http://arxiv.org/abs/2510.14979)|null|\n", "2510.14978": "|**2025-10-16**|**Learning an Image Editing Model without Image Editing Pairs**|Nupur Kumari,...Xun Huang|[2510.14978](http://arxiv.org/abs/2510.14978)|**[link](https://nupurkmr9.github.io/npedit/)**|\n", "2510.14968": "|**2025-10-16**|**RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks**|Mingxuan Yan,...Jiachen Li|[2510.14968](http://arxiv.org/abs/2510.14968)|null|\n", "2510.14828": "|**2025-10-16**|**RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning**|Jinrui Liu,...Haoran Li|[2510.14828](http://arxiv.org/abs/2510.14828)|null|\n", "2510.14792": "|**2025-10-16**|**CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection**|Hojun Choi,...Hyunjung Shim|[2510.14792](http://arxiv.org/abs/2510.14792)|null|\n", "2510.14737": "|**2025-10-16**|**Free-Grained Hierarchical Recognition**|Seulki Park,...Stella X. Yu|[2510.14737](http://arxiv.org/abs/2510.14737)|null|\n", "2510.14624": "|**2025-10-16**|**Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference**|Natan Bagrov,...Andrew Tao|[2510.14624](http://arxiv.org/abs/2510.14624)|null|\n", "2510.14583": "|**2025-10-16**|**Talking Points: Describing and Localizing Pixels**|Matan Rusanovsky,...Shai Avidan|[2510.14583](http://arxiv.org/abs/2510.14583)|null|\n", "2510.14543": "|**2025-10-16**|**Exploring Cross-Modal Flows for Few-Shot Learning**|Ziqi Jiang,...Long Chen|[2510.14543](http://arxiv.org/abs/2510.14543)|null|\n", "2510.14528": "|**2025-10-17**|**PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model**|Cheng Cui,...Yanjun Ma|[2510.14528](http://arxiv.org/abs/2510.14528)|**[link](https://github.com/PaddlePaddle/PaddleOCR)**|\n", "2510.14526": "|**2025-10-16**|**Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models**|Yunze Tong,...Ziyu Zhao|[2510.14526](http://arxiv.org/abs/2510.14526)|null|\n", "2510.14388": "|**2025-10-16**|**Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control**|Zhe Wu,...Yuanchun Shi|[2510.14388](http://arxiv.org/abs/2510.14388)|null|\n", "2510.14304": "|**2025-10-16**|**Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding**|Kyungryul Back,...Jinkyu Kim|[2510.14304](http://arxiv.org/abs/2510.14304)|**[link](https://github.com/KR-0822/TCD)**|\n", "2510.13993": "|**2025-10-15**|**Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models**|Jia Yun Chua,...Miguel Arana-Catania|[2510.13993](http://arxiv.org/abs/2510.13993)|null|\n", "2510.15866": "|**2025-10-17**|**BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models**|Kaushitha Silva,...Damayanthi Herath|[2510.15866](http://arxiv.org/abs/2510.15866)|null|\n", "2510.15841": "|**2025-10-17**|**Neuro-Symbolic Spatial Reasoning in Segmentation**|Jiayi Lin,...Shaogang Gong|[2510.15841](http://arxiv.org/abs/2510.15841)|null|\n", "2510.15430": "|**2025-10-17**|**Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models**|Shuang Liang,...Xiting Wang|[2510.15430](http://arxiv.org/abs/2510.15430)|null|\n", "2510.15418": "|**2025-10-17**|**Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs**|Lee Qi Zun,...Goh Man Fye|[2510.15418](http://arxiv.org/abs/2510.15418)|null|\n", "2510.15349": "|**2025-10-17**|**Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing**|Baode Wang,...Yuan Qi|[2510.15349](http://arxiv.org/abs/2510.15349)|null|\n", "2510.17800": "|**2025-10-21**|**Glyph: Scaling Context Windows via Visual-Text Compression**|Jiale Cheng,...Minlie Huang|[2510.17800](http://arxiv.org/abs/2510.17800)|null|\n", "2510.17777": "|**2025-10-20**|**SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference**|Samir Khaki,...Zhijian Liu|[2510.17777](http://arxiv.org/abs/2510.17777)|null|\n", "2510.17771": "|**2025-10-20**|**Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs**|Zhining Liu,...Hanghang Tong|[2510.17771](http://arxiv.org/abs/2510.17771)|null|\n", "2510.17759": "|**2025-10-20**|**VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models**|Qilin Liao,...Ruqi Zhang|[2510.17759](http://arxiv.org/abs/2510.17759)|null|\n", "2510.17651": "|**2025-10-20**|**Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs**|S\u00e9bastien Thuau,...Rachid Chelouah|[2510.17651](http://arxiv.org/abs/2510.17651)|null|\n", "2510.17633": "|**2025-10-20**|**SARSteer: Safeguarding Large Audio Language Models via Safe-Ablated Refusal Steering**|Weilin Lin,...Li Liu|[2510.17633](http://arxiv.org/abs/2510.17633)|null|\n", "2510.17590": "|**2025-10-20**|**MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning**|Mir Nafis Sharear Shopnil,...Adiba Mahbub Proma|[2510.17590](http://arxiv.org/abs/2510.17590)|null|\n", "2510.17354": "|**2025-10-20**|**Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation**|Chenghao Zhang,...Zhicheng Dou|[2510.17354](http://arxiv.org/abs/2510.17354)|null|\n", "2510.17313": "|**2025-10-20**|**Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations**|Tal Barami,...Omri Azencot|[2510.17313](http://arxiv.org/abs/2510.17313)|null|\n", "2510.17269": "|**2025-10-20**|**FineVision: Open Data Is All You Need**|Luis Wiedmann,...Andr\u00e9s Marafioti|[2510.17269](http://arxiv.org/abs/2510.17269)|null|\n", "2510.17197": "|**2025-10-20**|**ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models**|Pu Zhang,...Guoming Tang|[2510.17197](http://arxiv.org/abs/2510.17197)|null|\n", "2510.17191": "|**2025-10-20**|**SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving**|Peiru Zheng,...Shaohua Wu|[2510.17191](http://arxiv.org/abs/2510.17191)|null|\n", "2510.17150": "|**2025-10-20**|**OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation**|Heng Zhang,...Arash Ajoudani|[2510.17150](http://arxiv.org/abs/2510.17150)|**[link](https://sites.google.com/view/omni-vic})**|\n", "2510.17111": "|**2025-10-20**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Weifan Guan,...Jian Cheng|[2510.17111](http://arxiv.org/abs/2510.17111)|null|\n", "2510.17034": "|**2025-10-19**|**Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding**|Yutong Zhong,...Yutong Zhong|[2510.17034](http://arxiv.org/abs/2510.17034)|null|\n", "2510.16924": "|**2025-10-19**|**Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?**|Zhihui Yang,...Renfen Hu|[2510.16924](http://arxiv.org/abs/2510.16924)|null|\n", "2510.16907": "|**2025-10-19**|**VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents**|Kangrui Wang,...Manling Li|[2510.16907](http://arxiv.org/abs/2510.16907)|null|\n", "2510.16870": "|**2025-10-19**|**Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding**|Yudan Ren,...Xiaowei He|[2510.16870](http://arxiv.org/abs/2510.16870)|null|\n", "2510.16772": "|**2025-10-19**|**Region in Context: Text-condition Image editing with Human-like semantic reasoning**|Thuy Phuong Vu,...Phan Xuan Tan|[2510.16772](http://arxiv.org/abs/2510.16772)|null|\n", "2510.16769": "|**2025-10-19**|**See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models**|Shuo Han,...Xike Xie|[2510.16769](http://arxiv.org/abs/2510.16769)|null|\n", "2510.18873": "|**2025-10-21**|**DSI-Bench: A Benchmark for Dynamic Spatial Intelligence**|Ziang Zhang,...Zhou Zhao|[2510.18873](http://arxiv.org/abs/2510.18873)|null|\n", "2510.18837": "|**2025-10-21**|**FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning**|Yubin Zheng,...Jagath C. Rajapakse|[2510.18837](http://arxiv.org/abs/2510.18837)|null|\n", "2510.18751": "|**2025-10-21**|**Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation**|Patterson Hsieh,...Elvis Hsieh|[2510.18751](http://arxiv.org/abs/2510.18751)|null|\n", "2510.18703": "|**2025-10-21**|**Exploring a Unified Vision-Centric Contrastive Alternatives on Multi-Modal Web Documents**|Yiqi Lin,...Mike Zheng Shou|[2510.18703](http://arxiv.org/abs/2510.18703)|**[link](https://linyq17.github.io/VC2L/)**|\n", "2510.18632": "|**2025-10-21**|**Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views**|Zhangquan Chen,...Ruqi Huang|[2510.18632](http://arxiv.org/abs/2510.18632)|null|\n", "2510.18596": "|**2025-10-21**|**CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent**|Haojia Lin,...Xing Sun|[2510.18596](http://arxiv.org/abs/2510.18596)|null|\n", "2510.18583": "|**2025-10-21**|**CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder**|Yongmin Lee,...Hye Won Chung|[2510.18583](http://arxiv.org/abs/2510.18583)|null|\n", "2510.18502": "|**2025-10-21**|**Zero-Shot Vehicle Model Recognition via Text-Based Retrieval-Augmented Generation**|Wei-Chia Chang,...Yan-Ann Chen|[2510.18502](http://arxiv.org/abs/2510.18502)|null|\n", "2510.18483": "|**2025-10-21**|**StarBench: A Turn-Based RPG Benchmark for Agentic Multimodal Decision-Making and Information Seeking**|Haoran Zhang,...Donglin Yu|[2510.18483](http://arxiv.org/abs/2510.18483)|null|\n", "2510.18439": "|**2025-10-21**|**Grounding or Guessing? Visual Signals for Detecting Hallucinations in Sign Language Translation**|Yasser Hamidullah,...Cristina Espa\u00f1a-Bonet|[2510.18439](http://arxiv.org/abs/2510.18439)|null|\n", "2510.18433": "|**2025-10-21**|**ImageGem: In-the-wild Generative Image Interaction Dataset for Generative Model Personalization**|Yuanhe Guo,...Hongyi Wen|[2510.18433](http://arxiv.org/abs/2510.18433)|null|\n", "2510.18321": "|**2025-10-21**|**Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding**|Jinlin Li,...Xian Wu|[2510.18321](http://arxiv.org/abs/2510.18321)|null|\n", "2510.18269": "|**2025-10-21**|**StreamingTOM: Streaming Token Compression for Efficient Video Understanding**|Xueyi Chen,...Huan Wang|[2510.18269](http://arxiv.org/abs/2510.18269)|null|\n", "2510.18262": "|**2025-10-21**|**UWBench: A Comprehensive Vision-Language Benchmark for Underwater Understanding**|Da Zhang,...Xuelong Li|[2510.18262](http://arxiv.org/abs/2510.18262)|null|\n", "2510.18188": "|**2025-10-21**|**RadDiagSeg-M: A Vision Language Model for Joint Diagnosis and Multi-Target Segmentation in Radiology**|Chengrun Li,...Bjoern Menze|[2510.18188](http://arxiv.org/abs/2510.18188)|null|\n", "2510.18117": "|**2025-10-20**|**Online In-Context Distillation for Low-Resource Vision Language Models**|Zhiqi Kang,...Karteek Alahari|[2510.18117](http://arxiv.org/abs/2510.18117)|null|\n", "2510.18054": "|**2025-10-20**|**HouseTour: A Virtual Real Estate A(I)gent**|Ata \u00c7elen,...Iro Armeni|[2510.18054](http://arxiv.org/abs/2510.18054)|null|\n", "2510.18034": "|**2025-10-20**|**SAVANT: Semantic Analysis with Vision-Augmented Anomaly deTection**|Roberto Brusnicki,...Johannes Betz|[2510.18034](http://arxiv.org/abs/2510.18034)|null|\n", "2510.19818": "|**2025-10-22**|**Semantic World Models**|Jacob Berg,...Abhishek Gupta|[2510.19818](http://arxiv.org/abs/2510.19818)|null|\n", "2510.19817": "|**2025-10-22**|**olmOCR 2: Unit Test Rewards for Document OCR**|Jake Poznanski,...Kyle Lo|[2510.19817](http://arxiv.org/abs/2510.19817)|**[link](https://olmocr.allen.ai/)**|\n", "2510.19802": "|**2025-10-22**|**Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models**|Xiaozhen Qiao,...Xuelong Li|[2510.19802](http://arxiv.org/abs/2510.19802)|null|\n", "2510.19626": "|**2025-10-22**|**MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom**|Yifan Li,...Shaohua Kevin Zhou|[2510.19626](http://arxiv.org/abs/2510.19626)|**[link](https://github.com/Leevan001/MedReason-R1)**|\n", "2510.19599": "|**2025-10-22**|**XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography**|Haozhe Luo,...Mauricio Reyes|[2510.19599](http://arxiv.org/abs/2510.19599)|null|\n", "2510.19574": "|**2025-10-22**|**Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection**|Ariana Yi,...Qiben Yan|[2510.19574](http://arxiv.org/abs/2510.19574)|null|\n", "2510.19559": "|**2025-10-22**|**A Matter of Time: Revealing the Structure of Time in Vision-Language Models**|Nidham Tekaya,...Matthias Zeppelzauer|[2510.19559](http://arxiv.org/abs/2510.19559)|null|\n", "2510.19555": "|**2025-10-22**|**[De|Re]constructing VLMs' Reasoning in Counting**|Simone Alghisi,...Giuseppe Riccardi|[2510.19555](http://arxiv.org/abs/2510.19555)|null|\n", "2510.19496": "|**2025-10-22**|**CARES: Context-Aware Resolution Selector for VLMs**|Moshe Kimhi,...Eli Schwartz|[2510.19496](http://arxiv.org/abs/2510.19496)|null|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Zhiyuan Feng,...Baining Guo|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|\n", "2510.19333": "|**2025-10-22**|**A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP**|Ying Dai,...Wei Yu Chen|[2510.19333](http://arxiv.org/abs/2510.19333)|null|\n", "2510.19307": "|**2025-10-22**|**Unified Reinforcement and Imitation Learning for Vision-Language Models**|Byung-Kwan Lee,...Yueh-Hua Wu|[2510.19307](http://arxiv.org/abs/2510.19307)|**[link](https://byungkwanlee.github.io/RIL-page)**|\n", "2510.19268": "|**2025-10-22**|**Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models**|Mingen Li,...Changhyun Choi|[2510.19268](http://arxiv.org/abs/2510.19268)|null|\n", "2510.19160": "|**2025-10-22**|**Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression**|Paimon Goulart,...Evangelos E. Papalexakis|[2510.19160](http://arxiv.org/abs/2510.19160)|null|\n", "2510.19060": "|**2025-10-21**|**PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions**|Amith Ananthram,...Kathleen McKeown|[2510.19060](http://arxiv.org/abs/2510.19060)|**[link](https://github.com/amith-ananthram/posh)**|\n", "2510.19001": "|**2025-10-21**|**Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts**|Seungjun Yu,...Hyunjung Shim|[2510.19001](http://arxiv.org/abs/2510.19001)|null|\n", "2510.20812": "|**2025-10-23**|**Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation**|Yuhan Liu,...Shengjie Wang|[2510.20812](http://arxiv.org/abs/2510.20812)|null|\n", "2510.20707": "|**2025-10-23**|**Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models**|Xuyang Liu,...Linfeng Zhang|[2510.20707](http://arxiv.org/abs/2510.20707)|**[link](https://github.com/xuyang-liu16/MixKV)**|\n", "2510.20696": "|**2025-10-23**|**Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward**|Jing Bi,...Chenliang Xu|[2510.20696](http://arxiv.org/abs/2510.20696)|null|\n", "2510.20639": "|**2025-10-23**|**Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging**|Ibrahim Ethem Hamamci,...Bjoern Menze|[2510.20639](http://arxiv.org/abs/2510.20639)|null|\n", "2510.20477": "|**2025-10-23**|**Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models**|Rui Zhu,...Lan-Zhe Guo|[2510.20477](http://arxiv.org/abs/2510.20477)|null|\n", "2510.20333": "|**2025-10-23**|**GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?**|Chiyu Chen,...Yingchun Wang|[2510.20333](http://arxiv.org/abs/2510.20333)|null|\n", "2510.20287": "|**2025-10-23**|**Breakdance Video classification in the age of Generative AI**|Sauptik Dhar,...Michelle Munson|[2510.20287](http://arxiv.org/abs/2510.20287)|null|\n", "2510.20244": "|**2025-10-23**|**Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding**|Minseok Kang,...Sangyoun Lee|[2510.20244](http://arxiv.org/abs/2510.20244)|null|\n", "2510.20229": "|**2025-10-23**|**Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context**|Ge Zheng,...Sibei Yang|[2510.20229](http://arxiv.org/abs/2510.20229)|null|\n", "2510.19949": "|**2025-10-24**|**Surfer 2: The Next Generation of Cross-Platform Computer Use Agents**|Mathieu Andreux,...Jevgenij Zubovskij|[2510.19949](http://arxiv.org/abs/2510.19949)|null|\n", "2510.21679": "|**2025-10-24**|**A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection**|Gaku Morio,...Peter Henderson|[2510.21679](http://arxiv.org/abs/2510.21679)|null|\n", "2510.21606": "|**2025-10-24**|**Modest-Align: Data-Efficient Alignment for Vision-Language Models**|Jiaxiang Liu,...Zuozhu Liu|[2510.21606](http://arxiv.org/abs/2510.21606)|null|\n", "2510.21518": "|**2025-10-24**|**Head Pursuit: Probing Attention Specialization in Multimodal Transformers**|Lorenzo Basile,...Alberto Cazzaniga|[2510.21518](http://arxiv.org/abs/2510.21518)|null|\n", "2510.21449": "|**2025-10-24**|**MoniTor: Exploiting Large Language Models with Instruction for Online Video Anomaly Detection**|Shengtian Yang,...Jie Qin|[2510.21449](http://arxiv.org/abs/2510.21449)|null|\n", "2510.21424": "|**2025-10-24**|**Vision Language Models for Dynamic Human Activity Recognition in Healthcare Settings**|Abderrazek Abid,...Fakhri Karray|[2510.21424](http://arxiv.org/abs/2510.21424)|null|\n", "2510.21412": "|**2025-10-24**|**Bridging the gap to real-world language-grounded visual concept learning**|Whie Jung,...Seunghoon Hong|[2510.21412](http://arxiv.org/abs/2510.21412)|null|\n", "2510.21323": "|**2025-10-24**|**VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set**|Shufan Shen,...Shuhui Wang|[2510.21323](http://arxiv.org/abs/2510.21323)|null|\n", "2510.21175": "|**2025-10-24**|**Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models**|Yujin Jo,...Taesup Kim|[2510.21175](http://arxiv.org/abs/2510.21175)|null|\n", "2510.21121": "|**2025-10-24**|**Generalizable Hierarchical Skill Learning via Object-Centric Representation**|Haibo Zhao,...Robert Platt|[2510.21121](http://arxiv.org/abs/2510.21121)|null|\n", "2510.21120": "|**2025-10-24**|**SafetyPairs: Isolating Safety Critical Image Features with Counterfactual Image Generation**|Alec Helbling,...Joseph Yitan Cheng|[2510.21120](http://arxiv.org/abs/2510.21120)|null|\n", "2510.21093": "|**2025-10-24**|**MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning**|Siyong Chen,...Dong In Kim|[2510.21093](http://arxiv.org/abs/2510.21093)|null|\n", "2510.21083": "|**2025-10-24**|**Knowledge-Driven Vision-Language Model for Plexus Detection in Hirschsprung's Disease**|Youssef Megahed,...Adrian D. C. Chan|[2510.21083](http://arxiv.org/abs/2510.21083)|null|\n", "2510.21069": "|**2025-10-24**|**ZING-3D: Zero-shot Incremental 3D Scene Graphs via Vision-Language Models**|Pranav Saxena,...Jimmy Chiun|[2510.21069](http://arxiv.org/abs/2510.21069)|null|\n", "2510.20967": "|**2025-10-23**|**3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models**|Sraavya Sambara,...Pranav Rajpurkar|[2510.20967](http://arxiv.org/abs/2510.20967)|null|\n", "2510.23571": "|**2025-10-27**|**RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation**|Yash Jangir,...Katerina Fragkiadaki|[2510.23571](http://arxiv.org/abs/2510.23571)|**[link](https://robotarenainf.github.io)**|\n", "2510.23497": "|**2025-10-28**|**VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation**|Walid Bousselham,...Cordelia Schmid|[2510.23497](http://arxiv.org/abs/2510.23497)|null|\n", "2510.23482": "|**2025-10-27**|**On the Faithfulness of Visual Thinking: Measurement and Enhancement**|Zujing Liu,...Guisong Xia|[2510.23482](http://arxiv.org/abs/2510.23482)|null|\n", "2510.23253": "|**2025-10-27**|**A Video Is Not Worth a Thousand Words**|Sam Pollard,...Michael Wray|[2510.23253](http://arxiv.org/abs/2510.23253)|null|\n", "2510.23217": "|**2025-10-27**|**Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports**|Alois Thomas,...Curtis P. Langlotz|[2510.23217](http://arxiv.org/abs/2510.23217)|null|\n", "2510.23203": "|**2025-10-27**|**DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification**|Lukas Bierling,...Angelo Broere|[2510.23203](http://arxiv.org/abs/2510.23203)|null|\n", "2510.23190": "|**2025-10-27**|**Evaluation of Vision-LLMs in Surveillance Video**|Pascal Benschop,...Jelte P. Mense|[2510.23190](http://arxiv.org/abs/2510.23190)|null|\n", "2510.23184": "|**2025-10-27**|**Finding 3D Scene Analogies with Multimodal Foundation Models**|Junho Kim,...Young Min Kim|[2510.23184](http://arxiv.org/abs/2510.23184)|null|\n", "2510.23095": "|**2025-10-27**|**Revisiting Multimodal Positional Encoding in Vision-Language Models**|Jie Huang,...Shuai Bai|[2510.23095](http://arxiv.org/abs/2510.23095)|null|\n", "2510.23066": "|**2025-10-27**|**Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models**|Yichao Jin,...Donald MacDonald|[2510.23066](http://arxiv.org/abs/2510.23066)|null|\n", "2510.22975": "|**2025-10-27**|**VoMP: Predicting Volumetric Mechanical Property Fields**|Rishit Dagli,...Maria Shugrina|[2510.22975](http://arxiv.org/abs/2510.22975)|**[link](https://research.nvidia.com/labs/sil/projects/vomp)**|\n", "2510.22917": "|**2025-10-28**|**HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment**|Zecheng Yin,...Zhen Li|[2510.22917](http://arxiv.org/abs/2510.22917)|null|\n", "2510.22868": "|**2025-10-26**|**Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models**|Yang Zhang,...Jiong Tang|[2510.22868](http://arxiv.org/abs/2510.22868)|null|\n", "2510.22838": "|**2025-10-26**|**Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models**|Aya Nakayama,...Kaito Tanaka|[2510.22838](http://arxiv.org/abs/2510.22838)|null|\n", "2510.22798": "|**2025-10-26**|**VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions**|Thu Phuong Nguyen,...Taehwan Kim|[2510.22798](http://arxiv.org/abs/2510.22798)|**[link](https://vehme.github.io/)**|\n", "2510.22785": "|**2025-10-26**|**Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models**|Jiaxiang Liu,...Mingkun Xu|[2510.22785](http://arxiv.org/abs/2510.22785)|null|\n", "2510.22768": "|**2025-10-26**|**MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion**|Haoyi Qiu,...Chien-Sheng Wu|[2510.22768](http://arxiv.org/abs/2510.22768)|null|\n", "2510.22765": "|**2025-10-26**|**Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval**|Binxiao Xu,...Wentao Zhang|[2510.22765](http://arxiv.org/abs/2510.22765)|null|\n", "2510.22728": "|**2025-10-26**|**S-Chain: Structured Visual Chain-of-Thought For Medicine**|Khai Le-Duc,...Anh Totti Nguyen|[2510.22728](http://arxiv.org/abs/2510.22728)|null|\n", "2510.22702": "|**2025-10-26**|**Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring**|Mithul Chander,...Prathamesh Mayekar|[2510.22702](http://arxiv.org/abs/2510.22702)|null|\n", "2510.24650": "|**2025-10-28**|**Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning**|Nitin Rai,...Arnold W. Schumann|[2510.24650](http://arxiv.org/abs/2510.24650)|null|\n", "2510.24411": "|**2025-10-28**|**OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows**|Qiushi Sun,...Lingpeng Kong|[2510.24411](http://arxiv.org/abs/2510.24411)|null|\n", "2510.24331": "|**2025-10-28**|**What do vision-language models see in the context? Investigating multimodal in-context learning**|Gabriel O. dos Santos,...Sandra Avila|[2510.24331](http://arxiv.org/abs/2510.24331)|null|\n", "2510.24321": "|**2025-10-28**|**Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning**|Ivica Dimitrovski,...Ivan Kitanovski|[2510.24321](http://arxiv.org/abs/2510.24321)|null|\n", "2510.24285": "|**2025-10-28**|**ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model**|Juntian Zhang,...Rui Yan|[2510.24285](http://arxiv.org/abs/2510.24285)|null|\n", "2510.24242": "|**2025-10-28**|**Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models**|Zihan Li,...Yue Gao|[2510.24242](http://arxiv.org/abs/2510.24242)|null|\n", "2510.24180": "|**2025-10-28**|**V-SAT: Video Subtitle Annotation Tool**|Arpita Kundu,...Vishwanathan Raman|[2510.24180](http://arxiv.org/abs/2510.24180)|null|\n", "2510.24152": "|**2025-10-28**|**Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning**|Aodi Wu,...Xubo Luo|[2510.24152](http://arxiv.org/abs/2510.24152)|null|\n", "2510.24133": "|**2025-10-28**|**Compositional Image Synthesis with Inference-Time Scaling**|Minsuk Ji,...Namhyuk Ahn|[2510.24133](http://arxiv.org/abs/2510.24133)|**[link](https://github.com/gcl-inha/ReFocus)**|\n", "2510.24115": "|**2025-10-28**|**HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology**|Sandeep Vissapragada,...Vandita Singh|[2510.24115](http://arxiv.org/abs/2510.24115)|null|\n", "2510.24109": "|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Wenbin Ding,...Philip Dames|[2510.24109](http://arxiv.org/abs/2510.24109)|null|\n", "2510.24038": "|**2025-10-28**|**Enhancing CLIP Robustness via Cross-Modality Alignment**|Xingyu Zhu,...Hanwang Zhang|[2510.24038](http://arxiv.org/abs/2510.24038)|null|\n", "2510.24010": "|**2025-10-28**|**Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks**|Mirali Purohit,...Hannah Kerner|[2510.24010](http://arxiv.org/abs/2510.24010)|null|\n", "2510.23968": "|**2025-10-28**|**Reasoning Visual Language Model for Chest X-Ray Analysis**|Andriy Myronenko,...Daguang Xu|[2510.23968](http://arxiv.org/abs/2510.23968)|null|\n", "2510.23925": "|**2025-10-27**|**Latent Chain-of-Thought for Visual Reasoning**|Guohao Sun,...Zhiqiang Tao|[2510.23925](http://arxiv.org/abs/2510.23925)|null|\n", "2510.23775": "|**2025-10-27**|**Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices**|Aryan Mathur,...Madesh Kuppusamy|[2510.23775](http://arxiv.org/abs/2510.23775)|null|\n"}, "VLA": {"2509.21243": "|**2025-09-25**|**RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models**|Jiyeon Koo,...Andrew Jaeyong Choi|[2509.21243](http://arxiv.org/abs/2509.21243)|null|\n", "2509.20109": "|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Pengxiang Li,...Xianpeng Lang|[2509.20109](http://arxiv.org/abs/2509.20109)|null|\n", "2509.19870": "|**2025-09-24**|**FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models**|Xin Wang,...Yu-Gang Jiang|[2509.19870](http://arxiv.org/abs/2509.19870)|null|\n", "2509.19752": "|**2025-09-24**|**Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training**|Rushuai Yang,...Yi Chen|[2509.19752](http://arxiv.org/abs/2509.19752)|null|\n", "2509.19571": "|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Sacha Morin,...Liam Paull|[2509.19571](http://arxiv.org/abs/2509.19571)|**[link](https://montrealrobotics.ca/agentic-scene-policies.github.io/)**|\n", "2509.19480": "|**2025-09-23**|**OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation**|Noriaki Hirose,...Sergey Levine|[2509.19480](http://arxiv.org/abs/2509.19480)|null|\n", "2509.19012": "|**2025-09-25**|**Pure Vision Language Action (VLA) Models: A Comprehensive Survey**|Dapeng Zhang,...Qingguo Zhou|[2509.19012](http://arxiv.org/abs/2509.19012)|null|\n", "2509.18953": "|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Hanqing Liu,...Wen Yao|[2509.18953](http://arxiv.org/abs/2509.18953)|null|\n", "2509.18428": "|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Bahey Tharwat,...Ian Reid|[2509.18428](http://arxiv.org/abs/2509.18428)|null|\n", "2509.15968": "|**2025-09-19**|**CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine**|Shiyu Fang,...Jian Sun|[2509.15968](http://arxiv.org/abs/2509.15968)|null|\n", "2509.15937": "|**2025-09-19**|**A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning**|Shaopeng Zhai,...Jiangmiao Pang|[2509.15937](http://arxiv.org/abs/2509.15937)|null|\n", "2509.15212": "|**2025-09-18**|**RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation**|Yuming Jiang,...Xin Li|[2509.15212](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|\n", "2509.14932": "|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Tobias J\u00fclg,...Florian Walter|[2509.14932](http://arxiv.org/abs/2509.14932)|null|\n", "2509.14889": "|**2025-09-18**|**CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human**|Nan Sun,...Huaping Liu|[2509.14889](http://arxiv.org/abs/2509.14889)|null|\n", "2509.14687": "|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Cong Tai,...Tao Shen|[2509.14687](http://arxiv.org/abs/2509.14687)|null|\n", "2509.18183": "|**2025-09-18**|**VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation**|Jinyue Bian,...Anzhou Hou|[2509.18183](http://arxiv.org/abs/2509.18183)|null|\n", "2509.14630": "|**2025-09-18**|**Toward Embodiment Equivariant Vision-Language-Action Policy**|Anzhe Chen,...Yue Wang|[2509.14630](http://arxiv.org/abs/2509.14630)|null|\n", "2509.14143": "|**2025-09-17**|**CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping**|Zijian An,...Lifeng Zhou|[2509.14143](http://arxiv.org/abs/2509.14143)|null|\n", "2509.14138": "|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Ran Yang,...Yiming Feng|[2509.14138](http://arxiv.org/abs/2509.14138)|null|\n", "2509.14117": "|**2025-09-22**|**GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model**|Ali Abouzeid,...Dezhen Song|[2509.14117](http://arxiv.org/abs/2509.14117)|null|\n", "2509.22643": "|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Wenkai Guo,...Ziwei Wang|[2509.22643](http://arxiv.org/abs/2509.22643)|null|\n", "2509.22441": "|**2025-09-26**|**UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation**|Zhangyuan Wang,...Dixia Fan|[2509.22441](http://arxiv.org/abs/2509.22441)|null|\n", "2509.22407": "|**2025-09-26**|**EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer**|Zhehao Dong,...Guan Huang|[2509.22407](http://arxiv.org/abs/2509.22407)|null|\n", "2509.22199": "|**2025-09-29**|**MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training**|Haoyun Li,...Xingang Wang|[2509.22199](http://arxiv.org/abs/2509.22199)|null|\n", "2509.22195": "|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Asher J. Hancock,...Anirudha Majumdar|[2509.22195](http://arxiv.org/abs/2509.22195)|null|\n", "2509.22093": "|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Xiaohuan Pei,...Chang Xu|[2509.22093](http://arxiv.org/abs/2509.22093)|null|\n", "2509.21986": "|**2025-09-26**|**Developing Vision-Language-Action Model from Egocentric Videos**|Tomoya Yoshida,...Shinsuke Mori|[2509.21986](http://arxiv.org/abs/2509.21986)|null|\n", "2509.21354": "|**2025-09-20**|**KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache**|Wanshun Xu,...Long Zhuang|[2509.21354](http://arxiv.org/abs/2509.21354)|null|\n", "2509.25032": "|**2025-09-29**|**AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation**|Ryosuke Takanami,...Tetsuya Ogata|[2509.25032](http://arxiv.org/abs/2509.25032)|null|\n", "2509.24948": "|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Junjin Xiao,...Qing Zhang|[2509.24948](http://arxiv.org/abs/2509.24948)|null|\n", "2509.24768": "|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Eric Hannus,...Ville Kyrki|[2509.24768](http://arxiv.org/abs/2509.24768)|null|\n", "2509.24559": "|**2025-09-29**|**Emergent World Representations in OpenVLA**|Marco Molinari,...Omar G. Younis|[2509.24559](http://arxiv.org/abs/2509.24559)|null|\n", "2509.24524": "|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Zhihao Wang,...Xianyuan Zhan|[2509.24524](http://arxiv.org/abs/2509.24524)|null|\n", "2509.23931": "|**2025-09-28**|**AutoPrune: Each Complexity Deserves a Pruning Policy**|Hanshi Wang,...Zhipeng Zhang|[2509.23931](http://arxiv.org/abs/2509.23931)|null|\n", "2509.23823": "|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Tian Nian,...Bingshan Hu|[2509.23823](http://arxiv.org/abs/2509.23823)|**[link](https://github.com/Tian-Nian/control_your_robot)**|\n", "2509.23655": "|**2025-09-28**|**Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models**|Rokas Bendikas,...Pietro Mazzaglia|[2509.23655](http://arxiv.org/abs/2509.23655)|null|\n", "2509.23224": "|**2025-09-27**|**Leave No Observation Behind: Real-time Correction for VLA Action Chunks**|Kohei Sendai,...Yusuke Iwasawa|[2509.23224](http://arxiv.org/abs/2509.23224)|null|\n", "2509.23121": "|**2025-09-27**|**Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges**|Shuai Li,...Zhibo Pang|[2509.23121](http://arxiv.org/abs/2509.23121)|null|\n", "2509.26642": "|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Zhuoyang Liu,...Shanghang Zhang|[2509.26642](http://arxiv.org/abs/2509.26642)|null|\n", "2509.25966": "|**2025-09-30**|**MUVLA: Learning to Explore Object Navigation via Map Understanding**|Peilong Han,...Jianye Hao|[2509.25966](http://arxiv.org/abs/2509.25966)|null|\n", "2509.25746": "|**2025-09-30**|**TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses**|Shuaijun Wang,...Yangwei You|[2509.25746](http://arxiv.org/abs/2509.25746)|null|\n", "2509.25718": "|**2025-09-30**|**VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning**|Si-Cheng Wang,...Zeng-Guang Hou|[2509.25718](http://arxiv.org/abs/2509.25718)|null|\n", "2509.25681": "|**2025-09-30**|**dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought**|Junjie Wen,...Yi Xu|[2509.25681](http://arxiv.org/abs/2509.25681)|null|\n", "2509.26251": "|**2025-09-30**|**Seeing Space and Motion: Enhancing Latent Actions with Spatial and Dynamic Awareness for VLA**|Zhejia Cai,...Ruqi Huang|[2509.26251](http://arxiv.org/abs/2509.26251)|null|\n", "2510.01711": "|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Taeyoung Kim,...Jinwoo Shin|[2510.01711](http://arxiv.org/abs/2510.01711)|null|\n", "2510.01642": "|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Zijun Lin,...Bihan Wen|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|\n", "2510.01623": "|**2025-10-02**|**VLA-R1: Enhancing Reasoning in Vision-Language-Action Models**|Angen Ye,...Zheng Zhu|[2510.01623](http://arxiv.org/abs/2510.01623)|null|\n", "2510.01389": "|**2025-10-01**|**INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models**|Ulas Berk Karli,...Tesca FItzgerald|[2510.01389](http://arxiv.org/abs/2510.01389)|null|\n", "2510.01068": "|**2025-10-01**|**Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition**|Jiahang Cao,...Andrew F. Luo|[2510.01068](http://arxiv.org/abs/2510.01068)|**[link](https://sagecao1125.github.io/GPC-Site/)**|\n", "2510.00695": "|**2025-10-02**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Myungkyu Koo,...Jinwoo Shin|[2510.00695](http://arxiv.org/abs/2510.00695)|**[link](https://myungkyukoo.github.io/hamlet/)**|\n", "2510.00600": "|**2025-10-01**|**Hybrid Training for Vision-Language-Action Models**|Pietro Mazzaglia,...Daniel Dijkman|[2510.00600](http://arxiv.org/abs/2510.00600)|null|\n", "2510.00406": "|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Hengtao Li,...Weihua Su|[2510.00406](http://arxiv.org/abs/2510.00406)|null|\n", "2510.03142": "|**2025-10-03**|**MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning**|Tianyu Xu,...He Wang|[2510.03142](http://arxiv.org/abs/2510.03142)|**[link](https://pku-epic.github.io/MM-Nav-Web/)**|\n", "2510.04898": "|**2025-10-06**|**HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks**|Zheng Xiong,...Shimon Whiteson|[2510.04898](http://arxiv.org/abs/2510.04898)|null|\n", "2510.04246": "|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Huiwon Jang,...Jinwoo Shin|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|\n", "2510.04041": "|**2025-10-05**|**SITCOM: Scaling Inference-Time COMpute for VLAs**|Ayudh Saxena,...Esha Pahwa|[2510.04041](http://arxiv.org/abs/2510.04041)|null|\n", "2510.03896": "|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Mingyu Liu,...Chunhua Shen|[2510.03896](http://arxiv.org/abs/2510.03896)|null|\n", "2510.03895": "|**2025-10-04**|**NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation**|Zheng Huang,...Chunhua Shen|[2510.03895](http://arxiv.org/abs/2510.03895)|null|\n", "2510.03827": "|**2025-10-04**|**LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization**|Xueyang Zhou,...Lichao Sun|[2510.03827](http://arxiv.org/abs/2510.03827)|null|\n", "2510.03342": "|**2025-10-02**|**Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer**|Abbas Abdolmaleki,...Yuxiang Zhou|[2510.03342](http://arxiv.org/abs/2510.03342)|null|\n", "2510.06207": "|**2025-10-07**|**EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model**|Zefu Lin,...Zhaoxiang Zhang|[2510.06207](http://arxiv.org/abs/2510.06207)|**[link](https://anonymous.4open.science/w/Embodied-Coder/)**|\n", "2510.05681": "|**2025-10-07**|**Verifier-free Test-Time Sampling for Vision Language Action Models**|Suhyeok Jang,...Jinwoo Shin|[2510.05681](http://arxiv.org/abs/2510.05681)|null|\n", "2510.05580": "|**2025-10-07**|**MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption**|Chen Li,...Marios Savvides|[2510.05580](http://arxiv.org/abs/2510.05580)|null|\n", "2510.07134": "|**2025-10-08**|**TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking**|Jiahang Liu,...He Wang|[2510.07134](http://arxiv.org/abs/2510.07134)|**[link](https://pku-epic.github.io/TrackVLA-plus-plus-Web/)**|\n", "2510.07077": "|**2025-10-08**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Kento Kawaharazuka,...Yuke Zhu|[2510.07077](http://arxiv.org/abs/2510.07077)|**[link](https://vla-survey.github.io)**|\n", "2510.07067": "|**2025-10-08**|**Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models**|Daria Pugacheva,...Elena Tutubalina|[2510.07067](http://arxiv.org/abs/2510.07067)|null|\n", "2510.06710": "|**2025-10-08**|**RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training**|Hongzhi Zang,...Yu Wang|[2510.06710](http://arxiv.org/abs/2510.06710)|**[link](https://github.com/RLinf/RLinf)**|\n", "2510.08464": "|**2025-10-09**|**Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered**|Jason Jabbour,...Shayegan Omidshafiei|[2510.08464](http://arxiv.org/abs/2510.08464)|null|\n", "2510.07869": "|**2025-10-15**|**USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots**|Junwen Gu,...Zhengxing Wu|[2510.07869](http://arxiv.org/abs/2510.07869)|**[link](https://vincentgu2000.github.io/u0project/)**|\n", "2510.07778": "|**2025-10-09**|**IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction**|Yandu Chen,...Liqiang Nie|[2510.07778](http://arxiv.org/abs/2510.07778)|null|\n", "2510.07730": "|**2025-10-09**|**DEAS: DEtached value learning with Action Sequence for Scalable Offline RL**|Changyeon Kim,...Yuke Zhu|[2510.07730](http://arxiv.org/abs/2510.07730)|**[link](https://changyeon.site/deas)**|\n", "2510.09607": "|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Shaoqi Dong,...Caifeng Shan|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|\n", "2510.09507": "|**2025-10-10**|**PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs**|Zixin Zhang,...Ying-Cong Chen|[2510.09507](http://arxiv.org/abs/2510.09507)|null|\n", "2510.09269": "|**2025-10-10**|**Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects**|Zirun Zhou,...Jingfeng Zhang|[2510.09269](http://arxiv.org/abs/2510.09269)|null|\n", "2510.11660": "|**2025-10-14**|**ManiAgent: An Agentic Framework for General Robotic Manipulation**|Yi Yang,...Xudong Liu|[2510.11660](http://arxiv.org/abs/2510.11660)|null|\n", "2510.11027": "|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Ganlin Yang,...Zhi Hou|[2510.11027](http://arxiv.org/abs/2510.11027)|null|\n", "2510.10975": "|**2025-10-14**|**RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model**|Mingtong Dai,...Xinyu Wu|[2510.10975](http://arxiv.org/abs/2510.10975)|null|\n", "2510.10932": "|**2025-10-13**|**TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models**|Zonghuan Xu,...Yu-Gang Jiang|[2510.10932](http://arxiv.org/abs/2510.10932)|null|\n", "2510.10274": "|**2025-10-11**|**X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model**|Jinliang Zheng,...Xianyuan Zhan|[2510.10274](http://arxiv.org/abs/2510.10274)|null|\n", "2510.10181": "|**2025-10-11**|**Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback**|Shaokai Wu,...Hongtao Lu|[2510.10181](http://arxiv.org/abs/2510.10181)|null|\n", "2510.09976": "|**2025-10-11**|**Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models**|Mingyang Lyu,...Yi Zeng|[2510.09976](http://arxiv.org/abs/2510.09976)|null|\n", "2510.09667": "|**2025-10-08**|**OmniSAT: Compact Action Token, Faster Auto Regression**|Huaihai Lyu,...Changsheng Xu|[2510.09667](http://arxiv.org/abs/2510.09667)|null|\n", "2510.12796": "|**2025-10-14**|**DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving**|Yingyan Li,...Zhaoxiang Zhang|[2510.12796](http://arxiv.org/abs/2510.12796)|null|\n", "2510.12710": "|**2025-10-14**|**Reflection-Based Task Adaptation for Self-Improving VLA**|Baicheng Li,...Hongbin Zha|[2510.12710](http://arxiv.org/abs/2510.12710)|null|\n", "2510.12276": "|**2025-10-17**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Fuhao Li,...Haoang Li|[2510.12276](http://arxiv.org/abs/2510.12276)|null|\n", "2510.13778": "|**2025-10-15**|**InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy**|Xinyi Chen,...Yangkun Zhu|[2510.13778](http://arxiv.org/abs/2510.13778)|null|\n", "2510.13626": "|**2025-10-15**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Senyu Fei,...Xipeng Qiu|[2510.13626](http://arxiv.org/abs/2510.13626)|null|\n", "2510.13375": "|**2025-10-15**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Tianyuan Yuan,...Hang Zhao|[2510.13375](http://arxiv.org/abs/2510.13375)|null|\n", "2510.13237": "|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Haochuan Xu,...Jingfeng Zhang|[2510.13237](http://arxiv.org/abs/2510.13237)|null|\n", "2510.13054": "|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Ankit Goyal,...Fabio Ramos|[2510.13054](http://arxiv.org/abs/2510.13054)|null|\n", "2510.14968": "|**2025-10-16**|**RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks**|Mingxuan Yan,...Jiachen Li|[2510.14968](http://arxiv.org/abs/2510.14968)|null|\n", "2510.14952": "|**2025-10-17**|**From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance**|Zhe Li,...Chang Xu|[2510.14952](http://arxiv.org/abs/2510.14952)|null|\n", "2510.14902": "|**2025-10-16**|**VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation**|Han Zhao,...Donglin Wang|[2510.14902](http://arxiv.org/abs/2510.14902)|null|\n", "2510.14836": "|**2025-10-16**|**QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models**|Yixuan Li,...Haoran Li|[2510.14836](http://arxiv.org/abs/2510.14836)|null|\n", "2510.14300": "|**2025-10-16**|**Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning**|Weijie Shen,...Yao Mu|[2510.14300](http://arxiv.org/abs/2510.14300)|null|\n", "2510.15446": "|**2025-10-17**|**VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving**|Ziang Guo,...Zufeng Zhang|[2510.15446](http://arxiv.org/abs/2510.15446)|null|\n", "2510.17640": "|**2025-10-24**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Yuquan Xue,...Ziwei Wang|[2510.17640](http://arxiv.org/abs/2510.17640)|null|\n", "2510.17439": "|**2025-10-20**|**From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors**|Zhengshen Zhang,...Pan Zhou|[2510.17439](http://arxiv.org/abs/2510.17439)|**[link](https://falcon-vla.github.io/)**|\n", "2510.17369": "|**2025-10-20**|**Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots**|Haochen Su,...Josie Hughes|[2510.17369](http://arxiv.org/abs/2510.17369)|null|\n", "2510.17148": "|**2025-10-21**|**DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment**|Yu Gao,...Wang Jijun|[2510.17148](http://arxiv.org/abs/2510.17148)|null|\n", "2510.17111": "|**2025-10-23**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Weifan Guan,...Jian Cheng|[2510.17111](http://arxiv.org/abs/2510.17111)|null|\n", "2510.16617": "|**2025-10-18**|**MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation**|Ruihan Zhao,...Ufuk Topcu|[2510.16617](http://arxiv.org/abs/2510.16617)|null|\n", "2510.16281": "|**2025-10-18**|**Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification**|Yilin Wu,...Claudia P'erez-D'Arpino|[2510.16281](http://arxiv.org/abs/2510.16281)|null|\n", "2510.16263": "|**2025-10-21**|**NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?**|Jierui Peng,...Yu Yin|[2510.16263](http://arxiv.org/abs/2510.16263)|**[link](https://vulab-ai.github.io/NEBULA-Alpha/)**|\n", "2510.16240": "|**2025-10-17**|**Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning**|Lukas Zbinden,...Sean Huver|[2510.16240](http://arxiv.org/abs/2510.16240)|null|\n", "2510.18337": "|**2025-10-23**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Wenhui Huang,...Heng Yang|[2510.18337](http://arxiv.org/abs/2510.18337)|null|\n", "2510.19752": "|**2025-10-22**|**Learning Affordances at Inference-Time for Vision-Language-Action Models**|Ameesh Shah,...Sergey Levine|[2510.19752](http://arxiv.org/abs/2510.19752)|null|\n", "2510.19430": "|**2025-10-22**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**|GigaBrain Team,...Zheng Zhu|[2510.19430](http://arxiv.org/abs/2510.19430)|**[link](https://gigabrain0.github.io/)**|\n", "2510.19400": "|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Zhiyuan Feng,...Baining Guo|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|\n", "2510.20818": "|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Mateo Guaman Castro,...Abhishek Gupta|[2510.20818](http://arxiv.org/abs/2510.20818)|null|\n", "2510.20328": "|**2025-10-23**|**MemER: Scaling Up Memory for Robot Control via Experience Retrieval**|Ajay Sridhar,...Chelsea Finn|[2510.20328](http://arxiv.org/abs/2510.20328)|**[link](https://jen-pan.github.io/memer/)**|\n", "2510.21571": "|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Qixiu Li,...Baining Guo|[2510.21571](http://arxiv.org/abs/2510.21571)|**[link](https://microsoft.github.io/VITRA/)**|\n", "2510.20965": "|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Jesse Haworth,...Axel Krieger|[2510.20965](http://arxiv.org/abs/2510.20965)|null|\n", "2510.23576": "|**2025-10-27**|**UrbanVLA: A Vision-Language-Action Model for Urban Micromobility**|Anqi Li,...He Wang|[2510.23576](http://arxiv.org/abs/2510.23576)|null|\n", "2510.23511": "|**2025-10-27**|**Dexbotic: Open-Source Vision-Language-Action Toolbox**|Bin Xie,...Ziyu Zhang|[2510.23511](http://arxiv.org/abs/2510.23511)|**[link](https://dexbotic.com/.)**|\n", "2510.22201": "|**2025-10-25**|**ACG: Action Coherence Guidance for Flow-based VLA models**|Minho Park,...Jaegul Choo|[2510.22201](http://arxiv.org/abs/2510.22201)|null|\n", "2510.21860": "|**2025-10-23**|**Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence**|Callum Sharrock,...Elias Aronsson|[2510.21860](http://arxiv.org/abs/2510.21860)|null|\n", "2510.21817": "|**2025-10-21**|**VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting**|Xiaoyu Liu,...Ran He|[2510.21817](http://arxiv.org/abs/2510.21817)|**[link](https://lxysl.github.io/VITA-E/)**|\n", "2510.24161": "|**2025-10-28**|**BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning**|Wentao Tan,...Heng Tao Shen|[2510.24161](http://arxiv.org/abs/2510.24161)|null|\n", "2510.23763": "|**2025-10-27**|**RoboOmni: Proactive Robot Manipulation in Omni-modal Context**|Siyin Wang,...Xipeng Qiu|[2510.23763](http://arxiv.org/abs/2510.23763)|null|\n"}, "Humanoid": {"2509.21231": "|**2025-09-25**|**SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation**|Jaehwi Jang,...Ye Zhao|[2509.21231](http://arxiv.org/abs/2509.21231)|null|\n", "2509.20696": "|**2025-09-25**|**RuN: Residual Policy for Natural Humanoid Locomotion**|Qingpeng Li,...Yong Liu|[2509.20696](http://arxiv.org/abs/2509.20696)|null|\n", "2509.20579": "|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|Hanna Yurchyk,...David Meger|[2509.20579](http://arxiv.org/abs/2509.20579)|null|\n", "2509.20322": "|**2025-09-24**|**VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation**|Shaofeng Yin,...Jiajun Wu|[2509.20322](http://arxiv.org/abs/2509.20322)|**[link](https://visualmimic.github.io)**|\n", "2509.20263": "|**2025-09-25**|**HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms**|Bingjie Chen,...Houde Liu|[2509.20263](http://arxiv.org/abs/2509.20263)|null|\n", "2509.19573": "|**2025-09-23**|**Chasing Stability: Humanoid Running via Control Lyapunov Function Guided Reinforcement Learning**|Zachary Olkin,...Aaron D. Ames|[2509.19573](http://arxiv.org/abs/2509.19573)|null|\n", "2509.19545": "|**2025-09-23**|**RoMoCo: Robotic Motion Control Toolbox for Reduced-Order Model-Based Locomotion on Bipedal and Humanoid Robots**|Min Dai,...Aaron D. Ames|[2509.19545](http://arxiv.org/abs/2509.19545)|null|\n", "2509.19301": "|**2025-09-25**|**Residual Off-Policy RL for Finetuning Behavior Cloning Policies**|Lars Ankile,...Anusha Nagabandi|[2509.19301](http://arxiv.org/abs/2509.19301)|**[link](https://residual-offpolicy-rl.github.io)**|\n", "2509.16757": "|**2025-09-27**|**HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos**|Haoyang Weng,...Guanya Shi|[2509.16757](http://arxiv.org/abs/2509.16757)|null|\n", "2509.16638": "|**2025-09-20**|**KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control**|Jinrui Han,...Chenjia Bai|[2509.16638](http://arxiv.org/abs/2509.16638)|null|\n", "2509.16469": "|**2025-09-19**|**A Framework for Optimal Ankle Design of Humanoid Robots**|Guglielmo Cervettini,...Daniele Pucci|[2509.16469](http://arxiv.org/abs/2509.16469)|null|\n", "2509.16032": "|**2025-09-19**|**A Matter of Height: The Impact of a Robotic Object on Human Compliance**|Michael Faber,...Hadas Erel|[2509.16032](http://arxiv.org/abs/2509.16032)|null|\n", "2509.15443": "|**2025-09-18**|**Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning**|Xingyu Chen,...Haodong Zhang|[2509.15443](http://arxiv.org/abs/2509.15443)|null|\n", "2509.14935": "|**2025-09-18**|**CAD-Driven Co-Design for Flight-Ready Jet-Powered Humanoids**|Punith Reddy Vanteddu,...Daniele Pucci|[2509.14935](http://arxiv.org/abs/2509.14935)|null|\n", "2509.14687": "|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Cong Tai,...Tao Shen|[2509.14687](http://arxiv.org/abs/2509.14687)|null|\n", "2509.14139": "|**2025-09-23**|**Cybersecurity AI: Humanoid Robots as Attack Vectors**|V\u00edctor Mayoral-Vilches,...Kevin Finisterre|[2509.14139](http://arxiv.org/abs/2509.14139)|null|\n", "2509.14096": "|**2025-09-17**|**The Cybersecurity of a Humanoid Robot**|V\u00edctor Mayoral-Vilches,...V\u00edctor Mayoral-Vilches|[2509.14096](http://arxiv.org/abs/2509.14096)|null|\n", "2509.13780": "|**2025-09-17**|**Behavior Foundation Model for Humanoid Robots**|Weishuai Zeng,...Jiangmiao Pang|[2509.13780](http://arxiv.org/abs/2509.13780)|null|\n", "2509.13733": "|**2025-09-17**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Xiaolin Zhou,...Zhizhong Su|[2509.13733](http://arxiv.org/abs/2509.13733)|null|\n", "2509.13534": "|**2025-09-16**|**Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning**|Chunxin Zheng,...Jun Ma|[2509.13534](http://arxiv.org/abs/2509.13534)|null|\n", "2509.24697": "|**2025-09-29**|**Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering**|Evelyn D'Elia,...Daniele Pucci|[2509.24697](http://arxiv.org/abs/2509.24697)|null|\n", "2509.24530": "|**2025-09-29**|**Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game**|Giulia Pusceddu,...Alessandra Sciutti|[2509.24530](http://arxiv.org/abs/2509.24530)|null|\n", "2509.24163": "|**2025-09-29**|**Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models**|Wanming Yu,...Sethu Vijayakumar|[2509.24163](http://arxiv.org/abs/2509.24163)|null|\n", "2509.23852": "|**2025-09-28**|**SIG-Chat: Spatial Intent-Guided Conversational Gesture Generation Involving How, When and Where**|Yiheng Huang,...Chuanchen Luo|[2509.23852](http://arxiv.org/abs/2509.23852)|null|\n", "2509.26633": "|**2025-10-08**|**OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction**|Lujie Yang,...Guanya Shi|[2509.26633](http://arxiv.org/abs/2509.26633)|**[link](https://omniretarget.github.io)**|\n", "2509.26236": "|**2025-09-30**|**ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm**|Benjamin A. Richardson,...Katherine J. Kuchenbecker|[2509.26236](http://arxiv.org/abs/2509.26236)|null|\n", "2509.26082": "|**2025-09-30**|**Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance**|Tianyi Jin,...Frank Kirchner|[2509.26082](http://arxiv.org/abs/2509.26082)|null|\n", "2509.25443": "|**2025-10-06**|**CoTaP: Compliant Task Pipeline and Reinforcement Learning of Its Controller with Compliance Modulation**|Zewen He,...Yoshihiko Nakamura|[2509.25443](http://arxiv.org/abs/2509.25443)|null|\n", "2510.02252": "|**2025-10-02**|**Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking**|Joao Pedro Araujo,...C. Karen Liu|[2510.02252](http://arxiv.org/abs/2510.02252)|null|\n", "2510.02129": "|**2025-10-02**|**Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control**|Philip Reichenberg,...Tim Laue|[2510.02129](http://arxiv.org/abs/2510.02129)|null|\n", "2510.01843": "|**2025-10-02**|**Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots**|Wanyue Li,...Peng Lu|[2510.01843](http://arxiv.org/abs/2510.01843)|null|\n", "2510.00329": "|**2025-09-30**|**Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning**|Sarmad Mehrdad,...Ludovic Righetti|[2510.00329](http://arxiv.org/abs/2510.00329)|null|\n", "2510.03081": "|**2025-10-03**|**Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot**|Guiliang Liu,...Kui Jia|[2510.03081](http://arxiv.org/abs/2510.03081)|null|\n", "2510.03022": "|**2025-10-03**|**HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton**|Rui Zhong,...Yi Xu|[2510.03022](http://arxiv.org/abs/2510.03022)|null|\n", "2510.05001": "|**2025-10-06**|**Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot**|Aditya Sripada,...Abhishek Warrier|[2510.05001](http://arxiv.org/abs/2510.05001)|null|\n", "2510.04353": "|**2025-10-05**|**Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation**|Stephen McCrory,...Robert Griffin|[2510.04353](http://arxiv.org/abs/2510.04353)|null|\n", "2510.03529": "|**2025-10-03**|**LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy**|Zekai Liang,...Michael C. Yip|[2510.03529](http://arxiv.org/abs/2510.03529)|null|\n", "2510.05923": "|**2025-10-07**|**A Co-Design Framework for Energy-Aware Monoped Jumping with Detailed Actuator Modeling**|Aman Singh,...Shishir Kolathaya|[2510.05923](http://arxiv.org/abs/2510.05923)|null|\n", "2510.07152": "|**2025-10-10**|**DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction**|Jingkai Sun,...Qiang Zhang|[2510.07152](http://arxiv.org/abs/2510.07152)|null|\n", "2510.08475": "|**2025-10-09**|**DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos**|Jhen Hsieh,...Tsung-Wei Ke|[2510.08475](http://arxiv.org/abs/2510.08475)|**[link](https://embodiedai-ntu.github.io/dexman/index.html)**|\n", "2510.08406": "|**2025-10-09**|**Reliability of Single-Level Equality-Constrained Inverse Optimal Control**|Filip Be\u010danovi\u0107,...Vincent Bonnet|[2510.08406](http://arxiv.org/abs/2510.08406)|null|\n", "2510.07882": "|**2025-10-15**|**Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots**|Boyu Li,...Zongqing Lu|[2510.07882](http://arxiv.org/abs/2510.07882)|null|\n", "2510.08807": "|**2025-10-09**|**Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation**|Zhenyu Zhao,...Yue Wang|[2510.08807](http://arxiv.org/abs/2510.08807)|null|\n", "2510.11682": "|**2025-10-13**|**Ego-Vision World Model for Humanoid Contact Planning**|Hang Liu,...Koushil Sreenath|[2510.11682](http://arxiv.org/abs/2510.11682)|null|\n", "2510.11539": "|**2025-10-13**|**Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization**|Denglin Cheng,...Xiaobin Xiong|[2510.11539](http://arxiv.org/abs/2510.11539)|null|\n", "2510.11401": "|**2025-10-13**|**Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots**|Jiayang Wu,...Yao Su|[2510.11401](http://arxiv.org/abs/2510.11401)|null|\n", "2510.11258": "|**2025-10-13**|**DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation**|Yuhui Fu,...Zongqing Lu|[2510.11258](http://arxiv.org/abs/2510.11258)|null|\n", "2510.11072": "|**2025-10-13**|**PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System**|Huayi Wang,...Jiangmiao Pang|[2510.11072](http://arxiv.org/abs/2510.11072)|**[link](https://why618188.github.io/physhsi/)**|\n", "2510.10851": "|**2025-10-12**|**Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion**|Tingxuan Leng,...Mingguo Zhao|[2510.10851](http://arxiv.org/abs/2510.10851)|null|\n", "2510.10206": "|**2025-10-11**|**It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots**|Zuhong Liu,...Siheng Chen|[2510.10206](http://arxiv.org/abs/2510.10206)|null|\n", "2510.09786": "|**2025-10-10**|**Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks**|Yuang Lu,...Zhicheng He|[2510.09786](http://arxiv.org/abs/2510.09786)|null|\n", "2510.12346": "|**2025-10-14**|**PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing**|Bingquan Li,...Yucong Wu|[2510.12346](http://arxiv.org/abs/2510.12346)|null|\n", "2510.13625": "|**2025-10-15**|**A Modular Object Detection System for Humanoid Robots Using YOLO**|Nicolas Pottier,...Meng Cheng Lau|[2510.13625](http://arxiv.org/abs/2510.13625)|null|\n", "2510.13594": "|**2025-10-15**|**Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots**|Austin Barret,...Meng Cheng Lau|[2510.13594](http://arxiv.org/abs/2510.13594)|null|\n", "2510.14959": "|**2025-10-19**|**CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions**|Lizhi Yang,...Aaron D. Ames|[2510.14959](http://arxiv.org/abs/2510.14959)|null|\n", "2510.14952": "|**2025-10-17**|**From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance**|Zhe Li,...Chang Xu|[2510.14952](http://arxiv.org/abs/2510.14952)|null|\n", "2510.14454": "|**2025-10-16**|**Towards Adaptable Humanoid Control via Adaptive Motion Tracking**|Tao Huang,...Jiangmiao Pang|[2510.14454](http://arxiv.org/abs/2510.14454)|null|\n", "2510.17792": "|**2025-10-20**|**SoftMimic: Learning Compliant Whole-body Control from Examples**|Gabriel B. Margolis,...Pulkit Agrawal|[2510.17792](http://arxiv.org/abs/2510.17792)|**[link](https://gmargo11.github.io/softmimic/)**|\n", "2510.18544": "|**2025-10-21**|**SLICE: SLO-Driven Scheduling for LLM Inference on Edge Computing Devices**|Pan Zhou,...Yueyue Dai|[2510.18544](http://arxiv.org/abs/2510.18544)|null|\n", "2510.18002": "|**2025-10-20**|**Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints**|Junli Ren,...Jiangmiao Pang|[2510.18002](http://arxiv.org/abs/2510.18002)|null|\n", "2510.23059": "|**2025-10-27**|**Awakening Facial Emotional Expressions in Human-Robot**|Yongtong Zhu,...Jianwei Zhang|[2510.23059](http://arxiv.org/abs/2510.23059)|null|\n", "2510.22336": "|**2025-10-25**|**Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery**|Bo Yue,...Guiliang Liu|[2510.22336](http://arxiv.org/abs/2510.22336)|null|\n"}, "3DGS/NeRF": {"2509.20774": "|**2025-09-25**|**Gaussian splatting holography**|Shuhe Zhang,...Liangcai Cao|[2509.20774](http://arxiv.org/abs/2509.20774)|null|\n", "2509.20251": "|**2025-09-24**|**4D Driving Scene Generation With Stereo Forcing**|Hao Lu,...Yingcong Chen|[2509.20251](http://arxiv.org/abs/2509.20251)|null|\n", "2509.19937": "|**2025-09-24**|**GS-RoadPatching: Inpainting Gaussians via 3D Searching and Placing for Driving Scenes**|Guo Chen,...Sheng Yang|[2509.19937](http://arxiv.org/abs/2509.19937)|null|\n", "2509.19898": "|**2025-09-24**|**Aerial-Ground Image Feature Matching via 3D Gaussian Splatting-based Intermediate View Rendering**|Jiangxue Yu,...Qingquan Li|[2509.19898](http://arxiv.org/abs/2509.19898)|null|\n", "2509.19793": "|**2025-09-24**|**BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth Estimation via 3D Gaussian Splatting**|Yixun Zhang,...Jianqin Yin|[2509.19793](http://arxiv.org/abs/2509.19793)|null|\n", "2509.19726": "|**2025-09-24**|**PolGS: Polarimetric Gaussian Splatting for Fast Reflective Surface Reconstruction**|Yufei Han,...Zhanyu Ma|[2509.19726](http://arxiv.org/abs/2509.19726)|null|\n", "2509.20400": "|**2025-09-23**|**SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing**|Yiyu Li,...Rynson W. H. Lau|[2509.20400](http://arxiv.org/abs/2509.20400)|null|\n", "2509.19297": "|**2025-09-23**|**VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction**|Weijie Wang,...Bohan Zhuang|[2509.19297](http://arxiv.org/abs/2509.19297)|**[link](https://lhmd.top/volsplat)**|\n", "2509.19296": "|**2025-09-23**|**Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation**|Sherwin Bahmani,...Xuanchi Ren|[2509.19296](http://arxiv.org/abs/2509.19296)|**[link](https://research.nvidia.com/labs/toronto-ai/lyra/)**|\n", "2509.19073": "|**2025-09-23**|**WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction**|Hung Nguyen,...Truong Nguyen|[2509.19073](http://arxiv.org/abs/2509.19073)|null|\n", "2509.18956": "|**2025-09-23**|**Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting**|Zijing Guo,...Lin Wang|[2509.18956](http://arxiv.org/abs/2509.18956)|null|\n", "2509.18898": "|**2025-09-23**|**DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring**|Pengteng Li,...Hui Xiong|[2509.18898](http://arxiv.org/abs/2509.18898)|null|\n", "2509.18759": "|**2025-09-23**|**FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation**|Zhaorui Wang,...Renjing Xu|[2509.18759](http://arxiv.org/abs/2509.18759)|null|\n", "2509.18610": "|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Maximilian Adang,...Mac Schwager|[2509.18610](http://arxiv.org/abs/2509.18610)|null|\n", "2509.18566": "|**2025-09-23**|**Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction**|Xiaoting Yin,...Kaiwei Wang|[2509.18566](http://arxiv.org/abs/2509.18566)|null|\n", "2509.18501": "|**2025-09-23**|**BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting for Deformable Intraoperative Surgical Navigation**|Maximilian Fehrentz,...Nassir Navab|[2509.18501](http://arxiv.org/abs/2509.18501)|null|\n", "2509.18497": "|**2025-09-23**|**Differentiable Light Transport with Gaussian Surfels via Adapted Radiosity for Efficient Relighting and Geometry Reconstruction**|Kaiwen Jiang,...Ravi Ramamoorthi|[2509.18497](http://arxiv.org/abs/2509.18497)|null|\n", "2509.18090": "|**2025-09-22**|**GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction**|Jiahe Li,...Lin Gu|[2509.18090](http://arxiv.org/abs/2509.18090)|**[link](https://fictionarry.github.io/GeoSVR-project/)**|\n", "2509.17889": "|**2025-09-22**|**GaussianPSL: A novel framework based on Gaussian Splatting for exploring the Pareto frontier in multi-criteria optimization**|Phuong Mai Dinh,...Van-Nam Huynh|[2509.17889](http://arxiv.org/abs/2509.17889)|null|\n", "2509.17864": "|**2025-09-22**|**ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos**|Shi Chen,...Martin R. Oswald|[2509.17864](http://arxiv.org/abs/2509.17864)|null|\n", "2509.22615": "|**2025-09-26**|**Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting**|Yasmine Omri,...Thierry Tambe|[2509.22615](http://arxiv.org/abs/2509.22615)|null|\n", "2509.22276": "|**2025-09-26**|**GS-2M: Gaussian Splatting for Joint Mesh Reconstruction and Material Decomposition**|Dinh Minh Nguyen,...Thomas Lindemeier|[2509.22276](http://arxiv.org/abs/2509.22276)|null|\n", "2509.22225": "|**2025-09-26**|**Polysemous Language Gaussian Splatting via Matching-based Mask Lifting**|Jiayu Ding,...Ge Li|[2509.22225](http://arxiv.org/abs/2509.22225)|null|\n", "2509.22112": "|**2025-09-26**|**Large Material Gaussian Model for Relightable 3D Generation**|Jingrui Ye,...Qingmin Liao|[2509.22112](http://arxiv.org/abs/2509.22112)|null|\n", "2509.21888": "|**2025-09-26**|**Drag4D: Align Your Motion with Text-Driven 3D Scene Generation**|Minjun Kang,...Kuk-Jin Yoon|[2509.21888](http://arxiv.org/abs/2509.21888)|null|\n", "2509.21853": "|**2025-09-30**|**Dynamic Novel View Synthesis in High Dynamic Range**|Kaixuan Zhang,...Xiatian Zhu|[2509.21853](http://arxiv.org/abs/2509.21853)|null|\n", "2509.21702": "|**2025-09-25**|**PowerGS: Display-Rendering Power Co-Optimization for Neural Rendering in Power-Constrained XR Systems**|Weikai Lin,...Yuhao Zhu|[2509.21702](http://arxiv.org/abs/2509.21702)|null|\n", "2509.25122": "|**2025-09-29**|**Triangle Splatting+: Differentiable Rendering with Opaque Triangles**|Jan Held,...Andrea Tagliasacchi|[2509.25122](http://arxiv.org/abs/2509.25122)|null|\n", "2509.25075": "|**2025-10-02**|**GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction**|Huaizhi Qu,...Tianlong Chen|[2509.25075](http://arxiv.org/abs/2509.25075)|null|\n", "2509.25001": "|**2025-09-29**|**LVT: Large-Scale Scene Reconstruction via Local View Transformers**|Tooba Imtiaz,...John Flynn|[2509.25001](http://arxiv.org/abs/2509.25001)|**[link](https://toobaimt.github.io/lvt/)**|\n", "2509.24893": "|**2025-09-29**|**DWGS: Enhancing Sparse-View Gaussian Splatting with Hybrid-Loss Depth Estimation and Bidirectional Warping**|Yu Ma,...Yue Cheng|[2509.24893](http://arxiv.org/abs/2509.24893)|null|\n", "2509.24758": "|**2025-09-29**|**ExGS: Extreme 3D Gaussian Compression with Diffusion Priors**|Jiaqi Chen,...Xiao Sun|[2509.24758](http://arxiv.org/abs/2509.24758)|null|\n", "2509.24421": "|**2025-10-01**|**Proxy-GS: Efficient 3D Gaussian Splatting via Proxy Mesh**|Yuanyuan Gao,...Xiao Sun|[2509.24421](http://arxiv.org/abs/2509.24421)|null|\n", "2509.24308": "|**2025-09-29**|**OMeGa: Joint Optimization of Explicit Meshes and Gaussian Splats for Robust Scene-Level Surface Reconstruction**|Yuhang Cao,...Danya Yao|[2509.24308](http://arxiv.org/abs/2509.24308)|null|\n", "2509.23947": "|**2025-09-28**|**CrashSplat: 2D to 3D Vehicle Damage Segmentation in Gaussian Splatting**|Drago\u015f-Andrei Chileban,...Cosmin Cern\u01cezanu-Gl\u01cevan|[2509.23947](http://arxiv.org/abs/2509.23947)|null|\n", "2509.23555": "|**2025-09-28**|**From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations**|Javed Ahmad,...Yonas Teodros Tefera|[2509.23555](http://arxiv.org/abs/2509.23555)|null|\n", "2509.23492": "|**2025-09-27**|**Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual Videos**|Junyi Wu,...Yan Yan|[2509.23492](http://arxiv.org/abs/2509.23492)|**[link](https://github.com/adreamwu/OriGS}{OriGS})**|\n", "2509.23258": "|**2025-09-27**|**OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting**|Atakan Topaloglu,...Federico Tombari|[2509.23258](http://arxiv.org/abs/2509.23258)|null|\n", "2509.22917": "|**2025-09-26**|**Learning Unified Representation of 3D Gaussian Splatting**|Yuelin Xin,...Xinke Li|[2509.22917](http://arxiv.org/abs/2509.22917)|null|\n", "2509.26621": "|**2025-09-30**|**HART: Human Aligned Reconstruction Transformer**|Xiyi Chen,...Ming Lin|[2509.26621](http://arxiv.org/abs/2509.26621)|**[link](https://xiyichen.github.io/hart)**|\n", "2509.26455": "|**2025-09-30**|**Stylos: Multi-View 3D Stylization with Single-Forward Gaussian Splatting**|Hanzhou Liu,...Peng Jiang|[2509.26455](http://arxiv.org/abs/2509.26455)|null|\n", "2509.26055": "|**2025-09-30**|**GaussEdit: Adaptive 3D Scene Editing with Text and Image Prompts**|Zhenyu Shu,...Ligang Liu|[2509.26055](http://arxiv.org/abs/2509.26055)|null|\n", "2509.26008": "|**2025-09-30**|**PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion**|Zhiwei Zhang,...Lizhuang Ma|[2509.26008](http://arxiv.org/abs/2509.26008)|null|\n", "2509.25626": "|**2025-09-30**|**LLM-Powered Code Analysis and Optimization for Gaussian Splatting Kernels**|Yi Hu,...Huiyang Zhou|[2509.25626](http://arxiv.org/abs/2509.25626)|null|\n", "2509.25603": "|**2025-09-29**|**GaussianLens: Localized High-Resolution Reconstruction via On-Demand Gaussian Densification**|Yijia Weng,...Leonidas J. Guibas|[2509.25603](http://arxiv.org/abs/2509.25603)|null|\n", "2510.02314": "|**2025-10-02**|**StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions**|Bo-Hsu Ke,...Wei-Chen Chiu|[2510.02314](http://arxiv.org/abs/2510.02314)|**[link](https://hentci.github.io/stealthattack/)**|\n", "2510.02248": "|**2025-10-02**|**Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0**|Yan Miao,...Sayan Mitra|[2510.02248](http://arxiv.org/abs/2510.02248)|null|\n", "2510.02069": "|**2025-10-02**|**Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects**|Georgios Kouros,...Tinne Tuytelaars|[2510.02069](http://arxiv.org/abs/2510.02069)|null|\n", "2510.02034": "|**2025-10-02**|**GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing**|Mengtian Li,...Chaofeng Chen|[2510.02034](http://arxiv.org/abs/2510.02034)|**[link](https://baiyunshu.github.io/GAUSSIANMORPHING.github.io/)**|\n", "2510.01991": "|**2025-10-02**|**4DGS-Craft: Consistent and Interactive 4D Gaussian Splatting Editing**|Lei Liu,...Dong Xu|[2510.01991](http://arxiv.org/abs/2510.01991)|null|\n", "2510.01978": "|**2025-10-02**|**ROI-GS: Interest-based Local Quality 3D Gaussian Splatting**|Quoc-Anh Bui,...Simone Gasparini|[2510.01978](http://arxiv.org/abs/2510.01978)|null|\n", "2510.01848": "|**2025-10-02**|**GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics**|Diram Tabaa,...Gianni Di Caro|[2510.01848](http://arxiv.org/abs/2510.01848)|null|\n", "2510.01767": "|**2025-10-02**|**LOBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for Large-Scale Scene Reconstruction**|Sheng-Hsiang Hung,...Hung-Kuo Chu|[2510.01767](http://arxiv.org/abs/2510.01767)|null|\n", "2510.01619": "|**2025-10-02**|**MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics**|Changmin Lee,...Tae-Kyun Kim|[2510.01619](http://arxiv.org/abs/2510.01619)|null|\n", "2510.01119": "|**2025-10-01**|**Instant4D: 4D Gaussian Splatting in Minutes**|Zhanpeng Luo,...Li Lu|[2510.01119](http://arxiv.org/abs/2510.01119)|null|\n", "2510.03104": "|**2025-10-03**|**Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields**|Zhiting Mei,...Anirudha Majumdar|[2510.03104](http://arxiv.org/abs/2510.03104)|null|\n", "2510.02884": "|**2025-10-03**|**GS-Share: Enabling High-fidelity Map Sharing with Incremental Gaussian Splatting**|Xinran Zhang,...Yanyong Zhang|[2510.02884](http://arxiv.org/abs/2510.02884)|null|\n", "2510.02732": "|**2025-10-03**|**From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting**|Jianing Chen,...Yucheng Zhang|[2510.02732](http://arxiv.org/abs/2510.02732)|null|\n", "2510.02691": "|**2025-10-03**|**FSFSplatter: Build Surface and Novel Views with Sparse-Views within 3min**|Yibin Zhao,...Jianjun Yi|[2510.02691](http://arxiv.org/abs/2510.02691)|null|\n", "2510.02469": "|**2025-10-02**|**SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting**|Sung-Yeon Park,...Ziran Wang|[2510.02469](http://arxiv.org/abs/2510.02469)|null|\n", "2510.03857": "|**2025-10-04**|**Optimized Minimal 4D Gaussian Splatting**|Minseo Lee,...Eunbyung Park|[2510.03857](http://arxiv.org/abs/2510.03857)|null|\n", "2510.03545": "|**2025-10-03**|**SketchPlan: Diffusion Based Drone Planning From Human Sketches**|Sixten Norelius,...Mac Schwager|[2510.03545](http://arxiv.org/abs/2510.03545)|**[link](https://github.com/sixnor/SketchPlan)**|\n", "2510.03312": "|**2025-09-30**|**Universal Beta Splatting**|Rong Liu,...Ziyan Wu|[2510.03312](http://arxiv.org/abs/2510.03312)|null|\n", "2510.05488": "|**2025-10-07**|**ArchitectHead: Continuous Level of Detail Control for 3D Gaussian Head Avatars**|Peizhi Yan,...Shan Du|[2510.05488](http://arxiv.org/abs/2510.05488)|null|\n", "2510.06967": "|**2025-10-08**|**Generating Surface for Text-to-3D using 2D Gaussian Splatting**|Huanning Dong,...Jianwen Min|[2510.06967](http://arxiv.org/abs/2510.06967)|null|\n", "2510.06802": "|**2025-10-08**|**Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity**|Islomjon Shukhratov,...Sergey Gorinsky|[2510.06802](http://arxiv.org/abs/2510.06802)|null|\n", "2510.06694": "|**2025-10-08**|**SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis**|Jipeng Lyu,...Yu-Xiong Wang|[2510.06694](http://arxiv.org/abs/2510.06694)|null|\n", "2510.06644": "|**2025-10-09**|**RTGS: Real-Time 3D Gaussian Splatting SLAM via Multi-Level Redundancy Reduction**|Leshu Li,...Yang Katie Zhao|[2510.06644](http://arxiv.org/abs/2510.06644)|null|\n", "2510.06481": "|**2025-10-07**|**Active Next-Best-View Optimization for Risk-Averse Path Planning**|Amirhossein Mollaei Khass,...Nader Motee|[2510.06481](http://arxiv.org/abs/2510.06481)|null|\n", "2510.08575": "|**2025-10-09**|**ReSplat: Learning Recurrent Gaussian Splats**|Haofei Xu,...Marc Pollefeys|[2510.08575](http://arxiv.org/abs/2510.08575)|**[link](https://haofeixu.github.io/resplat/)**|\n", "2510.08566": "|**2025-10-09**|**D$^2$GS: Depth-and-Density Guided Gaussian Splatting for Stable and Accurate Sparse-View Reconstruction**|Meixi Song,...Lu Qi|[2510.08566](http://arxiv.org/abs/2510.08566)|null|\n", "2510.08491": "|**2025-10-09**|**Splat the Net: Radiance Fields with Splattable Neural Primitives**|Xilong Zhou,...Christian Theobalt|[2510.08491](http://arxiv.org/abs/2510.08491)|null|\n", "2510.08096": "|**2025-10-09**|**Efficient Label Refinement for Face Parsing Under Extreme Poses Using 3D Gaussian Splatting**|Ankit Gahlawat,...Dinesh Babu Jayagopi|[2510.08096](http://arxiv.org/abs/2510.08096)|null|\n", "2510.07944": "|**2025-10-09**|**CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving**|Tianrui Zhang,...Zehuan Wu|[2510.07944](http://arxiv.org/abs/2510.07944)|null|\n", "2510.07830": "|**2025-10-09**|**PrismGS: Physically-Grounded Anti-Aliasing for High-Fidelity Large-Scale 3D Gaussian Splatting**|Houqiang Zhong,...Qiang Hu|[2510.07830](http://arxiv.org/abs/2510.07830)|null|\n", "2510.07752": "|**2025-10-09**|**DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream**|Junhao He,...Renjing Xu|[2510.07752](http://arxiv.org/abs/2510.07752)|null|\n", "2510.07729": "|**2025-10-09**|**ComGS: Efficient 3D Object-Scene Composition via Surface Octahedral Probes**|Jian Gao,...Yao Yao|[2510.07729](http://arxiv.org/abs/2510.07729)|null|\n", "2510.09586": "|**2025-10-10**|**Vision Language Models: A Survey of 26K Papers**|Fengming Lin,...Fengming Lin|[2510.09586](http://arxiv.org/abs/2510.09586)|null|\n", "2510.09537": "|**2025-10-10**|**FLOWING: Implicit Neural Flows for Structure-Preserving Morphing**|Arthur Bizzi,...Tiago Novello|[2510.09537](http://arxiv.org/abs/2510.09537)|null|\n", "2510.09489": "|**2025-10-10**|**Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction**|Deborah Pintani,...Andrea Giachetti|[2510.09489](http://arxiv.org/abs/2510.09489)|null|\n", "2510.09364": "|**2025-10-10**|**Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes**|Yikang Zhang,...Rui Fan|[2510.09364](http://arxiv.org/abs/2510.09364)|null|\n", "2510.11717": "|**2025-10-13**|**Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams**|Takuya Nakabayashi,...Vladislav Golyanik|[2510.11717](http://arxiv.org/abs/2510.11717)|null|\n", "2510.11689": "|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Maggie Wang,...Mac Schwager|[2510.11689](http://arxiv.org/abs/2510.11689)|null|\n", "2510.11473": "|**2025-10-13**|**VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment**|Qing Li,...Yu-Shen Liu|[2510.11473](http://arxiv.org/abs/2510.11473)|null|\n", "2510.11387": "|**2025-10-13**|**MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference**|Wenyuan Zhang,...Zhizhong Han|[2510.11387](http://arxiv.org/abs/2510.11387)|**[link](https://wen-yuan-zhang.github.io/MaterialRefGS)**|\n", "2510.10691": "|**2025-10-12**|**Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos**|Xuankai Zhang,...Qing Zhang|[2510.10691](http://arxiv.org/abs/2510.10691)|null|\n", "2510.10637": "|**2025-10-12**|**High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting**|Haoyu Zhao,...Hua Zou|[2510.10637](http://arxiv.org/abs/2510.10637)|null|\n", "2510.10492": "|**2025-10-12**|**Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework**|Shanzhi Yin,...Yan Ye|[2510.10492](http://arxiv.org/abs/2510.10492)|null|\n", "2510.10257": "|**2025-10-11**|**Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting**|Abdelrhman Elrawy,...Emad A. Mohammed|[2510.10257](http://arxiv.org/abs/2510.10257)|null|\n", "2510.10152": "|**2025-10-11**|**Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer**|Yecong Wan,...Wangmeng Zuo|[2510.10152](http://arxiv.org/abs/2510.10152)|**[link](https://yecongwan.github.io/Color3D/)**|\n", "2510.10097": "|**2025-10-11**|**Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting**|Jiahui Lu,...Wenxiong Kang|[2510.10097](http://arxiv.org/abs/2510.10097)|null|\n", "2510.10030": "|**2025-10-11**|**P-4DGS: Predictive 4D Gaussian Splatting with 90$\\times$ Compression**|Henan Wang,...Zhibo Chen|[2510.10030](http://arxiv.org/abs/2510.10030)|null|\n", "2510.09997": "|**2025-10-11**|**CLoD-GS: Continuous Level-of-Detail via 3D Gaussian Splatting**|Zhigang Cheng,...Peng Pan|[2510.09997](http://arxiv.org/abs/2510.09997)|null|\n", "2510.09962": "|**2025-10-11**|**VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping**|Yicheng He,...Hong Zhang|[2510.09962](http://arxiv.org/abs/2510.09962)|null|\n", "2510.09881": "|**2025-10-10**|**LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates**|Minkwan Kim,...Young Min Kim|[2510.09881](http://arxiv.org/abs/2510.09881)|null|\n", "2510.12768": "|**2025-10-14**|**Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction**|Fengzhi Guo,...Cheng Zhang|[2510.12768](http://arxiv.org/abs/2510.12768)|**[link](https://tamu-visual-ai.github.io/usplat4d/)**|\n", "2510.12493": "|**2025-10-17**|**BSGS: Bi-stage 3D Gaussian Splatting for Camera Motion Deblurring**|An Zhao,...Mingqiang Wei|[2510.12493](http://arxiv.org/abs/2510.12493)|null|\n", "2510.12308": "|**2025-10-14**|**Hybrid Gaussian Splatting for Novel Urban View Synthesis**|Mohamed Omran,...Amirhossein Habibian|[2510.12308](http://arxiv.org/abs/2510.12308)|null|\n", "2510.12282": "|**2025-10-14**|**PAGS: Priority-Adaptive Gaussian Splatting for Dynamic Driving Scenes**|Ying A,...Jianxun Cui|[2510.12282](http://arxiv.org/abs/2510.12282)|null|\n", "2510.12174": "|**2025-10-14**|**UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering**|Yusen Xie,...Jun Ma|[2510.12174](http://arxiv.org/abs/2510.12174)|null|\n", "2510.12099": "|**2025-10-14**|**G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior**|Junfeng Ni,...Siyuan Huang|[2510.12099](http://arxiv.org/abs/2510.12099)|**[link](https://dali-jack.github.io/g4splat-web/)**|\n", "2510.11878": "|**2025-10-13**|**GS-Verse: Mesh-based Gaussian Splatting for Physics-aware Interaction in Virtual Reality**|Anastasiya Pechko,...Przemys\u0142aw Spurek|[2510.11878](http://arxiv.org/abs/2510.11878)|null|\n", "2510.13454": "|**2025-10-15**|**VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator**|Hyojun Go,...Konrad Schindler|[2510.13454](http://arxiv.org/abs/2510.13454)|**[link](https://gohyojun15.github.io/VIST3A/)**|\n", "2510.13381": "|**2025-10-15**|**Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering**|Siddharth Tourani,...Muhammad Haris Khan|[2510.13381](http://arxiv.org/abs/2510.13381)|**[link](https://dynamic-ugsdf.github.io/)**|\n", "2510.13186": "|**2025-10-15**|**STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control**|Zhen Li,...Chengzhong Xu|[2510.13186](http://arxiv.org/abs/2510.13186)|null|\n", "2510.14705": "|**2025-10-16**|**Leveraging Learned Image Prior for 3D Gaussian Compression**|Seungjoo Shin,...Sunghyun Cho|[2510.14705](http://arxiv.org/abs/2510.14705)|null|\n", "2510.14564": "|**2025-10-16**|**BalanceGS: Algorithm-System Co-design for Efficient 3D Gaussian Splatting Training on GPU**|Junyi Wu,...Guohao Dai|[2510.14564](http://arxiv.org/abs/2510.14564)|null|\n", "2510.14270": "|**2025-10-16**|**GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering**|Alexander Valverde,...Hongyun Wang|[2510.14270](http://arxiv.org/abs/2510.14270)|null|\n", "2510.14179": "|**2025-10-16**|**Virtually Being: Customizing Camera-Controllable Video Diffusion Models with Multi-View Performance Captures**|Yuancheng Xu,...Ning Yu|[2510.14179](http://arxiv.org/abs/2510.14179)|null|\n", "2510.14081": "|**2025-10-17**|**Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from Unstructured Phone Images**|Emanuel Garbin,...Shunsuke Saito|[2510.14081](http://arxiv.org/abs/2510.14081)|null|\n", "2510.13978": "|**2025-10-15**|**Instant Skinned Gaussian Avatars for Web, Mobile and VR Applications**|Naruya Kondo,...Yoichi Ochiai|[2510.13978](http://arxiv.org/abs/2510.13978)|null|\n", "2510.15386": "|**2025-10-17**|**PFGS: Pose-Fused 3D Gaussian Splatting for Complete Multi-Pose Object Reconstruction**|Ting-Yu Yen,...Hung-Kuo Chu|[2510.15386](http://arxiv.org/abs/2510.15386)|null|\n", "2510.15352": "|**2025-10-17**|**GaussGym: An open-source real-to-sim framework for learning locomotion from pixels**|Alejandro Escontrela,...Pieter Abbeel|[2510.15352](http://arxiv.org/abs/2510.15352)|null|\n", "2510.15072": "|**2025-10-16**|**SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images**|Jiaxin Guo,...Yun-Hui Liu|[2510.15072](http://arxiv.org/abs/2510.15072)|null|\n", "2510.17783": "|**2025-10-20**|**Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant Structures with Gaussian Splats**|Simeon Adebola,...Ken Goldberg|[2510.17783](http://arxiv.org/abs/2510.17783)|null|\n", "2510.17719": "|**2025-10-20**|**Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions**|Zhiqiang Teng,...Shunli Zhang|[2510.17719](http://arxiv.org/abs/2510.17719)|null|\n", "2510.17479": "|**2025-10-20**|**Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS**|Feng Zhou,...Jianqin Yin|[2510.17479](http://arxiv.org/abs/2510.17479)|null|\n", "2510.17095": "|**2025-10-20**|**GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation**|Ruitong Gan,...Zhaoxiang Zhang|[2510.17095](http://arxiv.org/abs/2510.17095)|null|\n", "2510.16837": "|**2025-10-19**|**2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting**|Haofan Ren,...Zunjie Zhu|[2510.16837](http://arxiv.org/abs/2510.16837)|null|\n", "2510.16777": "|**2025-10-19**|**GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation**|Junbo Li,...Xiangzhi Bai|[2510.16777](http://arxiv.org/abs/2510.16777)|null|\n", "2510.16463": "|**2025-10-18**|**HGC-Avatar: Hierarchical Gaussian Compression for Streamable Dynamic 3D Avatars**|Haocheng Tang,...Chuanmin Jia|[2510.16463](http://arxiv.org/abs/2510.16463)|null|\n", "2510.16410": "|**2025-10-18**|**REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting**|Changyue Shi,...Zhou Yu|[2510.16410](http://arxiv.org/abs/2510.16410)|null|\n", "2510.16272": "|**2025-10-17**|**Proactive Scene Decomposition and Reconstruction**|Baicheng Li,...Hongbin Zha|[2510.16272](http://arxiv.org/abs/2510.16272)|null|\n", "2510.18739": "|**2025-10-21**|**Moving Light Adaptive Colonoscopy Reconstruction via Illumination-Attenuation-Aware 3D Gaussian Splatting**|Hao Wang,...Zhiwei Wang|[2510.18739](http://arxiv.org/abs/2510.18739)|null|\n", "2510.18489": "|**2025-10-21**|**Mono4DGS-HDR: High Dynamic Range 4D Gaussian Splatting from Alternating-exposure Monocular Videos**|Jinfeng Liu,...Dan Xu|[2510.18489](http://arxiv.org/abs/2510.18489)|**[link](https://liujf1226.github.io/Mono4DGS-HDR/)**|\n", "2510.18253": "|**2025-10-21**|**OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion**|Tianyu Huang,...Tongliang Liu|[2510.18253](http://arxiv.org/abs/2510.18253)|null|\n", "2510.18101": "|**2025-10-20**|**From Volume Rendering to 3D Gaussian Splatting: Theory and Applications**|Vitor Pereira Matias,...Tiago Novello|[2510.18101](http://arxiv.org/abs/2510.18101)|null|\n", "2510.18054": "|**2025-10-20**|**HouseTour: A Virtual Real Estate A(I)gent**|Ata \u00c7elen,...Iro Armeni|[2510.18054](http://arxiv.org/abs/2510.18054)|null|\n", "2510.19578": "|**2025-10-22**|**VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction**|Junhong Lin,...Wei Gao|[2510.19578](http://arxiv.org/abs/2510.19578)|null|\n", "2510.19255": "|**2025-10-22**|**Advances in 4D Representation: Geometry, Motion, and Interaction**|Mingrui Zhao,...Hao Zhang|[2510.19255](http://arxiv.org/abs/2510.19255)|**[link](https://mingrui-zhao.github.io/4DRep-GMI/)**|\n", "2510.19210": "|**2025-10-22**|**MoE-GS: Mixture of Experts for Dynamic Gaussian Splatting**|In-Hwan Jin,...Kyeongbo Kong|[2510.19210](http://arxiv.org/abs/2510.19210)|null|\n", "2510.19200": "|**2025-10-22**|**GRASPLAT: Enabling dexterous grasping through novel view synthesis**|Matteo Bortolon,...Alessio Del Bue|[2510.19200](http://arxiv.org/abs/2510.19200)|null|\n", "2510.19653": "|**2025-10-21**|**Re-Activating Frozen Primitives for 3D Gaussian Splatting**|Yuxin Cheng,...Ngai Wong|[2510.19653](http://arxiv.org/abs/2510.19653)|null|\n", "2510.20813": "|**2025-10-23**|**GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation**|Guangqi Jiang,...Xiaolong Wang|[2510.20813](http://arxiv.org/abs/2510.20813)|null|\n", "2510.20335": "|**2025-10-23**|**Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking**|Zixuan Wu,...Liu Ren|[2510.20335](http://arxiv.org/abs/2510.20335)|**[link](https://github.com/ChampagneAndfragrance/Dino_Diffusion_Parking_Official)**|\n", "2510.20238": "|**2025-10-23**|**COS3D: Collaborative Open-Vocabulary 3D Segmentation**|Runsong Zhu,...Chi-Wing Fu|[2510.20238](http://arxiv.org/abs/2510.20238)|**[link](https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D})**|\n", "2510.20027": "|**2025-10-22**|**Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses**|Damian Bowness,...Charalambos Poullis|[2510.20027](http://arxiv.org/abs/2510.20027)|null|\n", "2510.21307": "|**2025-10-24**|**Towards Physically Executable 3D Gaussian for Embodied Navigation**|Bingchen Miao,...Juncheng Li|[2510.21307](http://arxiv.org/abs/2510.21307)|**[link](https://huggingface.co/datasets/spatialverse/InteriorGS)**|\n", "2510.23521": "|**2025-10-27**|**Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation**|Anthony Opipari,...Odest Chadwicke Jenkins|[2510.23521](http://arxiv.org/abs/2510.23521)|null|\n", "2510.23205": "|**2025-10-27**|**VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting**|Hoonhee Cho,...Kuk-Jin Yoon|[2510.23205](http://arxiv.org/abs/2510.23205)|null|\n", "2510.23087": "|**2025-10-27**|**EndoWave: Rational-Wavelet 4D Gaussian Splatting for Endoscopic Reconstruction**|Taoyu Wu,...Limin Yu|[2510.23087](http://arxiv.org/abs/2510.23087)|null|\n", "2510.22973": "|**2025-10-27**|**Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method**|Bohan Li,...Wenjun Zeng|[2510.22973](http://arxiv.org/abs/2510.22973)|**[link](https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation/tree/v2)**|\n", "2510.22930": "|**2025-10-27**|**Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression**|Pranav Saxena,...Pranav Saxena|[2510.22930](http://arxiv.org/abs/2510.22930)|null|\n", "2510.22812": "|**2025-10-26**|**Region-Adaptive Learned Hierarchical Encoding for 3D Gaussian Splatting Data**|Shashank N. Sridhara,...Antonio Ortega|[2510.22812](http://arxiv.org/abs/2510.22812)|null|\n", "2510.22718": "|**2025-10-26**|**Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication**|Yujie Wan,...Chengzhong Xu|[2510.22718](http://arxiv.org/abs/2510.22718)|null|\n", "2510.22669": "|**2025-10-26**|**LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering**|Wenkai Zhu,...Zihang Wang|[2510.22669](http://arxiv.org/abs/2510.22669)|null|\n", "2510.22600": "|**2025-10-26**|**RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience**|Huilin Yin,...Johannes Betz|[2510.22600](http://arxiv.org/abs/2510.22600)|null|\n", "2510.22473": "|**2025-10-26**|**DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss**|Jing Yang,...Yufeng Yang|[2510.22473](http://arxiv.org/abs/2510.22473)|null|\n", "2510.22213": "|**2025-10-25**|**DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum**|Yaokun Li,...Tianfan Xue|[2510.22213](http://arxiv.org/abs/2510.22213)|**[link](https://dynamictree-dev.github.io/DynamicTree.github.io/)**|\n", "2510.24335": "|**2025-10-28**|**NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation**|Mingyu Jeong,...Andrew Jaeyong Choi|[2510.24335](http://arxiv.org/abs/2510.24335)|null|\n", "2510.24118": "|**2025-10-28**|**LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation**|Haotian Zhou,...Huijing Zhao|[2510.24118](http://arxiv.org/abs/2510.24118)|null|\n", "2510.23988": "|**2025-10-28**|**A Survey on Collaborative SLAM with 3D Gaussian Splatting**|Phuc Nguyen Xuan,...Xiem HoangVan|[2510.23988](http://arxiv.org/abs/2510.23988)|null|\n", "2510.23930": "|**2025-10-27**|**PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors**|Xirui Jin,...Wenxian Yu|[2510.23930](http://arxiv.org/abs/2510.23930)|**[link](https://planargs.github.io)**|\n"}}